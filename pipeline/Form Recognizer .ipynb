{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9a4065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe that has confidence_score, isHandwritten (this comes from styles)\n",
    "# offset, length, content bounding regions\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99650183",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/David.Godinez/Downloads/7b12da4f-7664-433c-9a34-4306c35f1aab_removed.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "result = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26bc5603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>createdDateTime</th>\n",
       "      <th>lastUpdatedDateTime</th>\n",
       "      <th>analyzeResult.apiVersion</th>\n",
       "      <th>analyzeResult.modelId</th>\n",
       "      <th>analyzeResult.stringIndexType</th>\n",
       "      <th>analyzeResult.content</th>\n",
       "      <th>analyzeResult.pages</th>\n",
       "      <th>analyzeResult.paragraphs</th>\n",
       "      <th>analyzeResult.styles</th>\n",
       "      <th>analyzeResult.languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>succeeded</td>\n",
       "      <td>2023-05-03T15:30:33Z</td>\n",
       "      <td>2023-05-03T15:30:39Z</td>\n",
       "      <td>2023-02-28-preview</td>\n",
       "      <td>prebuilt-read</td>\n",
       "      <td>utf16CodeUnit</td>\n",
       "      <td>HØ12943623 KATALYST DATA MANAGEMENT\\nCR 1.03\\n...</td>\n",
       "      <td>[{'pageNumber': 1, 'angle': -0.513000011444091...</td>\n",
       "      <td>[{'spans': [{'offset': 1298, 'length': 9}], 'b...</td>\n",
       "      <td>[{'confidence': 0.95, 'spans': [{'offset': 0, ...</td>\n",
       "      <td>[{'spans': [{'offset': 0, 'length': 10}], 'loc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      status       createdDateTime   lastUpdatedDateTime   \n",
       "0  succeeded  2023-05-03T15:30:33Z  2023-05-03T15:30:39Z  \\\n",
       "\n",
       "  analyzeResult.apiVersion analyzeResult.modelId   \n",
       "0       2023-02-28-preview         prebuilt-read  \\\n",
       "\n",
       "  analyzeResult.stringIndexType   \n",
       "0                 utf16CodeUnit  \\\n",
       "\n",
       "                               analyzeResult.content   \n",
       "0  HØ12943623 KATALYST DATA MANAGEMENT\\nCR 1.03\\n...  \\\n",
       "\n",
       "                                 analyzeResult.pages   \n",
       "0  [{'pageNumber': 1, 'angle': -0.513000011444091...  \\\n",
       "\n",
       "                            analyzeResult.paragraphs   \n",
       "0  [{'spans': [{'offset': 1298, 'length': 9}], 'b...  \\\n",
       "\n",
       "                                analyzeResult.styles   \n",
       "0  [{'confidence': 0.95, 'spans': [{'offset': 0, ...  \\\n",
       "\n",
       "                             analyzeResult.languages  \n",
       "0  [{'spans': [{'offset': 0, 'length': 10}], 'loc...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing the result\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d2ddb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>boundingRegions</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'offset': 1298, 'length': 9}]</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [1.5794, 0.4786,...</td>\n",
       "      <td>:barcode:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'offset': 0, 'length': 35}]</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [1.5709, 0.6702,...</td>\n",
       "      <td>HØ12943623 KATALYST DATA MANAGEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'offset': 36, 'length': 7}]</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [6.7387, 1.3306,...</td>\n",
       "      <td>CR 1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'offset': 44, 'length': 14}]</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [3.6263, 1.7614,...</td>\n",
       "      <td>March 21, 1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'offset': 59, 'length': 11}]</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [5.0014, 2.2496,...</td>\n",
       "      <td>Filet CR-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             spans   \n",
       "0  [{'offset': 1298, 'length': 9}]  \\\n",
       "1    [{'offset': 0, 'length': 35}]   \n",
       "2    [{'offset': 36, 'length': 7}]   \n",
       "3   [{'offset': 44, 'length': 14}]   \n",
       "4   [{'offset': 59, 'length': 11}]   \n",
       "\n",
       "                                     boundingRegions   \n",
       "0  [{'pageNumber': 1, 'polygon': [1.5794, 0.4786,...  \\\n",
       "1  [{'pageNumber': 1, 'polygon': [1.5709, 0.6702,...   \n",
       "2  [{'pageNumber': 1, 'polygon': [6.7387, 1.3306,...   \n",
       "3  [{'pageNumber': 1, 'polygon': [3.6263, 1.7614,...   \n",
       "4  [{'pageNumber': 1, 'polygon': [5.0014, 2.2496,...   \n",
       "\n",
       "                               content  \n",
       "0                            :barcode:  \n",
       "1  HØ12943623 KATALYST DATA MANAGEMENT  \n",
       "2                              CR 1.03  \n",
       "3                       March 21, 1950  \n",
       "4                          Filet CR-30  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the initial paragraph dataframe\n",
    "paragraph = pd.DataFrame(result['analyzeResult.paragraphs'][0])\n",
    "paragraph.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f700e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create paragraph dataframe\n",
    "paragraph_spans = []\n",
    "\n",
    "for index, row in paragraph.iterrows():\n",
    "    for span in row['spans']:\n",
    "        span['content'] = row['content']\n",
    "        span['boundingRegions'] = row['boundingRegions']\n",
    "        paragraph_spans.append(span)\n",
    "\n",
    "df_paragraph_spans = pd.DataFrame(paragraph_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11667e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>boundingRegions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1298</td>\n",
       "      <td>9</td>\n",
       "      <td>:barcode:</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [1.5794, 0.4786,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>HØ12943623 KATALYST DATA MANAGEMENT</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [1.5709, 0.6702,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>CR 1.03</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [6.7387, 1.3306,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>March 21, 1950</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [3.6263, 1.7614,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>11</td>\n",
       "      <td>Filet CR-30</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [5.0014, 2.2496,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>5231</td>\n",
       "      <td>299</td>\n",
       "      <td>6 Circ &amp; cond mud 10 hrs. Drilled plug &amp; shoe ...</td>\n",
       "      <td>[{'pageNumber': 5, 'polygon': [3.2411, 5.8407,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>5531</td>\n",
       "      <td>10</td>\n",
       "      <td>Form. Nº %</td>\n",
       "      <td>[{'pageNumber': 5, 'polygon': [0.616, 10.0543,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>5542</td>\n",
       "      <td>123</td>\n",
       "      <td>7 Circ &amp; cond mud 16 hrs. Using Lime-Oil Emuls...</td>\n",
       "      <td>[{'pageNumber': 5, 'polygon': [3.2411, 7.2034,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>5666</td>\n",
       "      <td>3</td>\n",
       "      <td>79'</td>\n",
       "      <td>[{'pageNumber': 5, 'polygon': [2.4829, 7.3631,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5670</td>\n",
       "      <td>13</td>\n",
       "      <td>117.275 Tormo</td>\n",
       "      <td>[{'pageNumber': 5, 'polygon': [6.8706, 10.1633...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     offset  length                                            content   \n",
       "0      1298       9                                          :barcode:  \\\n",
       "1         0      35                HØ12943623 KATALYST DATA MANAGEMENT   \n",
       "2        36       7                                            CR 1.03   \n",
       "3        44      14                                     March 21, 1950   \n",
       "4        59      11                                        Filet CR-30   \n",
       "..      ...     ...                                                ...   \n",
       "135    5231     299  6 Circ & cond mud 10 hrs. Drilled plug & shoe ...   \n",
       "136    5531      10                                         Form. Nº %   \n",
       "137    5542     123  7 Circ & cond mud 16 hrs. Using Lime-Oil Emuls...   \n",
       "138    5666       3                                                79'   \n",
       "139    5670      13                                      117.275 Tormo   \n",
       "\n",
       "                                       boundingRegions  \n",
       "0    [{'pageNumber': 1, 'polygon': [1.5794, 0.4786,...  \n",
       "1    [{'pageNumber': 1, 'polygon': [1.5709, 0.6702,...  \n",
       "2    [{'pageNumber': 1, 'polygon': [6.7387, 1.3306,...  \n",
       "3    [{'pageNumber': 1, 'polygon': [3.6263, 1.7614,...  \n",
       "4    [{'pageNumber': 1, 'polygon': [5.0014, 2.2496,...  \n",
       "..                                                 ...  \n",
       "135  [{'pageNumber': 5, 'polygon': [3.2411, 5.8407,...  \n",
       "136  [{'pageNumber': 5, 'polygon': [0.616, 10.0543,...  \n",
       "137  [{'pageNumber': 5, 'polygon': [3.2411, 7.2034,...  \n",
       "138  [{'pageNumber': 5, 'polygon': [2.4829, 7.3631,...  \n",
       "139  [{'pageNumber': 5, 'polygon': [6.8706, 10.1633...  \n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragraph_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "730f9520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>spans</th>\n",
       "      <th>isHandwritten</th>\n",
       "      <th>fontStyle</th>\n",
       "      <th>fontWeight</th>\n",
       "      <th>similarFontFamily</th>\n",
       "      <th>color</th>\n",
       "      <th>backgroundColor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>[{'offset': 0, 'length': 35}, {'offset': 44, '...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>[{'offset': 0, 'length': 35}, {'offset': 1323,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>[{'offset': 0, 'length': 35}, {'offset': 1323,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>[{'offset': 0, 'length': 10}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arial, sans-serif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.99</td>\n",
       "      <td>[{'offset': 0, 'length': 10}, {'offset': 36, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confidence                                              spans   \n",
       "0        0.95  [{'offset': 0, 'length': 35}, {'offset': 44, '...  \\\n",
       "1        1.00  [{'offset': 0, 'length': 35}, {'offset': 1323,...   \n",
       "2        1.00  [{'offset': 0, 'length': 35}, {'offset': 1323,...   \n",
       "3        1.00                      [{'offset': 0, 'length': 10}]   \n",
       "4        0.99  [{'offset': 0, 'length': 10}, {'offset': 36, '...   \n",
       "\n",
       "  isHandwritten fontStyle fontWeight  similarFontFamily    color   \n",
       "0         False       NaN        NaN                NaN      NaN  \\\n",
       "1           NaN    normal        NaN                NaN      NaN   \n",
       "2           NaN       NaN       bold                NaN      NaN   \n",
       "3           NaN       NaN        NaN  Arial, sans-serif      NaN   \n",
       "4           NaN       NaN        NaN                NaN  #000000   \n",
       "\n",
       "  backgroundColor  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles = result['analyzeResult.styles']\n",
    "df_styles = pd.DataFrame(styles[0])\n",
    "df_styles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f84c3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create styles dataframe \n",
    "style_spans = []\n",
    "\n",
    "for index, row in df_styles.iterrows():\n",
    "    for span in row['spans']:\n",
    "        span['confidence'] = row['confidence']\n",
    "        span['isHandwritten'] = row['isHandwritten']\n",
    "        span['fontStyle'] = row['fontStyle']\n",
    "        span['fontWeight'] = row['fontWeight']\n",
    "        span['similarFontFamily'] = row['similarFontFamily']\n",
    "        span['color'] = row['color']\n",
    "        span['backgroundColor'] = row['backgroundColor']\n",
    "        style_spans.append(span)\n",
    "\n",
    "df_style_spans = pd.DataFrame(style_spans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1664bc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>confidence</th>\n",
       "      <th>isHandwritten</th>\n",
       "      <th>fontStyle</th>\n",
       "      <th>fontWeight</th>\n",
       "      <th>similarFontFamily</th>\n",
       "      <th>color</th>\n",
       "      <th>backgroundColor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>179</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235</td>\n",
       "      <td>207</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>836</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1292</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offset  length  confidence isHandwritten fontStyle fontWeight   \n",
       "0       0      35        0.95         False       NaN        NaN  \\\n",
       "1      44     179        0.95         False       NaN        NaN   \n",
       "2     235     207        0.95         False       NaN        NaN   \n",
       "3     449     836        0.95         False       NaN        NaN   \n",
       "4    1292       5        0.95         False       NaN        NaN   \n",
       "\n",
       "  similarFontFamily color backgroundColor  \n",
       "0               NaN   NaN             NaN  \n",
       "1               NaN   NaN             NaN  \n",
       "2               NaN   NaN             NaN  \n",
       "3               NaN   NaN             NaN  \n",
       "4               NaN   NaN             NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_style_spans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fa52568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_paragraph_spans, df_style_spans, on=['offset', 'length'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe4f388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the boundingRegions column and reset the index\n",
    "df_bounding_regions_normalized = pd.json_normalize(df_merged['boundingRegions'].explode()).reset_index(drop=True)\n",
    "\n",
    "# Merge the original DataFrame with the normalized boundingRegions DataFrame\n",
    "df_merged2 = pd.concat([df_merged.drop(columns=['boundingRegions']), df_bounding_regions_normalized], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6704c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>confidence</th>\n",
       "      <th>isHandwritten</th>\n",
       "      <th>fontStyle</th>\n",
       "      <th>fontWeight</th>\n",
       "      <th>similarFontFamily</th>\n",
       "      <th>color</th>\n",
       "      <th>backgroundColor</th>\n",
       "      <th>pageNumber</th>\n",
       "      <th>polygon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>CR 1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[6.7387, 1.3306, 7.7821, 1.345, 7.7791, 1.5604...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1308</td>\n",
       "      <td>14</td>\n",
       "      <td>Costa Rica Pre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[6.2395, 0.0901, 7.8714, 0.0474, 7.8778, 0.293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1355</td>\n",
       "      <td>8</td>\n",
       "      <td>CR. 1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[6.5255, 0.905, 7.5254, 0.9618, 7.5136, 1.1705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>4649</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>[2.4355, 3.5346, 2.7151, 3.5346, 2.7151, 3.619...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>4960</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>0.7</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>[2.426, 4.705, 2.7009, 4.705, 2.7009, 4.8045, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     offset  length         content  confidence isHandwritten fontStyle   \n",
       "4        36       7         CR 1.03         1.0          True       NaN  \\\n",
       "73     1308      14  Costa Rica Pre         1.0          True       NaN   \n",
       "80     1355       8        CR. 1.03         1.0          True       NaN   \n",
       "304    4649       1               -         0.4          True       NaN   \n",
       "315    4960       1               -         0.7          True       NaN   \n",
       "\n",
       "    fontWeight similarFontFamily color backgroundColor  pageNumber   \n",
       "4          NaN               NaN   NaN             NaN           1  \\\n",
       "73         NaN               NaN   NaN             NaN           2   \n",
       "80         NaN               NaN   NaN             NaN           2   \n",
       "304        NaN               NaN   NaN             NaN           5   \n",
       "315        NaN               NaN   NaN             NaN           5   \n",
       "\n",
       "                                               polygon  \n",
       "4    [6.7387, 1.3306, 7.7821, 1.345, 7.7791, 1.5604...  \n",
       "73   [6.2395, 0.0901, 7.8714, 0.0474, 7.8778, 0.293...  \n",
       "80   [6.5255, 0.905, 7.5254, 0.9618, 7.5136, 1.1705...  \n",
       "304  [2.4355, 3.5346, 2.7151, 3.5346, 2.7151, 3.619...  \n",
       "315  [2.426, 4.705, 2.7009, 4.705, 2.7009, 4.8045, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged2[df_merged['isHandwritten'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc1bc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def create_paragraph_dataframe(data):\n",
    "    result = pd.json_normalize(data)\n",
    "    paragraph = pd.DataFrame(result['analyzeResult.paragraphs'][0])\n",
    "\n",
    "    paragraph_spans = []\n",
    "\n",
    "    for index, row in paragraph.iterrows():\n",
    "        for span in row['spans']:\n",
    "            span['content'] = row['content']\n",
    "            span['boundingRegions'] = row['boundingRegions']\n",
    "            paragraph_spans.append(span)\n",
    "\n",
    "    df_paragraph_spans = pd.DataFrame(paragraph_spans)\n",
    "    return df_paragraph_spans\n",
    "\n",
    "\n",
    "def create_style_dataframe(data):\n",
    "    styles = pd.json_normalize(data)\n",
    "    df_styles = pd.DataFrame(result['analyzeResult.styles'][0])\n",
    "\n",
    "    style_spans = []\n",
    "\n",
    "    for index, row in df_styles.iterrows():\n",
    "        for span in row['spans']:\n",
    "            span['confidence'] = row['confidence']\n",
    "            span['isHandwritten'] = row['isHandwritten']\n",
    "            span['fontStyle'] = row['fontStyle']\n",
    "            span['fontWeight'] = row['fontWeight']\n",
    "            span['similarFontFamily'] = row['similarFontFamily']\n",
    "            span['color'] = row['color']\n",
    "            span['backgroundColor'] = row['backgroundColor']\n",
    "            style_spans.append(span)\n",
    "\n",
    "    df_style_spans = pd.DataFrame(style_spans)\n",
    "\n",
    "\n",
    "def merge_dataframes(df_paragraph_spans, df_style_spans):\n",
    "    df_merged = pd.merge(df_paragraph_spans, df_style_spans, on=['offset', 'length'], how='inner')\n",
    "    df_bounding_regions_normalized = pd.json_normalize(df_merged['boundingRegions'].explode()).reset_index(drop=True)\n",
    "    return pd.concat([df_merged.drop(columns=['boundingRegions']), df_bounding_regions_normalized], axis=1)\n",
    "\n",
    "\n",
    "def form_recognizer(file_path):\n",
    "    data = read_json_file(file_path)\n",
    "    \n",
    "    df_paragraph_spans = create_paragraph_dataframe(data)\n",
    "    df_style_spans = create_style_dataframe(data)\n",
    "    df_handwritten_spans_merged = merge_dataframes(df_paragraph_spans, df_style_spans)\n",
    "\n",
    "    return df_handwritten_spans_merged[df_handwritten_spans_merged['isHandwritten'] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76b7e4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>boundingRegions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1298</td>\n",
       "      <td>9</td>\n",
       "      <td>:barcode:</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [1.5794, 0.4786,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>HØ12943623 KATALYST DATA MANAGEMENT</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [1.5709, 0.6702,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>CR 1.03</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [6.7387, 1.3306,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>March 21, 1950</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [3.6263, 1.7614,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>11</td>\n",
       "      <td>Filet CR-30</td>\n",
       "      <td>[{'pageNumber': 1, 'polygon': [5.0014, 2.2496,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2254</td>\n",
       "      <td>28</td>\n",
       "      <td>ES-3 50 ohms 2,1001 - 3,060'</td>\n",
       "      <td>[{'pageNumber': 2, 'polygon': [2.5164, 9.1493,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2283</td>\n",
       "      <td>4</td>\n",
       "      <td>ES-7</td>\n",
       "      <td>[{'pageNumber': 2, 'polygon': [2.5258, 9.3294,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2288</td>\n",
       "      <td>15</td>\n",
       "      <td>6,210' - 7,500'</td>\n",
       "      <td>[{'pageNumber': 2, 'polygon': [3.1561, 9.3247,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2304</td>\n",
       "      <td>4</td>\n",
       "      <td>ES-5</td>\n",
       "      <td>[{'pageNumber': 2, 'polygon': [2.5164, 9.5, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2309</td>\n",
       "      <td>15</td>\n",
       "      <td>4,100' - 5,290'</td>\n",
       "      <td>[{'pageNumber': 2, 'polygon': [3.1893, 9.5, 4....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    offset  length                              content   \n",
       "0     1298       9                            :barcode:  \\\n",
       "1        0      35  HØ12943623 KATALYST DATA MANAGEMENT   \n",
       "2       36       7                              CR 1.03   \n",
       "3       44      14                       March 21, 1950   \n",
       "4       59      11                          Filet CR-30   \n",
       "..     ...     ...                                  ...   \n",
       "67    2254      28         ES-3 50 ohms 2,1001 - 3,060'   \n",
       "68    2283       4                                 ES-7   \n",
       "69    2288      15                      6,210' - 7,500'   \n",
       "70    2304       4                                 ES-5   \n",
       "71    2309      15                      4,100' - 5,290'   \n",
       "\n",
       "                                      boundingRegions  \n",
       "0   [{'pageNumber': 1, 'polygon': [1.5794, 0.4786,...  \n",
       "1   [{'pageNumber': 1, 'polygon': [1.5709, 0.6702,...  \n",
       "2   [{'pageNumber': 1, 'polygon': [6.7387, 1.3306,...  \n",
       "3   [{'pageNumber': 1, 'polygon': [3.6263, 1.7614,...  \n",
       "4   [{'pageNumber': 1, 'polygon': [5.0014, 2.2496,...  \n",
       "..                                                ...  \n",
       "67  [{'pageNumber': 2, 'polygon': [2.5164, 9.1493,...  \n",
       "68  [{'pageNumber': 2, 'polygon': [2.5258, 9.3294,...  \n",
       "69  [{'pageNumber': 2, 'polygon': [3.1561, 9.3247,...  \n",
       "70  [{'pageNumber': 2, 'polygon': [2.5164, 9.5, 2....  \n",
       "71  [{'pageNumber': 2, 'polygon': [3.1893, 9.5, 4....  \n",
       "\n",
       "[72 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/David.Godinez/Downloads/7b12da4f-7664-433c-9a34-4306c35f1aab_removed_pdf.json'\n",
    "\n",
    "# print(form_recognizer(file_path))\n",
    "data = read_json_file(file_path)\n",
    "# create_paragraph_dataframe(data)\n",
    "result = pd.json_normalize(data)\n",
    "paragraph = pd.DataFrame(result['analyzeResult.paragraphs'][0])\n",
    "\n",
    "paragraph_spans = []\n",
    "\n",
    "for index, row in paragraph.iterrows():\n",
    "    for span in row['spans']:\n",
    "        span['content'] = row['content']\n",
    "        span['boundingRegions'] = row['boundingRegions']\n",
    "        paragraph_spans.append(span)\n",
    "\n",
    "df_paragraph_spans = pd.DataFrame(paragraph_spans)\n",
    "df_paragraph_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/David.Godinez/Downloads/7b12da4f-7664-433c-9a34-4306c35f1aab_removed_pdf.json'\n",
    "\n",
    "# print(form_recognizer(file_path))\n",
    "data = read_json_file(file_path)\n",
    "\n",
    "def create_paragraph_dataframe(data):\n",
    "    result = pd.json_normalize(data)\n",
    "    paragraph = pd.DataFrame(result['analyzeResult.paragraphs'][0])\n",
    "\n",
    "    paragraph_spans = []\n",
    "\n",
    "    for index, row in paragraph.iterrows():\n",
    "        for span in row['spans']:\n",
    "            span['content'] = row['content']\n",
    "            span['boundingRegions'] = row['boundingRegions']\n",
    "            paragraph_spans.append(span)\n",
    "\n",
    "    df_paragraph_spans = pd.DataFrame(paragraph_spans)\n",
    "    return df_paragraph_spans\n",
    "\n",
    "# create_paragraph_dataframe(data)\n",
    "\n",
    "def create_style_dataframe(data):\n",
    "    styles = pd.json_normalize(data)\n",
    "    df_styles = pd.DataFrame(result['analyzeResult.styles'][0])\n",
    "\n",
    "    style_spans = []\n",
    "\n",
    "    for index, row in df_styles.iterrows():\n",
    "        for span in row['spans']:\n",
    "            span['confidence'] = row['confidence']\n",
    "            span['isHandwritten'] = row['isHandwritten']\n",
    "            span['fontStyle'] = row['fontStyle']\n",
    "            span['fontWeight'] = row['fontWeight']\n",
    "            span['similarFontFamily'] = row['similarFontFamily']\n",
    "            span['color'] = row['color']\n",
    "            span['backgroundColor'] = row['backgroundColor']\n",
    "            style_spans.append(span)\n",
    "\n",
    "    df_style_spans = pd.DataFrame(style_spans)\n",
    "    return df_style_spans\n",
    "\n",
    "create_style_dataframe(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95c50de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1433bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'azure.ai.formrecognizer._models.AnalyzeResult'>\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/David.Godinez/Downloads/24769174__AMERICAS__Costa-Rica_truncated_1-5.pdf'\n",
    "print(type(form_recognizer(file_path=file_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b22e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient, AnalyzeResult\n",
    "\n",
    "def analyze_document(file_path):\n",
    "    # Load the credentials from a JSON file and other necessary steps\n",
    "    credentials_path = os.path.abspath('credentials3.json')\n",
    "    with open(credentials_path, 'r') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    subscription_key = credentials['API_key']\n",
    "    endpoint = credentials['endpoint']\n",
    "\n",
    "    document_analysis_client = DocumentAnalysisClient(endpoint=endpoint, credential=AzureKeyCredential(subscription_key))\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    poller = document_analysis_client.begin_analyze_document(\"prebuilt-read\", file_content)\n",
    "    result = poller.result()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_paragraph_dataframe(analyze_result: AnalyzeResult):\n",
    "    paragraphs = [paragraph for page in analyze_result.pages for paragraph in page.paragraphs]\n",
    "    paragraph_spans = [\n",
    "        {**span.__dict__, 'content': paragraph.content, 'bounding_box': paragraph.bounding_box}\n",
    "        for paragraph in paragraphs\n",
    "        for span in paragraph.spans\n",
    "    ]\n",
    "    return pd.DataFrame(paragraph_spans)\n",
    "\n",
    "\n",
    "\n",
    "def create_style_dataframe(analyze_result: AnalyzeResult):\n",
    "    styles = analyze_result.styles\n",
    "    style_spans = [\n",
    "        {**span.__dict__, 'confidence': style.confidence, 'isHandwritten': style.is_handwritten,\n",
    "         'fontStyle': style.font_style, 'fontWeight': style.font_weight,\n",
    "         'similarFontFamily': style.similar_font_family, 'color': style.color,\n",
    "         'backgroundColor': style.background_color}\n",
    "        for style in styles\n",
    "        for span in style.spans\n",
    "    ]\n",
    "    return pd.DataFrame(style_spans)\n",
    "\n",
    "def merge_dataframes(df_paragraph_spans, df_style_spans):\n",
    "    df_merged = pd.merge(df_paragraph_spans, df_style_spans, on=['offset', 'length'], how='inner')\n",
    "    df_bounding_regions_normalized = pd.json_normalize(df_merged['boundingRegions'].explode()).reset_index(drop=True)\n",
    "    return pd.concat([df_merged.drop(columns=['boundingRegions']), df_bounding_regions_normalized], axis=1)\n",
    "\n",
    "def process_analyze_result(filepath: str):\n",
    "    analyzed_result = analyze_document(filepath)\n",
    "    df_paragraph_spans = create_paragraph_dataframe(analyzed_result)\n",
    "    df_style_spans = create_style_dataframe(analyzed_result)\n",
    "    df_handwritten_spans_merged = merge_dataframes(df_paragraph_spans, df_style_spans)\n",
    "\n",
    "    return df_handwritten_spans_merged[df_handwritten_spans_merged['isHandwritten'] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/David.Godinez/Downloads/7b12da4f-7664-433c-9a34-4306c35f1aab_removed_pdf.json'\n",
    "print(process_analyze_result(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e111778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bab08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e64e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c63ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0514cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6209e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7ea47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b1173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb126a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e2090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb633e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version with generated json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77383de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c58129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def create_paragraph_dataframe(data):\n",
    "    df_paragraph = pd.DataFrame(pd.json_normalize(data)['analyzeResult.paragraphs'][0])\n",
    "    paragraph_spans = [\n",
    "        {**span, 'content': row['content'], 'boundingRegions': row['boundingRegions']}\n",
    "        for _, row in df_paragraph.iterrows()\n",
    "        for span in row['spans']\n",
    "    ]\n",
    "    return pd.DataFrame(paragraph_spans)\n",
    "\n",
    "\n",
    "def create_style_dataframe(data):\n",
    "    styles = pd.json_normalize(data)['analyzeResult.styles']\n",
    "    df_styles = pd.DataFrame(styles[0])\n",
    "    style_spans = [\n",
    "        {**span, 'confidence': row['confidence'], 'isHandwritten': row['isHandwritten'],\n",
    "         'fontStyle': row['fontStyle'], 'fontWeight': row['fontWeight'],\n",
    "         'similarFontFamily': row['similarFontFamily'], 'color': row['color'],\n",
    "         'backgroundColor': row['backgroundColor']}\n",
    "        for _, row in df_styles.iterrows()\n",
    "        for span in row['spans']\n",
    "    ]\n",
    "    return pd.DataFrame(style_spans)\n",
    "\n",
    "\n",
    "def merge_dataframes(df_paragraph_spans, df_style_spans):\n",
    "    df_merged = pd.merge(df_paragraph_spans, df_style_spans, on=['offset', 'length'], how='inner')\n",
    "    df_bounding_regions_normalized = pd.json_normalize(df_merged['boundingRegions'].explode()).reset_index(drop=True)\n",
    "    return pd.concat([df_merged.drop(columns=['boundingRegions']), df_bounding_regions_normalized], axis=1)\n",
    "\n",
    "\n",
    "def form_recognizer(file_path):\n",
    "    data = read_json_file(file_path)\n",
    "\n",
    "    df_paragraph_spans = create_paragraph_dataframe(data)\n",
    "    df_style_spans = create_style_dataframe(data)\n",
    "    df_handwritten_spans_merged = merge_dataframes(df_paragraph_spans, df_style_spans)\n",
    "\n",
    "    return df_handwritten_spans_merged[df_handwritten_spans_merged['isHandwritten'] == True]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ab8746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>confidence</th>\n",
       "      <th>isHandwritten</th>\n",
       "      <th>fontStyle</th>\n",
       "      <th>fontWeight</th>\n",
       "      <th>similarFontFamily</th>\n",
       "      <th>color</th>\n",
       "      <th>backgroundColor</th>\n",
       "      <th>pageNumber</th>\n",
       "      <th>polygon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>CR 1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[6.7387, 1.3306, 7.7821, 1.345, 7.7791, 1.5604...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1308</td>\n",
       "      <td>14</td>\n",
       "      <td>Costa Rica Pre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[6.2395, 0.0901, 7.8714, 0.0474, 7.8778, 0.293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1355</td>\n",
       "      <td>8</td>\n",
       "      <td>CR. 1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[6.5255, 0.905, 7.5254, 0.9618, 7.5136, 1.1705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>4649</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>[2.4355, 3.5346, 2.7151, 3.5346, 2.7151, 3.619...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>4960</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>0.7</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>[2.426, 4.705, 2.7009, 4.705, 2.7009, 4.8045, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     offset  length         content  confidence isHandwritten fontStyle   \n",
       "4        36       7         CR 1.03         1.0          True       NaN  \\\n",
       "73     1308      14  Costa Rica Pre         1.0          True       NaN   \n",
       "80     1355       8        CR. 1.03         1.0          True       NaN   \n",
       "304    4649       1               -         0.4          True       NaN   \n",
       "315    4960       1               -         0.7          True       NaN   \n",
       "\n",
       "    fontWeight similarFontFamily color backgroundColor  pageNumber   \n",
       "4          NaN               NaN   NaN             NaN           1  \\\n",
       "73         NaN               NaN   NaN             NaN           2   \n",
       "80         NaN               NaN   NaN             NaN           2   \n",
       "304        NaN               NaN   NaN             NaN           5   \n",
       "315        NaN               NaN   NaN             NaN           5   \n",
       "\n",
       "                                               polygon  \n",
       "4    [6.7387, 1.3306, 7.7821, 1.345, 7.7791, 1.5604...  \n",
       "73   [6.2395, 0.0901, 7.8714, 0.0474, 7.8778, 0.293...  \n",
       "80   [6.5255, 0.905, 7.5254, 0.9618, 7.5136, 1.1705...  \n",
       "304  [2.4355, 3.5346, 2.7151, 3.5346, 2.7151, 3.619...  \n",
       "315  [2.426, 4.705, 2.7009, 4.705, 2.7009, 4.8045, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/David.Godinez/Downloads/7b12da4f-7664-433c-9a34-4306c35f1aab_removed.json'\n",
    "form_recognizer(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c2a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/David.Godinez/Downloads/7b12da4f-7664-433c-9a34-4306c35f1aab_removed.json'\n",
    "data = read_json_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce31d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraph = create_paragraph_dataframe(data)\n",
    "df_style = create_style_dataframe(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831b18ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>confidence</th>\n",
       "      <th>isHandwritten</th>\n",
       "      <th>fontStyle</th>\n",
       "      <th>fontWeight</th>\n",
       "      <th>similarFontFamily</th>\n",
       "      <th>color</th>\n",
       "      <th>backgroundColor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>179</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235</td>\n",
       "      <td>207</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>836</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1292</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>5231</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UD Digi Kyokasho N, serif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>5531</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Times New Roman, serif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>5542</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BIZ UDMincho Medium, serif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>5666</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BIZ UDMincho Medium, serif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>5670</td>\n",
       "      <td>13</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Times New Roman, serif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     offset  length  confidence isHandwritten fontStyle fontWeight   \n",
       "0         0      35        0.95         False       NaN        NaN  \\\n",
       "1        44     179        0.95         False       NaN        NaN   \n",
       "2       235     207        0.95         False       NaN        NaN   \n",
       "3       449     836        0.95         False       NaN        NaN   \n",
       "4      1292       5        0.95         False       NaN        NaN   \n",
       "..      ...     ...         ...           ...       ...        ...   \n",
       "752    5231       1        0.95           NaN       NaN        NaN   \n",
       "753    5531      10        0.95           NaN       NaN        NaN   \n",
       "754    5542       1        0.40           NaN       NaN        NaN   \n",
       "755    5666       3        0.50           NaN       NaN        NaN   \n",
       "756    5670      13        0.90           NaN       NaN        NaN   \n",
       "\n",
       "              similarFontFamily color backgroundColor  \n",
       "0                           NaN   NaN             NaN  \n",
       "1                           NaN   NaN             NaN  \n",
       "2                           NaN   NaN             NaN  \n",
       "3                           NaN   NaN             NaN  \n",
       "4                           NaN   NaN             NaN  \n",
       "..                          ...   ...             ...  \n",
       "752   UD Digi Kyokasho N, serif   NaN             NaN  \n",
       "753      Times New Roman, serif   NaN             NaN  \n",
       "754  BIZ UDMincho Medium, serif   NaN             NaN  \n",
       "755  BIZ UDMincho Medium, serif   NaN             NaN  \n",
       "756      Times New Roman, serif   NaN             NaN  \n",
       "\n",
       "[757 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at what comes out of the df_style \n",
    "df_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf488e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28a302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95386f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af5a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f159a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version that sends pdf to api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ae8f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re \n",
    "import os\n",
    "import pandas as pd\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient, AnalyzeResult\n",
    "\n",
    "def analyze_document(file_path):\n",
    "    # Load the credentials from a JSON file and other necessary steps\n",
    "    credentials_path = os.path.abspath('credentials2.json')\n",
    "    with open(credentials_path, 'r') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    subscription_key = credentials['API_key']\n",
    "    endpoint = credentials['endpoint']\n",
    "\n",
    "    document_analysis_client = DocumentAnalysisClient(endpoint=endpoint, credential=AzureKeyCredential(subscription_key))\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    poller = document_analysis_client.begin_analyze_document(\"prebuilt-read\", file_content)\n",
    "    result = poller.result()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def analyze_result(result): \n",
    "    # Extract relevant data from the AnalyzeResult object\n",
    "    data = {\n",
    "        \"analyzeResultapi_version\": [result.api_version],\n",
    "        \"analyzeResult.model_id\": [result.model_id],\n",
    "        \"analyzeResult.content\": [str(result.content)],\n",
    "        \"analyzeResult.pages\": [str(result.pages)],\n",
    "        \"analyzeResult.styles\": [str(result.styles)],\n",
    "        \"analyzeResult.paragraphs\": [str(result.paragraphs)]\n",
    "    }\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    analyze_result = pd.DataFrame(data)\n",
    "    return analyze_result\n",
    "    \n",
    "\n",
    "\n",
    "def create_paragraph_dataframe(input_string):\n",
    "    # input_string = anlyze_result['analyzeResult.paragraphs'][0]\n",
    "    content_pattern = re.compile(r\"content=([^,]+)\")\n",
    "    page_number_pattern = re.compile(r\"page_number=(\\d+)\")\n",
    "    polygon_pattern = re.compile(r\"Point\\(x=([\\d.]+), y=([\\d.]+)\\)\")\n",
    "    span_pattern = re.compile(r\"DocumentSpan\\(offset=(\\d+), length=(\\d+)\\)\")\n",
    "\n",
    "    content_list = content_pattern.findall(input_string)\n",
    "    page_number_list = page_number_pattern.findall(input_string)\n",
    "    polygon_list = [list(zip(x[0::2], x[1::2])) for x in polygon_pattern.findall(input_string)]\n",
    "    span_list = span_pattern.findall(input_string)\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(content_list)):\n",
    "        data.append({\n",
    "            \"offset\": span_list[i][0],\n",
    "            \"length\": span_list[i][1],\n",
    "            \"content\": content_list[i],\n",
    "            \"page_number\": page_number_list[i],\n",
    "            \"polygon\": polygon_list[i]\n",
    "            \n",
    "        })\n",
    "        \n",
    "    df_paragraph_spans = pd.DataFrame(data)\n",
    "\n",
    "    return df_paragraph_spans\n",
    "\n",
    "\n",
    "\n",
    "def create_style_dataframe(input_string):\n",
    "    is_handwritten_pattern = re.compile(r\"is_handwritten=([^,]+)\")\n",
    "    span_pattern = re.compile(r\"DocumentSpan\\(offset=(\\d+), length=(\\d+)\\)\")\n",
    "    confidence_pattern = re.compile(r\"confidence=([\\d.]+)\")\n",
    "\n",
    "    is_handwritten_list = is_handwritten_pattern.findall(input_string)\n",
    "    span_list = span_pattern.findall(input_string)\n",
    "    confidence_list = confidence_pattern.findall(input_string)\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(is_handwritten_list)):\n",
    "        data.append({\n",
    "            \"confidence\": confidence_list[i],\n",
    "            \"is_handwritten\": is_handwritten_list[i],\n",
    "            \"offset\": span_list[i][0],\n",
    "            \"length\": span_list[i][1]\n",
    "        })\n",
    "\n",
    "    df_style_spans = pd.DataFrame(data)\n",
    "\n",
    "    return df_style_spans\n",
    "\n",
    "def merge_dataframes(df_paragraph_spans, df_style_spans):\n",
    "    df_merged = pd.merge(df_paragraph_spans, df_style_spans, on=['offset', 'length'], how='inner')\n",
    "    return df_merged.reindex()\n",
    "\n",
    "def process_analyze_result(filepath: str):\n",
    "    result = analyze_document(filepath)\n",
    "    analyzed_result = analyze_result(result)\n",
    "    df_paragraph_spans = create_paragraph_dataframe(analyzed_result['analyzeResult.paragraphs'][0])\n",
    "    df_style_spans = create_style_dataframe(analyzed_result['analyzeResult.styles'][0])\n",
    "    df_handwritten_spans_merged = merge_dataframes(df_paragraph_spans, df_style_spans)\n",
    "\n",
    "    return df_handwritten_spans_merged[df_handwritten_spans_merged['isHandwritten'] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1625b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/David.Godinez/Desktop/BJSS/exxon3/exxonmobile/files/7b12da4f-7664-433c-9a34-4306c35f1aab_removed.pdf'\n",
    "result = analyze_document(file_path)\n",
    "analyzed_result = analyze_result(result)\n",
    "df_paragraph_spans = create_paragraph_dataframe(analyzed_result['analyzeResult.paragraphs'][0])\n",
    "df_style_spans = create_style_dataframe(analyzed_result['analyzeResult.styles'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61e73ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>is_handwritten</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>4450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>5503</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>True</td>\n",
       "      <td>438</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>2834</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>True</td>\n",
       "      <td>3404</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  confidence is_handwritten offset length\n",
       "0       0.95           True     38      7\n",
       "1        0.5           True   4450      1\n",
       "2        0.4           True    144      1\n",
       "3        1.0           True   2836      1\n",
       "4        0.6           True   5503      2\n",
       "5        0.7           True    438      6\n",
       "6        0.9           True   2834      1\n",
       "7        0.8           True   3404      9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_style_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d8613d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_paragraph_spans, df_style_spans, on=['offset', 'length'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a6c1fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>page_number</th>\n",
       "      <th>polygon</th>\n",
       "      <th>confidence</th>\n",
       "      <th>is_handwritten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>CR 1.03</td>\n",
       "      <td>1</td>\n",
       "      <td>[(2.7774, 0.9142)]</td>\n",
       "      <td>0.95</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[(6.0256, 0.7945)]</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>438</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[(4.877, 1.9385)]</td>\n",
       "      <td>0.7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2834</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>[(1.5363, 10.1567)]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2836</td>\n",
       "      <td>1</td>\n",
       "      <td>Observations</td>\n",
       "      <td>4</td>\n",
       "      <td>[(1.5571, 10.3481)]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5503</td>\n",
       "      <td>2</td>\n",
       "      <td>running Schlumberger \"E\" log</td>\n",
       "      <td>5</td>\n",
       "      <td>[(1.7155, 3.4967)]</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  offset length                       content page_number   \n",
       "0     38      7                       CR 1.03           1  \\\n",
       "1    144      1                             -           1   \n",
       "2    438      6                             7           1   \n",
       "3   2834      1                             -           4   \n",
       "4   2836      1                  Observations           4   \n",
       "5   5503      2  running Schlumberger \"E\" log           5   \n",
       "\n",
       "               polygon confidence is_handwritten  \n",
       "0   [(2.7774, 0.9142)]       0.95           True  \n",
       "1   [(6.0256, 0.7945)]        0.4           True  \n",
       "2    [(4.877, 1.9385)]        0.7           True  \n",
       "3  [(1.5363, 10.1567)]        0.9           True  \n",
       "4  [(1.5571, 10.3481)]        1.0           True  \n",
       "5   [(1.7155, 3.4967)]        0.6           True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = merge_dataframes(df_paragraph_spans, df_style_spans)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3faf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "472d113d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a52a99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-08-31'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.api_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74ca7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27501f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581f94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d914073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b332bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e5c7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at result 2 using the free tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c88a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path2 = '/Users/David.Godinez/Desktop/BJSS/exxon3/exxonmobile/files/7b12da4f-7664-433c-9a34-4306c35f1aab_removed.pdf'\n",
    "result2 = analyze_document(file_path)\n",
    "analyzed_result2 = analyze_result(result)\n",
    "df_paragraph_spans2 = create_paragraph_dataframe(analyzed_result['analyzeResult.paragraphs'][0])\n",
    "df_style_spans2 = create_style_dataframe(analyzed_result['analyzeResult.styles'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8b3378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_paragraph_spans2, df_style_spans2, on=['offset', 'length'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0168f2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>page_number</th>\n",
       "      <th>polygon</th>\n",
       "      <th>confidence</th>\n",
       "      <th>is_handwritten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>CR 1.03</td>\n",
       "      <td>1</td>\n",
       "      <td>[(2.7774, 0.9142)]</td>\n",
       "      <td>0.95</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>[(6.0256, 0.7945)]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>438</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[(4.877, 1.9385)]</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  offset length  content page_number             polygon confidence   \n",
       "0     38      7  CR 1.03           1  [(2.7774, 0.9142)]       0.95  \\\n",
       "1    144      1        -           1  [(6.0256, 0.7945)]        0.5   \n",
       "2    438      6        7           1   [(4.877, 1.9385)]        0.4   \n",
       "\n",
       "  is_handwritten  \n",
       "0           True  \n",
       "1           True  \n",
       "2           True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f09ab8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107421"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(analyzed_result2['analyzeResult.pages'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ba234",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/David.Godinez/Desktop/BJSS/exxon3/exxonmobile/files/7b12da4f-7664-433c-9a34-4306c35f1aab_removed.pdf'\n",
    "process_analyze_result(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5122d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/David.Godinez/Desktop/BJSS/exxon3/exxonmobile/files/7b12da4f-7664-433c-9a34-4306c35f1aab_removed.pdf'\n",
    "b = analyze_document(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c735f141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentParagraph(role=None, content=H012943623 KATALYST DATA MANAGEMENT, bounding_regions=[BoundingRegion(page_number=1, polygon=[Point(x=1.5764, y=0.6653), Point(x=2.7731, y=0.6461), Point(x=2.7774, y=0.9142), Point(x=1.5807, y=0.9334)])], spans=[DocumentSpan(offset=0, length=35)])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.paragraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3205987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentPage(page_number=1, angle=-0.4957999885082245, width=8.5, height=11.0278, unit=inch, lines=[DocumentLine(content=H012943623, polygon=[Point(x=1.5794, y=0.6653), Point(x=2.7663, y=0.6462), Point(x=2.7711, y=0.8376), Point(x=1.5794, y=0.852)], spans=[DocumentSpan(offset=0, length=10)]), DocumentLine(content=KATALYST DATA MANAGEMENT, polygon=[Point(x=1.5842, y=0.8424), Point(x=2.7759, y=0.8233), Point(x=2.7759, y=0.9142), Point(x=1.5842, y=0.9333)], spans=[DocumentSpan(offset=11, length=24)]), DocumentLine(content=-, polygon=[Point(x=6.0974, y=0.7419), Point(x=6.0639, y=0.8137), Point(x=6.0256, y=0.7945), Point(x=6.0639, y=0.7227)], spans=[DocumentSpan(offset=36, length=1)]), DocumentLine(content=CR 1.03, polygon=[Point(x=6.7196, y=1.3354), Point(x=7.7965, y=1.3545), Point(x=7.7917, y=1.5651), Point(x=6.7196, y=1.5412)], spans=[DocumentSpan(offset=38, length=7)]), DocumentLine(content=March 21, 1953, polygon=[Point(x=3.6565, y=1.771), Point(x=4.8722, y=1.747), Point(x=4.877, y=1.9385), Point(x=3.6565, y=1.9672)], spans=[DocumentSpan(offset=46, length=14)]), DocumentLine(content=Fler CR-30 ., polygon=[Point(x=4.9966, y=2.2496), Point(x=6.1213, y=2.2496), Point(x=6.1261, y=2.4267), Point(x=4.9966, y=2.4267)], spans=[DocumentSpan(offset=61, length=12)]), DocumentLine(content=Subject: WELL DATA FROM THESE TESTS, polygon=[Point(x=5.0158, y=2.5942), Point(x=8.0693, y=2.5607), Point(x=8.074, y=2.7378), Point(x=5.0206, y=2.7857)], spans=[DocumentSpan(offset=74, length=35)]), DocumentLine(content=DRILLSD BY UMION CIL 02 CAL., polygon=[Point(x=5.839, y=2.7474), Point(x=8.2272, y=2.7426), Point(x=8.2272, y=2.9005), Point(x=5.839, y=2.9053)], spans=[DocumentSpan(offset=110, length=28)]), DocumentLine(content=MACA, polygon=[Point(x=7.1312, y=2.9436), Point(x=7.4614, y=2.9388), Point(x=7.4566, y=3.0585), Point(x=7.1312, y=3.0728)], spans=[DocumentSpan(offset=139, length=4)]), DocumentLine(content=-, polygon=[Point(x=7.9017, y=3.0106), Point(x=8.2607, y=3.0106), Point(x=8.2607, y=3.1111), Point(x=7.9017, y=3.1111)], spans=[DocumentSpan(offset=144, length=1)]), DocumentLine(content=Mr. K. A. Kright, polygon=[Point(x=1.4693, y=3.6424), Point(x=2.8716, y=3.6376), Point(x=2.8764, y=3.8147), Point(x=1.4693, y=3.8291)], spans=[DocumentSpan(offset=146, length=16)]), DocumentLine(content=Producing Coordination, polygon=[Point(x=1.4693, y=3.7908), Point(x=3.3742, y=3.7908), Point(x=3.3694, y=3.9679), Point(x=1.4693, y=3.9679)], spans=[DocumentSpan(offset=163, length=22)]), DocumentLine(content=30 Rockefeller Plaza, polygon=[Point(x=1.4885, y=3.9823), Point(x=3.2162, y=3.9775), Point(x=3.2162, y=4.1306), Point(x=1.4885, y=4.1402)], spans=[DocumentSpan(offset=186, length=20)]), DocumentLine(content=New York 20, N.Y., polygon=[Point(x=1.4645, y=4.145), Point(x=2.9434, y=4.1402), Point(x=2.9482, y=4.3173), Point(x=1.4645, y=4.3221)], spans=[DocumentSpan(offset=207, length=17)]), DocumentLine(content=bear SEx:, polygon=[Point(x=1.5172, y=4.4752), Point(x=2.2877, y=4.4752), Point(x=2.2877, y=4.6571), Point(x=1.5172, y=4.6619)], spans=[DocumentSpan(offset=225, length=9)]), DocumentLine(content=Tixier separate cover we are sending you well data as Listed in, polygon=[Point(x=2.1633, y=4.8103), Point(x=7.4375, y=4.7576), Point(x=7.4375, y=4.9347), Point(x=2.1633, y=4.9778)], spans=[DocumentSpan(offset=235, length=63)]), DocumentLine(content=an attachment to this letter frea the following tests drilled by Urdon, polygon=[Point(x=1.498, y=4.9922), Point(x=7.4279, y=4.9347), Point(x=7.4327, y=5.1023), Point(x=1.5028, y=5.1501)], spans=[DocumentSpan(offset=299, length=70)]), DocumentLine(content=011 of California in Costa Rica:, polygon=[Point(x=1.4789, y=5.1597), Point(x=4.2117, y=5.1501), Point(x=4.2117, y=5.3033), Point(x=1.4837, y=5.3224)], spans=[DocumentSpan(offset=370, length=32)]), DocumentLine(content=Patiño No. 2, polygon=[Point(x=2.5127, y=5.6575), Point(x=3.5752, y=5.6527), Point(x=3.5752, y=5.8202), Point(x=2.5127, y=5.8202)], spans=[DocumentSpan(offset=403, length=12)]), DocumentLine(content=30,1281, polygon=[Point(x=5.1833, y=5.6431), Point(x=5.7863, y=5.624), Point(x=5.7959, y=5.7819), Point(x=5.1833, y=5.8059)], spans=[DocumentSpan(offset=416, length=7)]), DocumentLine(content=Cocoles Bo. 2, polygon=[Point(x=2.4983, y=5.8346), Point(x=3.6757, y=5.8346), Point(x=3.6757, y=5.9877), Point(x=2.4983, y=5.9877)], spans=[DocumentSpan(offset=424, length=13)]), DocumentLine(content=7,4071, polygon=[Point(x=5.2934, y=5.8059), Point(x=5.8007, y=5.7867), Point(x=5.8007, y=5.9638), Point(x=5.2934, y=5.983)], spans=[DocumentSpan(offset=438, length=6)]), DocumentLine(content=Brie No. L, polygon=[Point(x=2.5127, y=6.0021), Point(x=3.4172, y=5.9925), Point(x=3.4172, y=6.1696), Point(x=2.5127, y=6.1792)], spans=[DocumentSpan(offset=445, length=10)]), DocumentLine(content=7,9691, polygon=[Point(x=5.3029, y=5.9877), Point(x=5.8007, y=5.959), Point(x=5.7959, y=6.1361), Point(x=5.3077, y=6.1553)], spans=[DocumentSpan(offset=456, length=6)]), DocumentLine(content=A guneral summary is attached for each wall., polygon=[Point(x=2.1776, y=6.3515), Point(x=5.9251, y=6.3084), Point(x=5.9299, y=6.4712), Point(x=2.1776, y=6.5238)], spans=[DocumentSpan(offset=463, length=44)]), DocumentLine(content=The material on there Union 011 of California welle in Central, polygon=[Point(x=2.1824, y=6.6818), Point(x=7.4375, y=6.6291), Point(x=7.4423, y=6.7871), Point(x=2.1824, y=6.8445)], spans=[DocumentSpan(offset=508, length=62)]), DocumentLine(content=Acerica ves the result of an e reasont signed on January 16, 1958 botwoon, polygon=[Point(x=1.5076, y=6.8589), Point(x=7.7103, y=6.7966), Point(x=7.7103, y=6.9642), Point(x=1.5076, y=7.0168)], spans=[DocumentSpan(offset=571, length=73)]), DocumentLine(content=Esso Standard 012, 5.A. and Union Oil of Califorde, Union agreed to, polygon=[Point(x=1.5172, y=7.0312), Point(x=7.3753, y=6.9833), Point(x=7.3753, y=7.1317), Point(x=1.5172, y=7.1939)], spans=[DocumentSpan(offset=645, length=67)]), DocumentLine(content=furnish Esso with information on the wells listed above and Baso agreed, polygon=[Point(x=1.5267, y=7.2035), Point(x=7.5284, y=7.1508), Point(x=7.5284, y=7.304), Point(x=1.5267, y=7.3614)], spans=[DocumentSpan(offset=713, length=71)]), DocumentLine(content=to furnish Union with Information from its Balios No. 1 drilled in Cuba, polygon=[Point(x=1.522, y=7.371), Point(x=7.4471, y=7.3136), Point(x=7.4471, y=7.4763), Point(x=1.522, y=7.5337)], spans=[DocumentSpan(offset=785, length=71)]), DocumentLine(content=and roch other vello Laco drills in the Caribbean ares, that in their, polygon=[Point(x=1.5267, y=7.5529), Point(x=7.3801, y=7.4907), Point(x=7.3801, y=7.6486), Point(x=1.5267, y=7.706)], spans=[DocumentSpan(offset=857, length=69)]), DocumentLine(content=opinion the relenen of information is not detrimental to then, The cx-, polygon=[Point(x=1.5267, y=7.7156), Point(x=7.5476, y=7.663), Point(x=7.5476, y=7.8113), Point(x=1.5267, y=7.8784)], spans=[DocumentSpan(offset=927, length=70)]), DocumentLine(content=change includes senples and goneral well infomation such as logs, DSTS,, polygon=[Point(x=1.5363, y=7.8831), Point(x=7.6194, y=7.8305), Point(x=7.6194, y=7.998), Point(x=1.5363, y=8.0507)], spans=[DocumentSpan(offset=998, length=71)]), DocumentLine(content=etc. and is on a foot for foot tasis .., polygon=[Point(x=1.5315, y=8.0554), Point(x=4.719, y=8.0315), Point(x=4.719, y=8.1943), Point(x=1.5315, y=8.223)], spans=[DocumentSpan(offset=1070, length=39)]), DocumentLine(content=Wo have the sons set we are sorting you in our Havana office., polygon=[Point(x=2.1872, y=8.3809), Point(x=7.3561, y=8.3283), Point(x=7.3609, y=8.5006), Point(x=2.1872, y=8.5389)], spans=[DocumentSpan(offset=1110, length=61)]), DocumentLine(content=The purpose of sending you a cot is for security and your use., polygon=[Point(x=1.5267, y=8.5676), Point(x=6.7818, y=8.5245), Point(x=6.7818, y=8.6825), Point(x=1.5267, y=8.7255)], spans=[DocumentSpan(offset=1172, length=62)]), DocumentLine(content=Very truly yours,, polygon=[Point(x=5.1163, y=8.8452), Point(x=6.6813, y=8.8452), Point(x=6.6813, y=9.0271), Point(x=5.1163, y=9.0223)], spans=[DocumentSpan(offset=1235, length=17)]), DocumentLine(content=E250 STANDARD OIL, S.A .., polygon=[Point(x=4.9775, y=9.0941), Point(x=6.9493, y=9.0797), Point(x=6.9541, y=9.276), Point(x=4.9775, y=9.2855)], spans=[DocumentSpan(offset=1253, length=25)]), DocumentLine(content=ORIGINAL, polygon=[Point(x=4.9344, y=9.3286), Point(x=5.5709, y=9.3238), Point(x=5.5709, y=9.477), Point(x=4.9392, y=9.4818)], spans=[DocumentSpan(offset=1279, length=8)]), DocumentLine(content=SIGNED, polygon=[Point(x=4.9248, y=9.477), Point(x=5.3891, y=9.4674), Point(x=5.3939, y=9.5919), Point(x=4.9248, y=9.6014)], spans=[DocumentSpan(offset=1288, length=6)]), DocumentLine(content=-, polygon=[Point(x=5.638, y=9.4004), Point(x=5.6427, y=9.5536), Point(x=5.5709, y=9.5488), Point(x=5.5757, y=9.3956)], spans=[DocumentSpan(offset=1295, length=1)]), DocumentLine(content=--, polygon=[Point(x=6.4994, y=9.6158), Point(x=6.8967, y=9.6206), Point(x=6.8919, y=9.7211), Point(x=6.4994, y=9.7163)], spans=[DocumentSpan(offset=1297, length=2)]), DocumentLine(content=J. Il. Sexpor, polygon=[Point(x=5.3077, y=9.6685), Point(x=6.3894, y=9.678), Point(x=6.3846, y=9.8743), Point(x=5.3077, y=9.8695)], spans=[DocumentSpan(offset=1300, length=13)]), DocumentLine(content=ÅSter, polygon=[Point(x=1.5459, y=9.9891), Point(x=2.0149, y=9.9844), Point(x=2.0149, y=10.1567), Point(x=1.5363, y=10.1567)], spans=[DocumentSpan(offset=1314, length=5)]), DocumentLine(content=Atts., polygon=[Point(x=1.5602, y=10.3481), Point(x=2.0006, y=10.3577), Point(x=2.0006, y=10.5013), Point(x=1.5555, y=10.4965)], spans=[DocumentSpan(offset=1320, length=5)])], words=[DocumentWord(content=H012943623, polygon=[Point(x=1.5842, y=0.6701), Point(x=2.7376, y=0.6462), Point(x=2.7472, y=0.8376), Point(x=1.5842, y=0.852)], span=DocumentSpan(offset=0, length=10), confidence=0.984), DocumentWord(content=KATALYST, polygon=[Point(x=1.5842, y=0.8472), Point(x=1.9862, y=0.8376), Point(x=1.9862, y=0.9333), Point(x=1.5842, y=0.9381)], span=DocumentSpan(offset=11, length=8), confidence=0.993), DocumentWord(content=DATA, polygon=[Point(x=2.0197, y=0.8376), Point(x=2.2255, y=0.8376), Point(x=2.2255, y=0.9286), Point(x=2.0197, y=0.9286)], span=DocumentSpan(offset=20, length=4), confidence=0.985), DocumentWord(content=MANAGEMENT, polygon=[Point(x=2.2686, y=0.8328), Point(x=2.7759, y=0.828), Point(x=2.7759, y=0.919), Point(x=2.2686, y=0.9286)], span=DocumentSpan(offset=25, length=10), confidence=0.937), DocumentWord(content=-, polygon=[Point(x=6.1022, y=0.7419), Point(x=6.0926, y=0.7658), Point(x=6.0543, y=0.7467), Point(x=6.0639, y=0.7227)], span=DocumentSpan(offset=36, length=1), confidence=0.958), DocumentWord(content=CR, polygon=[Point(x=6.8345, y=1.3402), Point(x=7.1264, y=1.345), Point(x=7.1312, y=1.546), Point(x=6.844, y=1.5412)], span=DocumentSpan(offset=38, length=2), confidence=0.757), DocumentWord(content=1.03, polygon=[Point(x=7.2078, y=1.3498), Point(x=7.7917, y=1.3545), Point(x=7.7869, y=1.5699), Point(x=7.2126, y=1.546)], span=DocumentSpan(offset=41, length=4), confidence=0.949), DocumentWord(content=March, polygon=[Point(x=3.6661, y=1.7757), Point(x=4.1016, y=1.771), Point(x=4.0968, y=1.9624), Point(x=3.6613, y=1.9672)], span=DocumentSpan(offset=46, length=5), confidence=0.622), DocumentWord(content=21,, polygon=[Point(x=4.1543, y=1.771), Point(x=4.4414, y=1.7614), Point(x=4.4462, y=1.9528), Point(x=4.1495, y=1.9624)], span=DocumentSpan(offset=52, length=3), confidence=0.997), DocumentWord(content=1953, polygon=[Point(x=4.4797, y=1.7614), Point(x=4.8674, y=1.7518), Point(x=4.8722, y=1.9433), Point(x=4.4797, y=1.9528)], span=DocumentSpan(offset=56, length=4), confidence=0.916), DocumentWord(content=Fler, polygon=[Point(x=5.0014, y=2.2496), Point(x=5.4513, y=2.2592), Point(x=5.4609, y=2.4315), Point(x=5.0062, y=2.4315)], span=DocumentSpan(offset=61, length=4), confidence=0.57), DocumentWord(content=CR-30, polygon=[Point(x=5.5709, y=2.2592), Point(x=6.0256, y=2.2544), Point(x=6.0352, y=2.4219), Point(x=5.5757, y=2.4315)], span=DocumentSpan(offset=66, length=5), confidence=0.846), DocumentWord(content=., polygon=[Point(x=6.0591, y=2.2544), Point(x=6.1213, y=2.2496), Point(x=6.1309, y=2.4219), Point(x=6.0687, y=2.4219)], span=DocumentSpan(offset=72, length=1), confidence=0.269), DocumentWord(content=Subject:, polygon=[Point(x=5.0206, y=2.6038), Point(x=5.7097, y=2.5894), Point(x=5.7097, y=2.7665), Point(x=5.0253, y=2.7904)], span=DocumentSpan(offset=74, length=8), confidence=0.848), DocumentWord(content=WELL, polygon=[Point(x=5.8246, y=2.5846), Point(x=6.2123, y=2.5798), Point(x=6.2123, y=2.7522), Point(x=5.8294, y=2.7617)], span=DocumentSpan(offset=83, length=4), confidence=0.971), DocumentWord(content=DATA, polygon=[Point(x=6.2601, y=2.5798), Point(x=6.6191, y=2.5751), Point(x=6.6239, y=2.7426), Point(x=6.2601, y=2.7474)], span=DocumentSpan(offset=88, length=4), confidence=0.847), DocumentWord(content=FROM, polygon=[Point(x=6.6813, y=2.5703), Point(x=7.0403, y=2.5703), Point(x=7.045, y=2.7378), Point(x=6.6813, y=2.7426)], span=DocumentSpan(offset=93, length=4), confidence=0.489), DocumentWord(content=THESE, polygon=[Point(x=7.1025, y=2.5655), Point(x=7.5524, y=2.5655), Point(x=7.5572, y=2.733), Point(x=7.1025, y=2.7378)], span=DocumentSpan(offset=98, length=5), confidence=0.318), DocumentWord(content=TESTS, polygon=[Point(x=7.6146, y=2.5655), Point(x=8.0645, y=2.5655), Point(x=8.0693, y=2.733), Point(x=7.6146, y=2.733)], span=DocumentSpan(offset=104, length=5), confidence=0.609), DocumentWord(content=DRILLSD, polygon=[Point(x=5.8485, y=2.7569), Point(x=6.4372, y=2.7522), Point(x=6.4324, y=2.9053), Point(x=5.8438, y=2.9005)], span=DocumentSpan(offset=110, length=7), confidence=0.542), DocumentWord(content=BY, polygon=[Point(x=6.5138, y=2.7522), Point(x=6.7052, y=2.7474), Point(x=6.7005, y=2.9053), Point(x=6.509, y=2.9053)], span=DocumentSpan(offset=118, length=2), confidence=0.607), DocumentWord(content=UMION, polygon=[Point(x=6.7579, y=2.7474), Point(x=7.1982, y=2.7474), Point(x=7.1934, y=2.9053), Point(x=6.7531, y=2.9053)], span=DocumentSpan(offset=121, length=5), confidence=0.628), DocumentWord(content=CIL, polygon=[Point(x=7.2604, y=2.7474), Point(x=7.5476, y=2.7426), Point(x=7.5428, y=2.9053), Point(x=7.2556, y=2.9053)], span=DocumentSpan(offset=127, length=3), confidence=0.963), DocumentWord(content=02, polygon=[Point(x=7.6098, y=2.7426), Point(x=7.7917, y=2.7426), Point(x=7.7869, y=2.9053), Point(x=7.605, y=2.9053)], span=DocumentSpan(offset=131, length=2), confidence=0.666), DocumentWord(content=CAL., polygon=[Point(x=7.8587, y=2.7426), Point(x=8.2272, y=2.7426), Point(x=8.2224, y=2.9005), Point(x=7.8491, y=2.9053)], span=DocumentSpan(offset=134, length=4), confidence=0.703), DocumentWord(content=MACA, polygon=[Point(x=7.136, y=2.9436), Point(x=7.4423, y=2.9388), Point(x=7.4471, y=3.0633), Point(x=7.136, y=3.0728)], span=DocumentSpan(offset=139, length=4), confidence=0.155), DocumentWord(content=-, polygon=[Point(x=7.9065, y=3.0154), Point(x=7.9688, y=3.0154), Point(x=7.964, y=3.1111), Point(x=7.9065, y=3.1111)], span=DocumentSpan(offset=144, length=1), confidence=0.34), DocumentWord(content=Mr., polygon=[Point(x=1.4741, y=3.6424), Point(x=1.7565, y=3.6424), Point(x=1.7517, y=3.8243), Point(x=1.4741, y=3.8339)], span=DocumentSpan(offset=146, length=3), confidence=0.632), DocumentWord(content=K., polygon=[Point(x=1.79, y=3.6424), Point(x=2.0149, y=3.6424), Point(x=2.0149, y=3.8195), Point(x=1.79, y=3.8243)], span=DocumentSpan(offset=150, length=2), confidence=0.14), DocumentWord(content=A., polygon=[Point(x=2.0484, y=3.6424), Point(x=2.2638, y=3.6424), Point(x=2.2638, y=3.8195), Point(x=2.0484, y=3.8195)], span=DocumentSpan(offset=153, length=2), confidence=0.957), DocumentWord(content=Kright, polygon=[Point(x=2.2973, y=3.6376), Point(x=2.862, y=3.6376), Point(x=2.862, y=3.8147), Point(x=2.2973, y=3.8147)], span=DocumentSpan(offset=156, length=6), confidence=0.625), DocumentWord(content=Producing, polygon=[Point(x=1.498, y=3.7956), Point(x=2.2782, y=3.8147), Point(x=2.2829, y=3.9631), Point(x=1.5076, y=3.9727)], span=DocumentSpan(offset=163, length=9), confidence=0.725), DocumentWord(content=Coordination, polygon=[Point(x=2.3452, y=3.8147), Point(x=3.3789, y=3.8052), Point(x=3.3742, y=3.9631), Point(x=2.3499, y=3.9631)], span=DocumentSpan(offset=173, length=12), confidence=0.243), DocumentWord(content=30, polygon=[Point(x=1.498, y=3.987), Point(x=1.6751, y=3.9823), Point(x=1.6751, y=4.145), Point(x=1.498, y=4.145)], span=DocumentSpan(offset=186, length=2), confidence=0.78), DocumentWord(content=Rockefeller, polygon=[Point(x=1.7278, y=3.9823), Point(x=2.685, y=3.9823), Point(x=2.6802, y=4.1306), Point(x=1.7278, y=4.145)], span=DocumentSpan(offset=189, length=11), confidence=0.286), DocumentWord(content=Plaza, polygon=[Point(x=2.7472, y=3.9823), Point(x=3.1923, y=3.987), Point(x=3.1923, y=4.1211), Point(x=2.7424, y=4.1306)], span=DocumentSpan(offset=201, length=5), confidence=0.076), DocumentWord(content=New, polygon=[Point(x=1.4741, y=4.1593), Point(x=1.7565, y=4.1593), Point(x=1.7565, y=4.3173), Point(x=1.4741, y=4.3173)], span=DocumentSpan(offset=207, length=3), confidence=0.291), DocumentWord(content=York, polygon=[Point(x=1.8139, y=4.1593), Point(x=2.1776, y=4.1546), Point(x=2.1776, y=4.3173), Point(x=1.8139, y=4.3173)], span=DocumentSpan(offset=211, length=4), confidence=0.144), DocumentWord(content=20,, polygon=[Point(x=2.2351, y=4.1546), Point(x=2.527, y=4.1498), Point(x=2.527, y=4.3173), Point(x=2.2351, y=4.3173)], span=DocumentSpan(offset=216, length=3), confidence=0.997), DocumentWord(content=N.Y., polygon=[Point(x=2.5749, y=4.1498), Point(x=2.9482, y=4.145), Point(x=2.9434, y=4.3221), Point(x=2.5701, y=4.3221)], span=DocumentSpan(offset=220, length=4), confidence=0.855), DocumentWord(content=bear, polygon=[Point(x=1.5172, y=4.4848), Point(x=1.8666, y=4.48), Point(x=1.8666, y=4.6619), Point(x=1.5172, y=4.6619)], span=DocumentSpan(offset=225, length=4), confidence=0.78), DocumentWord(content=SEx:, polygon=[Point(x=1.9001, y=4.48), Point(x=2.2734, y=4.4752), Point(x=2.2829, y=4.6619), Point(x=1.9048, y=4.6619)], span=DocumentSpan(offset=230, length=4), confidence=0.065), DocumentWord(content=Tixier, polygon=[Point(x=2.1681, y=4.8199), Point(x=2.6036, y=4.8199), Point(x=2.6036, y=4.9778), Point(x=2.1681, y=4.9778)], span=DocumentSpan(offset=235, length=6), confidence=0.179), DocumentWord(content=separate, polygon=[Point(x=2.6706, y=4.8199), Point(x=3.3646, y=4.8151), Point(x=3.3646, y=4.973), Point(x=2.6706, y=4.9778)], span=DocumentSpan(offset=242, length=8), confidence=0.306), DocumentWord(content=cover, polygon=[Point(x=3.4316, y=4.8151), Point(x=3.8671, y=4.8103), Point(x=3.8671, y=4.973), Point(x=3.4316, y=4.973)], span=DocumentSpan(offset=251, length=5), confidence=0.975), DocumentWord(content=we, polygon=[Point(x=3.9245, y=4.8103), Point(x=4.1399, y=4.8103), Point(x=4.1351, y=4.9682), Point(x=3.9245, y=4.973)], span=DocumentSpan(offset=257, length=2), confidence=0.292), DocumentWord(content=are, polygon=[Point(x=4.183, y=4.8103), Point(x=4.4606, y=4.8055), Point(x=4.4606, y=4.9682), Point(x=4.183, y=4.9682)], span=DocumentSpan(offset=260, length=3), confidence=0.612), DocumentWord(content=sending, polygon=[Point(x=4.5276, y=4.8055), Point(x=5.1354, y=4.8007), Point(x=5.1354, y=4.9635), Point(x=4.5276, y=4.9682)], span=DocumentSpan(offset=264, length=7), confidence=0.637), DocumentWord(content=you, polygon=[Point(x=5.1928, y=4.7959), Point(x=5.4704, y=4.7959), Point(x=5.4704, y=4.9587), Point(x=5.1928, y=4.9635)], span=DocumentSpan(offset=272, length=3), confidence=0.997), DocumentWord(content=well, polygon=[Point(x=5.5279, y=4.7911), Point(x=5.9012, y=4.7864), Point(x=5.8964, y=4.9539), Point(x=5.5231, y=4.9587)], span=DocumentSpan(offset=276, length=4), confidence=0.827), DocumentWord(content=data, polygon=[Point(x=5.9443, y=4.7864), Point(x=6.308, y=4.7816), Point(x=6.308, y=4.9491), Point(x=5.9443, y=4.9539)], span=DocumentSpan(offset=281, length=4), confidence=0.693), DocumentWord(content=as, polygon=[Point(x=6.375, y=4.7768), Point(x=6.5664, y=4.7768), Point(x=6.5617, y=4.9443), Point(x=6.375, y=4.9491)], span=DocumentSpan(offset=286, length=2), confidence=0.617), DocumentWord(content=Listed, polygon=[Point(x=6.6334, y=4.7768), Point(x=7.1551, y=4.7624), Point(x=7.1551, y=4.9347), Point(x=6.6287, y=4.9443)], span=DocumentSpan(offset=289, length=6), confidence=0.834), DocumentWord(content=in, polygon=[Point(x=7.2126, y=4.7624), Point(x=7.404, y=4.7576), Point(x=7.3992, y=4.9347), Point(x=7.2126, y=4.9347)], span=DocumentSpan(offset=296, length=2), confidence=0.969), DocumentWord(content=an, polygon=[Point(x=1.5028, y=5.0113), Point(x=1.6751, y=5.0065), Point(x=1.6799, y=5.1501), Point(x=1.5076, y=5.1501)], span=DocumentSpan(offset=299, length=2), confidence=0.906), DocumentWord(content=attachment, polygon=[Point(x=1.7373, y=5.0065), Point(x=2.6132, y=4.9922), Point(x=2.618, y=5.1453), Point(x=1.7421, y=5.1501)], span=DocumentSpan(offset=302, length=10), confidence=0.276), DocumentWord(content=to, polygon=[Point(x=2.6802, y=4.9922), Point(x=2.8525, y=4.9922), Point(x=2.8573, y=5.1453), Point(x=2.6802, y=5.1453)], span=DocumentSpan(offset=313, length=2), confidence=0.997), DocumentWord(content=this, polygon=[Point(x=2.9291, y=4.9922), Point(x=3.2832, y=4.9874), Point(x=3.2832, y=5.1406), Point(x=2.9338, y=5.1453)], span=DocumentSpan(offset=316, length=4), confidence=0.631), DocumentWord(content=letter, polygon=[Point(x=3.3359, y=4.9826), Point(x=3.8671, y=4.9778), Point(x=3.8671, y=5.1358), Point(x=3.3407, y=5.1406)], span=DocumentSpan(offset=321, length=6), confidence=0.603), DocumentWord(content=frea, polygon=[Point(x=3.9437, y=4.9778), Point(x=4.2835, y=4.973), Point(x=4.2835, y=5.1358), Point(x=3.9437, y=5.1358)], span=DocumentSpan(offset=328, length=4), confidence=0.647), DocumentWord(content=the, polygon=[Point(x=4.3601, y=4.973), Point(x=4.6281, y=4.9682), Point(x=4.6281, y=5.131), Point(x=4.3601, y=5.131)], span=DocumentSpan(offset=333, length=3), confidence=0.997), DocumentWord(content=following, polygon=[Point(x=4.6951, y=4.9682), Point(x=5.4752, y=4.9587), Point(x=5.4752, y=5.1262), Point(x=4.6951, y=5.131)], span=DocumentSpan(offset=337, length=9), confidence=0.244), DocumentWord(content=tests, polygon=[Point(x=5.5422, y=4.9587), Point(x=5.9778, y=4.9539), Point(x=5.973, y=5.1214), Point(x=5.5422, y=5.1262)], span=DocumentSpan(offset=347, length=5), confidence=0.657), DocumentWord(content=drilled, polygon=[Point(x=6.0448, y=4.9539), Point(x=6.6574, y=4.9443), Point(x=6.6526, y=5.1166), Point(x=6.04, y=5.1214)], span=DocumentSpan(offset=353, length=7), confidence=0.617), DocumentWord(content=by, polygon=[Point(x=6.71, y=4.9443), Point(x=6.9062, y=4.9443), Point(x=6.9015, y=5.1118), Point(x=6.71, y=5.1118)], span=DocumentSpan(offset=361, length=2), confidence=0.997), DocumentWord(content=Urdon, polygon=[Point(x=6.9541, y=4.9443), Point(x=7.3992, y=4.9395), Point(x=7.3944, y=5.107), Point(x=6.9493, y=5.1118)], span=DocumentSpan(offset=364, length=5), confidence=0.804), DocumentWord(content=011, polygon=[Point(x=1.4885, y=5.1645), Point(x=1.7613, y=5.1597), Point(x=1.766, y=5.3224), Point(x=1.4932, y=5.3272)], span=DocumentSpan(offset=370, length=3), confidence=0.37), DocumentWord(content=of, polygon=[Point(x=1.8283, y=5.1597), Point(x=2.0197, y=5.1597), Point(x=2.0197, y=5.3224), Point(x=1.8331, y=5.3224)], span=DocumentSpan(offset=374, length=2), confidence=0.991), DocumentWord(content=California, polygon=[Point(x=2.0724, y=5.1597), Point(x=2.9386, y=5.1549), Point(x=2.9434, y=5.3176), Point(x=2.0771, y=5.3224)], span=DocumentSpan(offset=377, length=10), confidence=0.606), DocumentWord(content=in, polygon=[Point(x=3.0056, y=5.1549), Point(x=3.1923, y=5.1501), Point(x=3.1971, y=5.3129), Point(x=3.0056, y=5.3176)], span=DocumentSpan(offset=388, length=2), confidence=0.996), DocumentWord(content=Costa, polygon=[Point(x=3.2497, y=5.1501), Point(x=3.7044, y=5.1501), Point(x=3.7044, y=5.3081), Point(x=3.2497, y=5.3129)], span=DocumentSpan(offset=391, length=5), confidence=0.654), DocumentWord(content=Rica:, polygon=[Point(x=3.757, y=5.1501), Point(x=4.2069, y=5.1501), Point(x=4.2021, y=5.3081), Point(x=3.757, y=5.3081)], span=DocumentSpan(offset=397, length=5), confidence=0.226), DocumentWord(content=Patiño, polygon=[Point(x=2.5175, y=5.6575), Point(x=3.0439, y=5.6671), Point(x=3.0439, y=5.825), Point(x=2.5175, y=5.8202)], span=DocumentSpan(offset=403, length=6), confidence=0.603), DocumentWord(content=No., polygon=[Point(x=3.0774, y=5.6671), Point(x=3.3789, y=5.6623), Point(x=3.3789, y=5.825), Point(x=3.0774, y=5.825)], span=DocumentSpan(offset=410, length=3), confidence=0.931), DocumentWord(content=2, polygon=[Point(x=3.4316, y=5.6623), Point(x=3.5225, y=5.6575), Point(x=3.5273, y=5.8202), Point(x=3.4364, y=5.8202)], span=DocumentSpan(offset=414, length=1), confidence=0.995), DocumentWord(content=30,1281, polygon=[Point(x=5.1928, y=5.6431), Point(x=5.7911, y=5.624), Point(x=5.7959, y=5.7724), Point(x=5.1928, y=5.8059)], span=DocumentSpan(offset=416, length=7), confidence=0.624), DocumentWord(content=Cocoles, polygon=[Point(x=2.5031, y=5.8394), Point(x=3.1109, y=5.8346), Point(x=3.1061, y=5.9877), Point(x=2.4983, y=5.9925)], span=DocumentSpan(offset=424, length=7), confidence=0.594), DocumentWord(content=Bo., polygon=[Point(x=3.1731, y=5.8346), Point(x=3.4651, y=5.8346), Point(x=3.4603, y=5.9877), Point(x=3.1684, y=5.9877)], span=DocumentSpan(offset=432, length=3), confidence=0.702), DocumentWord(content=2, polygon=[Point(x=3.5273, y=5.8346), Point(x=3.6182, y=5.8346), Point(x=3.6087, y=5.9925), Point(x=3.5225, y=5.9925)], span=DocumentSpan(offset=436, length=1), confidence=0.995), DocumentWord(content=7,4071, polygon=[Point(x=5.2934, y=5.8059), Point(x=5.7911, y=5.7867), Point(x=5.7959, y=5.959), Point(x=5.2981, y=5.9782)], span=DocumentSpan(offset=438, length=6), confidence=0.647), DocumentWord(content=Brie, polygon=[Point(x=2.5127, y=6.0069), Point(x=2.8764, y=6.0021), Point(x=2.8764, y=6.1744), Point(x=2.5127, y=6.1792)], span=DocumentSpan(offset=445, length=4), confidence=0.647), DocumentWord(content=No., polygon=[Point(x=2.9147, y=6.0021), Point(x=3.221, y=5.9973), Point(x=3.2258, y=6.1744), Point(x=2.9147, y=6.1744)], span=DocumentSpan(offset=450, length=3), confidence=0.297), DocumentWord(content=L, polygon=[Point(x=3.2593, y=5.9973), Point(x=3.3598, y=5.9973), Point(x=3.3646, y=6.1744), Point(x=3.2593, y=6.1744)], span=DocumentSpan(offset=454, length=1), confidence=0.662), DocumentWord(content=7,9691, polygon=[Point(x=5.3077, y=5.983), Point(x=5.7911, y=5.959), Point(x=5.8007, y=6.1313), Point(x=5.3173, y=6.1553)], span=DocumentSpan(offset=456, length=6), confidence=0.618), DocumentWord(content=A, polygon=[Point(x=2.1824, y=6.3563), Point(x=2.2782, y=6.3515), Point(x=2.2782, y=6.5238), Point(x=2.1824, y=6.5238)], span=DocumentSpan(offset=463, length=1), confidence=0.926), DocumentWord(content=guneral, polygon=[Point(x=2.3452, y=6.3515), Point(x=2.9626, y=6.3419), Point(x=2.9626, y=6.519), Point(x=2.3452, y=6.5238)], span=DocumentSpan(offset=465, length=7), confidence=0.886), DocumentWord(content=summary, polygon=[Point(x=3.02, y=6.3419), Point(x=3.647, y=6.3324), Point(x=3.647, y=6.5095), Point(x=3.02, y=6.5142)], span=DocumentSpan(offset=473, length=7), confidence=0.297), DocumentWord(content=is, polygon=[Point(x=3.6948, y=6.3324), Point(x=3.891, y=6.3324), Point(x=3.8958, y=6.5047), Point(x=3.6948, y=6.5095)], span=DocumentSpan(offset=481, length=2), confidence=0.933), DocumentWord(content=attached, polygon=[Point(x=3.9389, y=6.3324), Point(x=4.6472, y=6.3228), Point(x=4.6472, y=6.4951), Point(x=3.9389, y=6.5047)], span=DocumentSpan(offset=484, length=8), confidence=0.468), DocumentWord(content=for, polygon=[Point(x=4.7047, y=6.3228), Point(x=4.9918, y=6.318), Point(x=4.9966, y=6.4903), Point(x=4.7047, y=6.4951)], span=DocumentSpan(offset=493, length=3), confidence=0.893), DocumentWord(content=each, polygon=[Point(x=5.0397, y=6.318), Point(x=5.3986, y=6.3132), Point(x=5.3986, y=6.4807), Point(x=5.0397, y=6.4903)], span=DocumentSpan(offset=497, length=4), confidence=0.641), DocumentWord(content=wall., polygon=[Point(x=5.4561, y=6.3132), Point(x=5.9155, y=6.3084), Point(x=5.9155, y=6.4759), Point(x=5.4561, y=6.4807)], span=DocumentSpan(offset=502, length=5), confidence=0.669), DocumentWord(content=The, polygon=[Point(x=2.192, y=6.6961), Point(x=2.4648, y=6.6913), Point(x=2.4648, y=6.8445), Point(x=2.192, y=6.8445)], span=DocumentSpan(offset=508, length=3), confidence=0.993), DocumentWord(content=material, polygon=[Point(x=2.5079, y=6.6913), Point(x=3.221, y=6.677), Point(x=3.221, y=6.8397), Point(x=2.5079, y=6.8445)], span=DocumentSpan(offset=512, length=8), confidence=0.729), DocumentWord(content=on, polygon=[Point(x=3.2784, y=6.677), Point(x=3.4651, y=6.6722), Point(x=3.4651, y=6.8349), Point(x=3.2784, y=6.8349)], span=DocumentSpan(offset=521, length=2), confidence=0.991), DocumentWord(content=there, polygon=[Point(x=3.5417, y=6.6722), Point(x=3.9772, y=6.6674), Point(x=3.9772, y=6.8301), Point(x=3.5417, y=6.8349)], span=DocumentSpan(offset=524, length=5), confidence=0.603), DocumentWord(content=Union, polygon=[Point(x=4.0203, y=6.6674), Point(x=4.4749, y=6.6578), Point(x=4.4749, y=6.8254), Point(x=4.0203, y=6.8301)], span=DocumentSpan(offset=530, length=5), confidence=0.881), DocumentWord(content=011, polygon=[Point(x=4.5324, y=6.6578), Point(x=4.8148, y=6.653), Point(x=4.8148, y=6.8206), Point(x=4.5324, y=6.8254)], span=DocumentSpan(offset=536, length=3), confidence=0.123), DocumentWord(content=of, polygon=[Point(x=4.8722, y=6.653), Point(x=5.0732, y=6.653), Point(x=5.0732, y=6.8206), Point(x=4.8722, y=6.8206)], span=DocumentSpan(offset=540, length=2), confidence=0.991), DocumentWord(content=California, polygon=[Point(x=5.1163, y=6.653), Point(x=5.9873, y=6.6435), Point(x=5.9873, y=6.811), Point(x=5.1163, y=6.8206)], span=DocumentSpan(offset=543, length=10), confidence=0.63), DocumentWord(content=welle, polygon=[Point(x=6.0543, y=6.6435), Point(x=6.4994, y=6.6387), Point(x=6.4994, y=6.8014), Point(x=6.0543, y=6.8062)], span=DocumentSpan(offset=554, length=5), confidence=0.657), DocumentWord(content=in, polygon=[Point(x=6.5664, y=6.6387), Point(x=6.7435, y=6.6339), Point(x=6.7435, y=6.8014), Point(x=6.5664, y=6.8014)], span=DocumentSpan(offset=560, length=2), confidence=0.997), DocumentWord(content=Central, polygon=[Point(x=6.801, y=6.6339), Point(x=7.4231, y=6.6291), Point(x=7.4231, y=6.7918), Point(x=6.801, y=6.8014)], span=DocumentSpan(offset=563, length=7), confidence=0.836), DocumentWord(content=Acerica, polygon=[Point(x=1.5076, y=6.8684), Point(x=2.1202, y=6.8589), Point(x=2.1202, y=7.012), Point(x=1.5076, y=7.0168)], span=DocumentSpan(offset=571, length=7), confidence=0.728), DocumentWord(content=ves, polygon=[Point(x=2.1872, y=6.8589), Point(x=2.4552, y=6.8589), Point(x=2.4552, y=7.012), Point(x=2.1872, y=7.012)], span=DocumentSpan(offset=579, length=3), confidence=0.153), DocumentWord(content=the, polygon=[Point(x=2.5318, y=6.8589), Point(x=2.7903, y=6.8541), Point(x=2.7903, y=7.012), Point(x=2.5318, y=7.012)], span=DocumentSpan(offset=583, length=3), confidence=0.853), DocumentWord(content=result, polygon=[Point(x=2.8573, y=6.8541), Point(x=3.3789, y=6.8493), Point(x=3.3789, y=7.0072), Point(x=2.8573, y=7.012)], span=DocumentSpan(offset=587, length=6), confidence=0.436), DocumentWord(content=of, polygon=[Point(x=3.4412, y=6.8493), Point(x=3.6374, y=6.8445), Point(x=3.6374, y=7.0072), Point(x=3.4412, y=7.0072)], span=DocumentSpan(offset=594, length=2), confidence=0.251), DocumentWord(content=an, polygon=[Point(x=3.7044, y=6.8445), Point(x=3.891, y=6.8445), Point(x=3.891, y=7.0024), Point(x=3.7044, y=7.0072)], span=DocumentSpan(offset=597, length=2), confidence=0.996), DocumentWord(content=e, polygon=[Point(x=3.9437, y=6.8445), Point(x=4.0346, y=6.8397), Point(x=4.0346, y=7.0024), Point(x=3.9437, y=7.0024)], span=DocumentSpan(offset=600, length=1), confidence=0.67), DocumentWord(content=reasont, polygon=[Point(x=4.1447, y=6.8397), Point(x=4.7382, y=6.8349), Point(x=4.7382, y=6.9977), Point(x=4.1447, y=7.0024)], span=DocumentSpan(offset=602, length=7), confidence=0.605), DocumentWord(content=signed, polygon=[Point(x=4.7908, y=6.8349), Point(x=5.3125, y=6.8301), Point(x=5.3125, y=6.9929), Point(x=4.7908, y=6.9977)], span=DocumentSpan(offset=610, length=6), confidence=0.454), DocumentWord(content=on, polygon=[Point(x=5.3795, y=6.8254), Point(x=5.5662, y=6.8254), Point(x=5.5614, y=6.9881), Point(x=5.3795, y=6.9881)], span=DocumentSpan(offset=617, length=2), confidence=0.994), DocumentWord(content=January, polygon=[Point(x=5.6188, y=6.8254), Point(x=6.2458, y=6.8158), Point(x=6.241, y=6.9785), Point(x=5.6188, y=6.9881)], span=DocumentSpan(offset=620, length=7), confidence=0.63), DocumentWord(content=16,, polygon=[Point(x=6.2984, y=6.8158), Point(x=6.5904, y=6.811), Point(x=6.5904, y=6.9785), Point(x=6.2984, y=6.9785)], span=DocumentSpan(offset=628, length=3), confidence=0.964), DocumentWord(content=1958, polygon=[Point(x=6.6334, y=6.811), Point(x=6.9876, y=6.8062), Point(x=6.9876, y=6.9689), Point(x=6.6334, y=6.9737)], span=DocumentSpan(offset=632, length=4), confidence=0.991), DocumentWord(content=botwoon, polygon=[Point(x=7.0546, y=6.8062), Point(x=7.6672, y=6.7966), Point(x=7.6672, y=6.9594), Point(x=7.0498, y=6.9689)], span=DocumentSpan(offset=637, length=7), confidence=0.578), DocumentWord(content=Esso, polygon=[Point(x=1.522, y=7.0407), Point(x=1.8809, y=7.036), Point(x=1.8761, y=7.1891), Point(x=1.522, y=7.1939)], span=DocumentSpan(offset=645, length=4), confidence=0.642), DocumentWord(content=Standard, polygon=[Point(x=1.9336, y=7.036), Point(x=2.6323, y=7.0264), Point(x=2.6323, y=7.1843), Point(x=1.9336, y=7.1891)], span=DocumentSpan(offset=650, length=8), confidence=0.993), DocumentWord(content=012,, polygon=[Point(x=2.685, y=7.0264), Point(x=3.0678, y=7.0216), Point(x=3.0631, y=7.1795), Point(x=2.685, y=7.1843)], span=DocumentSpan(offset=659, length=4), confidence=0.307), DocumentWord(content=5.A., polygon=[Point(x=3.1014, y=7.0216), Point(x=3.4794, y=7.0168), Point(x=3.4794, y=7.1795), Point(x=3.0966, y=7.1795)], span=DocumentSpan(offset=664, length=4), confidence=0.601), DocumentWord(content=and, polygon=[Point(x=3.5321, y=7.0168), Point(x=3.8097, y=7.012), Point(x=3.8097, y=7.1748), Point(x=3.5321, y=7.1748)], span=DocumentSpan(offset=669, length=3), confidence=0.95), DocumentWord(content=Union, polygon=[Point(x=3.8623, y=7.012), Point(x=4.3074, y=7.0072), Point(x=4.3026, y=7.17), Point(x=3.8623, y=7.1748)], span=DocumentSpan(offset=673, length=5), confidence=0.94), DocumentWord(content=Oil, polygon=[Point(x=4.3697, y=7.0072), Point(x=4.6472, y=7.0024), Point(x=4.6472, y=7.1652), Point(x=4.3697, y=7.17)], span=DocumentSpan(offset=679, length=3), confidence=0.605), DocumentWord(content=of, polygon=[Point(x=4.7095, y=7.0024), Point(x=4.9057, y=7.0024), Point(x=4.9057, y=7.1652), Point(x=4.7095, y=7.1652)], span=DocumentSpan(offset=683, length=2), confidence=0.955), DocumentWord(content=Califorde,, polygon=[Point(x=4.9583, y=7.0024), Point(x=5.9155, y=6.9929), Point(x=5.9155, y=7.1508), Point(x=4.9583, y=7.1604)], span=DocumentSpan(offset=686, length=10), confidence=0.536), DocumentWord(content=Union, polygon=[Point(x=6.0543, y=6.9929), Point(x=6.4947, y=6.9881), Point(x=6.4947, y=7.146), Point(x=6.0543, y=7.1508)], span=DocumentSpan(offset=697, length=5), confidence=0.849), DocumentWord(content=agreed, polygon=[Point(x=6.5712, y=6.9881), Point(x=7.0929, y=6.9881), Point(x=7.0929, y=7.1365), Point(x=6.5712, y=7.1413)], span=DocumentSpan(offset=703, length=6), confidence=0.303), DocumentWord(content=to, polygon=[Point(x=7.1599, y=6.9881), Point(x=7.3418, y=6.9833), Point(x=7.3418, y=7.1317), Point(x=7.1599, y=7.1365)], span=DocumentSpan(offset=710, length=2), confidence=0.866), DocumentWord(content=furnish, polygon=[Point(x=1.5363, y=7.2083), Point(x=2.125, y=7.1987), Point(x=2.1202, y=7.3566), Point(x=1.5267, y=7.3614)], span=DocumentSpan(offset=713, length=7), confidence=0.62), DocumentWord(content=Esso, polygon=[Point(x=2.1824, y=7.1987), Point(x=2.551, y=7.1987), Point(x=2.5414, y=7.3566), Point(x=2.1729, y=7.3566)], span=DocumentSpan(offset=721, length=4), confidence=0.587), DocumentWord(content=with, polygon=[Point(x=2.6132, y=7.1939), Point(x=2.9721, y=7.1939), Point(x=2.9673, y=7.3519), Point(x=2.6084, y=7.3519)], span=DocumentSpan(offset=726, length=4), confidence=0.944), DocumentWord(content=information, polygon=[Point(x=3.0343, y=7.1939), Point(x=3.9676, y=7.1843), Point(x=3.9676, y=7.3423), Point(x=3.0296, y=7.3519)], span=DocumentSpan(offset=731, length=11), confidence=0.097), DocumentWord(content=on, polygon=[Point(x=4.0442, y=7.1795), Point(x=4.2261, y=7.1795), Point(x=4.2261, y=7.3423), Point(x=4.0394, y=7.3423)], span=DocumentSpan(offset=743, length=2), confidence=0.907), DocumentWord(content=the, polygon=[Point(x=4.2931, y=7.1795), Point(x=4.5659, y=7.1748), Point(x=4.5659, y=7.3375), Point(x=4.2883, y=7.3423)], span=DocumentSpan(offset=746, length=3), confidence=0.736), DocumentWord(content=wells, polygon=[Point(x=4.6185, y=7.1748), Point(x=5.0684, y=7.1748), Point(x=5.0684, y=7.3327), Point(x=4.6185, y=7.3375)], span=DocumentSpan(offset=750, length=5), confidence=0.782), DocumentWord(content=listed, polygon=[Point(x=5.1258, y=7.17), Point(x=5.6571, y=7.1652), Point(x=5.6571, y=7.3279), Point(x=5.1258, y=7.3327)], span=DocumentSpan(offset=756, length=6), confidence=0.612), DocumentWord(content=above, polygon=[Point(x=5.7241, y=7.1652), Point(x=6.1596, y=7.1652), Point(x=6.1644, y=7.3183), Point(x=5.7193, y=7.3231)], span=DocumentSpan(offset=763, length=5), confidence=0.601), DocumentWord(content=and, polygon=[Point(x=6.2266, y=7.1604), Point(x=6.4994, y=7.1604), Point(x=6.5042, y=7.3136), Point(x=6.2266, y=7.3183)], span=DocumentSpan(offset=769, length=3), confidence=0.616), DocumentWord(content=Baso, polygon=[Point(x=6.5569, y=7.1604), Point(x=6.9254, y=7.1556), Point(x=6.9254, y=7.3088), Point(x=6.5569, y=7.3136)], span=DocumentSpan(offset=773, length=4), confidence=0.369), DocumentWord(content=agreed, polygon=[Point(x=6.978, y=7.1556), Point(x=7.5093, y=7.1508), Point(x=7.5141, y=7.2992), Point(x=6.978, y=7.3088)], span=DocumentSpan(offset=778, length=6), confidence=0.443), DocumentWord(content=to, polygon=[Point(x=1.5315, y=7.3806), Point(x=1.7421, y=7.3758), Point(x=1.7373, y=7.5289), Point(x=1.5267, y=7.5337)], span=DocumentSpan(offset=785, length=2), confidence=0.884), DocumentWord(content=furnish, polygon=[Point(x=1.7852, y=7.3758), Point(x=2.3739, y=7.371), Point(x=2.3691, y=7.5289), Point(x=1.7804, y=7.5289)], span=DocumentSpan(offset=788, length=7), confidence=0.681), DocumentWord(content=Union, polygon=[Point(x=2.46, y=7.371), Point(x=2.8812, y=7.3662), Point(x=2.8764, y=7.5242), Point(x=2.4552, y=7.5289)], span=DocumentSpan(offset=796, length=5), confidence=0.695), DocumentWord(content=with, polygon=[Point(x=2.9482, y=7.3662), Point(x=3.3215, y=7.3614), Point(x=3.3215, y=7.5194), Point(x=2.9434, y=7.5242)], span=DocumentSpan(offset=802, length=4), confidence=0.98), DocumentWord(content=Information, polygon=[Point(x=3.3885, y=7.3614), Point(x=4.3361, y=7.3519), Point(x=4.3314, y=7.5146), Point(x=3.3837, y=7.5194)], span=DocumentSpan(offset=807, length=11), confidence=0.267), DocumentWord(content=from, polygon=[Point(x=4.3984, y=7.3471), Point(x=4.7573, y=7.3471), Point(x=4.7525, y=7.5098), Point(x=4.3984, y=7.5098)], span=DocumentSpan(offset=819, length=4), confidence=0.92), DocumentWord(content=its, polygon=[Point(x=4.8004, y=7.3423), Point(x=5.0923, y=7.3423), Point(x=5.0923, y=7.505), Point(x=4.8004, y=7.5098)], span=DocumentSpan(offset=824, length=3), confidence=0.974), DocumentWord(content=Balios, polygon=[Point(x=5.1402, y=7.3423), Point(x=5.5997, y=7.3375), Point(x=5.5997, y=7.5002), Point(x=5.1354, y=7.505)], span=DocumentSpan(offset=828, length=6), confidence=0.806), DocumentWord(content=No., polygon=[Point(x=5.6427, y=7.3375), Point(x=5.9347, y=7.3327), Point(x=5.9347, y=7.4954), Point(x=5.6427, y=7.5002)], span=DocumentSpan(offset=835, length=3), confidence=0.665), DocumentWord(content=1, polygon=[Point(x=6.0017, y=7.3327), Point(x=6.107, y=7.3279), Point(x=6.1022, y=7.4954), Point(x=6.0017, y=7.4954)], span=DocumentSpan(offset=839, length=1), confidence=0.861), DocumentWord(content=drilled, polygon=[Point(x=6.1501, y=7.3279), Point(x=6.7579, y=7.3231), Point(x=6.7579, y=7.4859), Point(x=6.1501, y=7.4907)], span=DocumentSpan(offset=841, length=7), confidence=0.681), DocumentWord(content=in, polygon=[Point(x=6.8249, y=7.3231), Point(x=7.0307, y=7.3183), Point(x=7.0307, y=7.4811), Point(x=6.8249, y=7.4859)], span=DocumentSpan(offset=849, length=2), confidence=0.995), DocumentWord(content=Cuba, polygon=[Point(x=7.0785, y=7.3183), Point(x=7.4327, y=7.3136), Point(x=7.4327, y=7.4763), Point(x=7.0785, y=7.4811)], span=DocumentSpan(offset=852, length=4), confidence=0.85), DocumentWord(content=and, polygon=[Point(x=1.5363, y=7.5577), Point(x=1.7804, y=7.5529), Point(x=1.7804, y=7.706), Point(x=1.5363, y=7.706)], span=DocumentSpan(offset=857, length=3), confidence=0.655), DocumentWord(content=roch, polygon=[Point(x=1.8666, y=7.5529), Point(x=2.2159, y=7.5481), Point(x=2.2111, y=7.7013), Point(x=1.8666, y=7.706)], span=DocumentSpan(offset=861, length=4), confidence=0.701), DocumentWord(content=other, polygon=[Point(x=2.2782, y=7.5481), Point(x=2.7185, y=7.5433), Point(x=2.7185, y=7.6965), Point(x=2.2782, y=7.7013)], span=DocumentSpan(offset=866, length=5), confidence=0.604), DocumentWord(content=vello, polygon=[Point(x=2.7759, y=7.5433), Point(x=3.2162, y=7.5385), Point(x=3.2114, y=7.6965), Point(x=2.7711, y=7.6965)], span=DocumentSpan(offset=872, length=5), confidence=0.095), DocumentWord(content=Laco, polygon=[Point(x=3.2689, y=7.5337), Point(x=3.647, y=7.5337), Point(x=3.647, y=7.6917), Point(x=3.2689, y=7.6965)], span=DocumentSpan(offset=878, length=4), confidence=0.265), DocumentWord(content=drills, polygon=[Point(x=3.7044, y=7.5289), Point(x=4.2356, y=7.5242), Point(x=4.2309, y=7.6869), Point(x=3.6996, y=7.6917)], span=DocumentSpan(offset=883, length=6), confidence=0.651), DocumentWord(content=in, polygon=[Point(x=4.2979, y=7.5242), Point(x=4.4845, y=7.5242), Point(x=4.4797, y=7.6821), Point(x=4.2979, y=7.6869)], span=DocumentSpan(offset=890, length=2), confidence=0.941), DocumentWord(content=the, polygon=[Point(x=4.5563, y=7.5194), Point(x=4.8243, y=7.5194), Point(x=4.8195, y=7.6821), Point(x=4.5563, y=7.6821)], span=DocumentSpan(offset=893, length=3), confidence=0.602), DocumentWord(content=Caribbean, polygon=[Point(x=4.877, y=7.5194), Point(x=5.6571, y=7.5098), Point(x=5.6523, y=7.6725), Point(x=4.8722, y=7.6773)], span=DocumentSpan(offset=897, length=9), confidence=0.665), DocumentWord(content=ares,, polygon=[Point(x=5.7241, y=7.5098), Point(x=6.174, y=7.505), Point(x=6.1692, y=7.663), Point(x=5.7193, y=7.6678)], span=DocumentSpan(offset=907, length=5), confidence=0.763), DocumentWord(content=that, polygon=[Point(x=6.2362, y=7.505), Point(x=6.5856, y=7.5002), Point(x=6.5808, y=7.6582), Point(x=6.2362, y=7.663)], span=DocumentSpan(offset=913, length=4), confidence=0.8), DocumentWord(content=in, polygon=[Point(x=6.6526, y=7.5002), Point(x=6.8345, y=7.5002), Point(x=6.8297, y=7.6534), Point(x=6.6478, y=7.6582)], span=DocumentSpan(offset=918, length=2), confidence=0.924), DocumentWord(content=their, polygon=[Point(x=6.9062, y=7.4954), Point(x=7.337, y=7.4954), Point(x=7.3322, y=7.6486), Point(x=6.9062, y=7.6534)], span=DocumentSpan(offset=921, length=5), confidence=0.728), DocumentWord(content=opinion, polygon=[Point(x=1.5315, y=7.7252), Point(x=2.1298, y=7.7156), Point(x=2.125, y=7.8784), Point(x=1.5267, y=7.8831)], span=DocumentSpan(offset=927, length=7), confidence=0.778), DocumentWord(content=the, polygon=[Point(x=2.2064, y=7.7156), Point(x=2.4696, y=7.7108), Point(x=2.4648, y=7.8736), Point(x=2.2016, y=7.8736)], span=DocumentSpan(offset=935, length=3), confidence=0.945), DocumentWord(content=relenen, polygon=[Point(x=2.5414, y=7.7108), Point(x=3.1444, y=7.7013), Point(x=3.1396, y=7.864), Point(x=2.5366, y=7.8736)], span=DocumentSpan(offset=939, length=7), confidence=0.646), DocumentWord(content=of, polygon=[Point(x=3.2066, y=7.7013), Point(x=3.3981, y=7.7013), Point(x=3.3933, y=7.8592), Point(x=3.2019, y=7.864)], span=DocumentSpan(offset=947, length=2), confidence=0.883), DocumentWord(content=information, polygon=[Point(x=3.4603, y=7.6965), Point(x=4.3984, y=7.6869), Point(x=4.3936, y=7.8496), Point(x=3.4603, y=7.8592)], span=DocumentSpan(offset=950, length=11), confidence=0.073), DocumentWord(content=is, polygon=[Point(x=4.4654, y=7.6869), Point(x=4.6472, y=7.6869), Point(x=4.6425, y=7.8448), Point(x=4.4606, y=7.8496)], span=DocumentSpan(offset=962, length=2), confidence=0.94), DocumentWord(content=not, polygon=[Point(x=4.7095, y=7.6869), Point(x=4.9918, y=7.6821), Point(x=4.987, y=7.8401), Point(x=4.7047, y=7.8448)], span=DocumentSpan(offset=965, length=3), confidence=0.957), DocumentWord(content=detrimental, polygon=[Point(x=5.0493, y=7.6821), Point(x=5.9969, y=7.6773), Point(x=5.9921, y=7.8305), Point(x=5.0445, y=7.8401)], span=DocumentSpan(offset=969, length=11), confidence=0.545), DocumentWord(content=to, polygon=[Point(x=6.0687, y=7.6725), Point(x=6.241, y=7.6725), Point(x=6.2362, y=7.8257), Point(x=6.0639, y=7.8257)], span=DocumentSpan(offset=981, length=2), confidence=0.997), DocumentWord(content=then,, polygon=[Point(x=6.3128, y=7.6725), Point(x=6.7722, y=7.6725), Point(x=6.7675, y=7.8209), Point(x=6.308, y=7.8257)], span=DocumentSpan(offset=984, length=5), confidence=0.618), DocumentWord(content=The, polygon=[Point(x=6.8967, y=7.6725), Point(x=7.1695, y=7.6678), Point(x=7.1647, y=7.8113), Point(x=6.8919, y=7.8161)], span=DocumentSpan(offset=990, length=3), confidence=0.618), DocumentWord(content=cx-, polygon=[Point(x=7.2461, y=7.6678), Point(x=7.538, y=7.6678), Point(x=7.5332, y=7.8113), Point(x=7.2413, y=7.8113)], span=DocumentSpan(offset=994, length=3), confidence=0.628), DocumentWord(content=change, polygon=[Point(x=1.5363, y=7.8975), Point(x=2.0532, y=7.8879), Point(x=2.0532, y=8.0459), Point(x=1.5363, y=8.0507)], span=DocumentSpan(offset=998, length=6), confidence=0.954), DocumentWord(content=includes, polygon=[Point(x=2.1106, y=7.8879), Point(x=2.8094, y=7.8784), Point(x=2.8094, y=8.0363), Point(x=2.1106, y=8.0459)], span=DocumentSpan(offset=1005, length=8), confidence=0.601), DocumentWord(content=senples, polygon=[Point(x=2.8764, y=7.8784), Point(x=3.4794, y=7.8688), Point(x=3.4794, y=8.0315), Point(x=2.8764, y=8.0363)], span=DocumentSpan(offset=1014, length=7), confidence=0.683), DocumentWord(content=and, polygon=[Point(x=3.5369, y=7.8688), Point(x=3.8336, y=7.864), Point(x=3.8288, y=8.0267), Point(x=3.5369, y=8.0315)], span=DocumentSpan(offset=1022, length=3), confidence=0.349), DocumentWord(content=goneral, polygon=[Point(x=3.891, y=7.864), Point(x=4.4941, y=7.8592), Point(x=4.4893, y=8.0219), Point(x=3.8863, y=8.0267)], span=DocumentSpan(offset=1026, length=7), confidence=0.456), DocumentWord(content=well, polygon=[Point(x=4.5515, y=7.8592), Point(x=4.92, y=7.8544), Point(x=4.9153, y=8.0172), Point(x=4.5467, y=8.0219)], span=DocumentSpan(offset=1034, length=4), confidence=0.534), DocumentWord(content=infomation, polygon=[Point(x=4.9775, y=7.8544), Point(x=5.9203, y=7.8448), Point(x=5.9155, y=8.0076), Point(x=4.9727, y=8.0172)], span=DocumentSpan(offset=1039, length=10), confidence=0.455), DocumentWord(content=such, polygon=[Point(x=5.9873, y=7.8448), Point(x=6.3367, y=7.8401), Point(x=6.3319, y=8.0076), Point(x=5.9825, y=8.0076)], span=DocumentSpan(offset=1050, length=4), confidence=0.585), DocumentWord(content=as, polygon=[Point(x=6.4133, y=7.8401), Point(x=6.6047, y=7.8401), Point(x=6.5952, y=8.0076), Point(x=6.4085, y=8.0076)], span=DocumentSpan(offset=1055, length=2), confidence=0.601), DocumentWord(content=logs,, polygon=[Point(x=6.6574, y=7.8401), Point(x=7.112, y=7.8353), Point(x=7.1073, y=8.0028), Point(x=6.6526, y=8.0076)], span=DocumentSpan(offset=1058, length=5), confidence=0.844), DocumentWord(content=DSTS,, polygon=[Point(x=7.1503, y=7.8353), Point(x=7.6146, y=7.8353), Point(x=7.6098, y=8.0028), Point(x=7.1408, y=8.0028)], span=DocumentSpan(offset=1064, length=5), confidence=0.379), DocumentWord(content=etc., polygon=[Point(x=1.5315, y=8.0602), Point(x=1.8857, y=8.0554), Point(x=1.8857, y=8.223), Point(x=1.5315, y=8.2278)], span=DocumentSpan(offset=1070, length=4), confidence=0.67), DocumentWord(content=and, polygon=[Point(x=1.9431, y=8.0554), Point(x=2.2255, y=8.0507), Point(x=2.2255, y=8.2134), Point(x=1.9431, y=8.223)], span=DocumentSpan(offset=1075, length=3), confidence=0.928), DocumentWord(content=is, polygon=[Point(x=2.2782, y=8.0507), Point(x=2.4792, y=8.0507), Point(x=2.4792, y=8.2086), Point(x=2.2782, y=8.2134)], span=DocumentSpan(offset=1079, length=2), confidence=0.795), DocumentWord(content=on, polygon=[Point(x=2.5318, y=8.0507), Point(x=2.7233, y=8.0459), Point(x=2.7233, y=8.2086), Point(x=2.5318, y=8.2086)], span=DocumentSpan(offset=1082, length=2), confidence=0.996), DocumentWord(content=a, polygon=[Point(x=2.7855, y=8.0459), Point(x=2.8812, y=8.0459), Point(x=2.8812, y=8.2038), Point(x=2.7855, y=8.2038)], span=DocumentSpan(offset=1085, length=1), confidence=0.995), DocumentWord(content=foot, polygon=[Point(x=2.9578, y=8.0459), Point(x=3.3119, y=8.0411), Point(x=3.3119, y=8.199), Point(x=2.9578, y=8.2038)], span=DocumentSpan(offset=1087, length=4), confidence=0.85), DocumentWord(content=for, polygon=[Point(x=3.3789, y=8.0411), Point(x=3.6517, y=8.0411), Point(x=3.6517, y=8.199), Point(x=3.3789, y=8.199)], span=DocumentSpan(offset=1092, length=3), confidence=0.682), DocumentWord(content=foot, polygon=[Point(x=3.7188, y=8.0363), Point(x=4.0633, y=8.0363), Point(x=4.0633, y=8.1943), Point(x=3.7188, y=8.1943)], span=DocumentSpan(offset=1096, length=4), confidence=0.96), DocumentWord(content=tasis, polygon=[Point(x=4.1303, y=8.0363), Point(x=4.5419, y=8.0363), Point(x=4.5419, y=8.1943), Point(x=4.1303, y=8.1943)], span=DocumentSpan(offset=1101, length=5), confidence=0.615), DocumentWord(content=.., polygon=[Point(x=4.5755, y=8.0363), Point(x=4.7142, y=8.0363), Point(x=4.7142, y=8.1943), Point(x=4.5755, y=8.1943)], span=DocumentSpan(offset=1107, length=2), confidence=0.68), DocumentWord(content=Wo, polygon=[Point(x=2.192, y=8.3905), Point(x=2.3882, y=8.3857), Point(x=2.393, y=8.5389), Point(x=2.1968, y=8.5389)], span=DocumentSpan(offset=1110, length=2), confidence=0.929), DocumentWord(content=have, polygon=[Point(x=2.4457, y=8.3857), Point(x=2.8142, y=8.3857), Point(x=2.8142, y=8.5389), Point(x=2.4505, y=8.5389)], span=DocumentSpan(offset=1113, length=4), confidence=0.169), DocumentWord(content=the, polygon=[Point(x=2.8764, y=8.3857), Point(x=3.1396, y=8.3857), Point(x=3.1444, y=8.5341), Point(x=2.8812, y=8.5389)], span=DocumentSpan(offset=1118, length=3), confidence=0.929), DocumentWord(content=sons, polygon=[Point(x=3.2162, y=8.3857), Point(x=3.5752, y=8.3809), Point(x=3.5752, y=8.5341), Point(x=3.221, y=8.5341)], span=DocumentSpan(offset=1122, length=4), confidence=0.011), DocumentWord(content=set, polygon=[Point(x=3.6278, y=8.3809), Point(x=3.9054, y=8.3809), Point(x=3.9054, y=8.5341), Point(x=3.6278, y=8.5341)], span=DocumentSpan(offset=1127, length=3), confidence=0.771), DocumentWord(content=we, polygon=[Point(x=3.9676, y=8.3809), Point(x=4.1495, y=8.3761), Point(x=4.1495, y=8.5341), Point(x=3.9676, y=8.5341)], span=DocumentSpan(offset=1131, length=2), confidence=0.001), DocumentWord(content=are, polygon=[Point(x=4.2165, y=8.3761), Point(x=4.4989, y=8.3761), Point(x=4.4989, y=8.5293), Point(x=4.2165, y=8.5293)], span=DocumentSpan(offset=1134, length=3), confidence=0.61), DocumentWord(content=sorting, polygon=[Point(x=4.5563, y=8.3713), Point(x=5.1689, y=8.3666), Point(x=5.1689, y=8.5245), Point(x=4.5563, y=8.5293)], span=DocumentSpan(offset=1138, length=7), confidence=0.556), DocumentWord(content=you, polygon=[Point(x=5.2311, y=8.3666), Point(x=5.4992, y=8.3618), Point(x=5.4944, y=8.5197), Point(x=5.2311, y=8.5245)], span=DocumentSpan(offset=1146, length=3), confidence=0.993), DocumentWord(content=in, polygon=[Point(x=5.5614, y=8.3618), Point(x=5.7576, y=8.357), Point(x=5.7528, y=8.5197), Point(x=5.5614, y=8.5197)], span=DocumentSpan(offset=1150, length=2), confidence=0.933), DocumentWord(content=our, polygon=[Point(x=5.8198, y=8.357), Point(x=6.0926, y=8.3522), Point(x=6.0926, y=8.5149), Point(x=5.8198, y=8.5197)], span=DocumentSpan(offset=1153, length=3), confidence=0.721), DocumentWord(content=Havana, polygon=[Point(x=6.1405, y=8.3522), Point(x=6.6813, y=8.3426), Point(x=6.6765, y=8.5054), Point(x=6.1357, y=8.5149)], span=DocumentSpan(offset=1157, length=6), confidence=0.324), DocumentWord(content=office., polygon=[Point(x=6.7435, y=8.3426), Point(x=7.3561, y=8.3331), Point(x=7.3514, y=8.4958), Point(x=6.7435, y=8.5054)], span=DocumentSpan(offset=1164, length=7), confidence=0.636), DocumentWord(content=The, polygon=[Point(x=1.5411, y=8.5676), Point(x=1.8091, y=8.5676), Point(x=1.8091, y=8.7303), Point(x=1.5363, y=8.7303)], span=DocumentSpan(offset=1172, length=3), confidence=0.955), DocumentWord(content=purpose, polygon=[Point(x=1.8761, y=8.5676), Point(x=2.4744, y=8.5628), Point(x=2.4744, y=8.7255), Point(x=1.8761, y=8.7303)], span=DocumentSpan(offset=1176, length=7), confidence=0.62), DocumentWord(content=of, polygon=[Point(x=2.5414, y=8.5628), Point(x=2.7376, y=8.558), Point(x=2.7376, y=8.7208), Point(x=2.5414, y=8.7208)], span=DocumentSpan(offset=1184, length=2), confidence=0.997), DocumentWord(content=sending, polygon=[Point(x=2.795, y=8.558), Point(x=3.4124, y=8.5532), Point(x=3.4124, y=8.716), Point(x=2.7903, y=8.7208)], span=DocumentSpan(offset=1187, length=7), confidence=0.631), DocumentWord(content=you, polygon=[Point(x=3.4699, y=8.5532), Point(x=3.7283, y=8.5532), Point(x=3.7283, y=8.7112), Point(x=3.4651, y=8.716)], span=DocumentSpan(offset=1195, length=3), confidence=0.955), DocumentWord(content=a, polygon=[Point(x=3.8049, y=8.5484), Point(x=3.8958, y=8.5484), Point(x=3.8958, y=8.7112), Point(x=3.8049, y=8.7112)], span=DocumentSpan(offset=1199, length=1), confidence=0.991), DocumentWord(content=cot, polygon=[Point(x=3.9868, y=8.5484), Point(x=4.2452, y=8.5484), Point(x=4.2452, y=8.7064), Point(x=3.982, y=8.7112)], span=DocumentSpan(offset=1201, length=3), confidence=0.901), DocumentWord(content=is, polygon=[Point(x=4.3122, y=8.5484), Point(x=4.4989, y=8.5437), Point(x=4.4989, y=8.7064), Point(x=4.3122, y=8.7064)], span=DocumentSpan(offset=1205, length=2), confidence=0.635), DocumentWord(content=for, polygon=[Point(x=4.5659, y=8.5437), Point(x=4.8243, y=8.5437), Point(x=4.8243, y=8.7016), Point(x=4.5611, y=8.7016)], span=DocumentSpan(offset=1208, length=3), confidence=0.997), DocumentWord(content=security, polygon=[Point(x=4.9009, y=8.5389), Point(x=5.5949, y=8.5341), Point(x=5.5949, y=8.6968), Point(x=4.9009, y=8.7016)], span=DocumentSpan(offset=1212, length=8), confidence=0.617), DocumentWord(content=and, polygon=[Point(x=5.6619, y=8.5341), Point(x=5.9299, y=8.5341), Point(x=5.9299, y=8.692), Point(x=5.6571, y=8.692)], span=DocumentSpan(offset=1221, length=3), confidence=0.991), DocumentWord(content=your, polygon=[Point(x=5.9873, y=8.5293), Point(x=6.3559, y=8.5293), Point(x=6.3511, y=8.6872), Point(x=5.9873, y=8.692)], span=DocumentSpan(offset=1225, length=4), confidence=0.998), DocumentWord(content=use., polygon=[Point(x=6.3989, y=8.5293), Point(x=6.777, y=8.5245), Point(x=6.7722, y=8.6825), Point(x=6.3989, y=8.6872)], span=DocumentSpan(offset=1230, length=4), confidence=0.728), DocumentWord(content=Very, polygon=[Point(x=5.1354, y=8.8452), Point(x=5.5135, y=8.8452), Point(x=5.5183, y=9.0175), Point(x=5.1402, y=9.0223)], span=DocumentSpan(offset=1235, length=4), confidence=0.619), DocumentWord(content=truly, polygon=[Point(x=5.5662, y=8.8452), Point(x=6.0256, y=8.8452), Point(x=6.0256, y=9.0223), Point(x=5.5662, y=9.0175)], span=DocumentSpan(offset=1240, length=5), confidence=0.955), DocumentWord(content=yours,, polygon=[Point(x=6.0735, y=8.8452), Point(x=6.6143, y=8.8452), Point(x=6.6191, y=9.0319), Point(x=6.0783, y=9.0223)], span=DocumentSpan(offset=1246, length=6), confidence=0.93), DocumentWord(content=E250, polygon=[Point(x=4.9823, y=9.1132), Point(x=5.346, y=9.1037), Point(x=5.3412, y=9.2808), Point(x=4.9775, y=9.276)], span=DocumentSpan(offset=1253, length=4), confidence=0.089), DocumentWord(content=STANDARD, polygon=[Point(x=5.3843, y=9.1037), Point(x=6.1022, y=9.0941), Point(x=6.1022, y=9.2855), Point(x=5.3795, y=9.2808)], span=DocumentSpan(offset=1258, length=8), confidence=0.366), DocumentWord(content=OIL,, polygon=[Point(x=6.1548, y=9.0893), Point(x=6.5234, y=9.0845), Point(x=6.5234, y=9.2855), Point(x=6.1548, y=9.2855)], span=DocumentSpan(offset=1267, length=4), confidence=0.32), DocumentWord(content=S.A, polygon=[Point(x=6.5617, y=9.0845), Point(x=6.7818, y=9.0845), Point(x=6.7818, y=9.2808), Point(x=6.5617, y=9.2855)], span=DocumentSpan(offset=1272, length=3), confidence=0.626), DocumentWord(content=.., polygon=[Point(x=6.8153, y=9.0845), Point(x=6.9541, y=9.0797), Point(x=6.9589, y=9.2808), Point(x=6.8201, y=9.2808)], span=DocumentSpan(offset=1276, length=2), confidence=0.439), DocumentWord(content=ORIGINAL, polygon=[Point(x=4.9392, y=9.343), Point(x=5.5231, y=9.3286), Point(x=5.5183, y=9.4818), Point(x=4.9392, y=9.477)], span=DocumentSpan(offset=1279, length=8), confidence=0.943), DocumentWord(content=SIGNED, polygon=[Point(x=4.9344, y=9.4818), Point(x=5.3604, y=9.4722), Point(x=5.3604, y=9.5967), Point(x=4.9392, y=9.6062)], span=DocumentSpan(offset=1288, length=6), confidence=0.627), DocumentWord(content=-, polygon=[Point(x=5.6427, y=9.3956), Point(x=5.6427, y=9.4531), Point(x=5.5709, y=9.4531), Point(x=5.5709, y=9.3956)], span=DocumentSpan(offset=1295, length=1), confidence=0.712), DocumentWord(content=--, polygon=[Point(x=6.4994, y=9.6206), Point(x=6.8488, y=9.6254), Point(x=6.844, y=9.7211), Point(x=6.5042, y=9.7211)], span=DocumentSpan(offset=1297, length=2), confidence=0.805), DocumentWord(content=J., polygon=[Point(x=5.3221, y=9.6732), Point(x=5.4944, y=9.6732), Point(x=5.4848, y=9.8743), Point(x=5.3125, y=9.8743)], span=DocumentSpan(offset=1300, length=2), confidence=0.739), DocumentWord(content=Il., polygon=[Point(x=5.5327, y=9.6732), Point(x=5.7815, y=9.678), Point(x=5.7767, y=9.8743), Point(x=5.5231, y=9.8743)], span=DocumentSpan(offset=1303, length=3), confidence=0.151), DocumentWord(content=Sexpor, polygon=[Point(x=5.8198, y=9.678), Point(x=6.3894, y=9.6828), Point(x=6.3894, y=9.8791), Point(x=5.815, y=9.8743)], span=DocumentSpan(offset=1307, length=6), confidence=0.174), DocumentWord(content=ÅSter, polygon=[Point(x=1.5459, y=9.9844), Point(x=2.0006, y=9.9844), Point(x=2.0006, y=10.1567), Point(x=1.5459, y=10.1567)], span=DocumentSpan(offset=1314, length=5), confidence=0.41), DocumentWord(content=Atts., polygon=[Point(x=1.5555, y=10.3481), Point(x=2.0006, y=10.3529), Point(x=1.9958, y=10.5013), Point(x=1.5555, y=10.4917)], span=DocumentSpan(offset=1320, length=5), confidence=0.846)], selection_marks=[], spans=[DocumentSpan(offset=0, length=1325)]),\n",
       " DocumentPage(page_number=2, angle=-0.32010000944137573, width=8.4306, height=10.9167, unit=inch, lines=[DocumentLine(content=Costa Rica Pire, polygon=[Point(x=6.2554, y=0.1042), Point(x=7.8619, y=0.0521), Point(x=7.8714, y=0.3032), Point(x=6.2554, y=0.3411)], spans=[DocumentSpan(offset=1326, length=15)]), DocumentLine(content=Union 011 Company of California, polygon=[Point(x=3.1324, y=1.1419), Point(x=5.772, y=1.1324), Point(x=5.772, y=1.3077), Point(x=3.1324, y=1.3219)], spans=[DocumentSpan(offset=1342, length=31)]), DocumentLine(content=CR.1.03, polygon=[Point(x=6.5255, y=0.9145), Point(x=7.5207, y=0.9618), Point(x=7.5159, y=1.1703), Point(x=6.5255, y=1.1087)], spans=[DocumentSpan(offset=1374, length=7)]), DocumentLine(content=Pati fo No. 2, polygon=[Point(x=1.3885, y=1.6726), Point(x=2.4548, y=1.6773), Point(x=2.4548, y=1.8479), Point(x=1.3885, y=1.8431)], spans=[DocumentSpan(offset=1382, length=13)]), DocumentLine(content=Location: 5 Kms. southwest of Puerto Viejo in SE Limon Province, polygon=[Point(x=1.7297, y=1.9995), Point(x=7.0894, y=1.9474), Point(x=7.0942, y=2.1179), Point(x=1.7297, y=2.1606)], spans=[DocumentSpan(offset=1396, length=63)]), DocumentLine(content=(Caribbean side), Costa Rica., polygon=[Point(x=2.6633, y=2.1606), Point(x=5.0707, y=2.1464), Point(x=5.0754, y=2.3169), Point(x=2.6633, y=2.3312)], spans=[DocumentSpan(offset=1460, length=29)]), DocumentLine(content=Coordinates: Lat. 9º 39' 14\" - Long. 82' 48' 10\", polygon=[Point(x=2.6633, y=2.3264), Point(x=6.7861, y=2.2838), Point(x=6.7861, y=2.4686), Point(x=2.6633, y=2.497)], spans=[DocumentSpan(offset=1490, length=48)]), DocumentLine(content=Dates: Commenced:, polygon=[Point(x=1.725, y=2.6818), Point(x=3.3267, y=2.6534), Point(x=3.3315, y=2.8192), Point(x=1.725, y=2.8524)], spans=[DocumentSpan(offset=1539, length=17)]), DocumentLine(content=2/23/55, polygon=[Point(x=3.3694, y=2.6486), Point(x=4.0281, y=2.6486), Point(x=4.0281, y=2.8287), Point(x=3.3694, y=2.8287)], spans=[DocumentSpan(offset=1557, length=7)]), DocumentLine(content=Completed:, polygon=[Point(x=2.4074, y=2.8381), Point(x=3.322, y=2.8334), Point(x=3.3267, y=3.0087), Point(x=2.4074, y=3.0182)], spans=[DocumentSpan(offset=1565, length=10)]), DocumentLine(content=4/19/55, polygon=[Point(x=3.3931, y=2.8287), Point(x=4.0186, y=2.8287), Point(x=4.0186, y=3.004), Point(x=3.3931, y=3.004)], spans=[DocumentSpan(offset=1576, length=7)]), DocumentLine(content=Status: D & A, polygon=[Point(x=1.7392, y=3.1698), Point(x=2.9381, y=3.1603), Point(x=2.9429, y=3.3214), Point(x=1.7439, y=3.3356)], spans=[DocumentSpan(offset=1584, length=13)]), DocumentLine(content=Total Depth: 10,128' formation unknown as yet. Probably Eocene., polygon=[Point(x=1.7155, y=3.4967), Point(x=7.1605, y=3.4588), Point(x=7.1605, y=3.6484), Point(x=1.7155, y=3.6863)], spans=[DocumentSpan(offset=1598, length=63)]), DocumentLine(content=Shows: No oil or gas shows., polygon=[Point(x=1.7392, y=3.8332), Point(x=4.0992, y=3.8332), Point(x=4.0992, y=3.999), Point(x=1.7392, y=3.999)], spans=[DocumentSpan(offset=1662, length=27)]), DocumentLine(content=DST's: None., polygon=[Point(x=1.7439, y=4.1601), Point(x=2.8481, y=4.1743), Point(x=2.8481, y=4.3259), Point(x=1.7439, y=4.3212)], spans=[DocumentSpan(offset=1690, length=12)]), DocumentLine(content=Location based on: Surface: Puerto Viejo Anticline., polygon=[Point(x=1.7392, y=4.5012), Point(x=6.1796, y=4.4681), Point(x=6.1843, y=4.6434), Point(x=1.7439, y=4.6718)], spans=[DocumentSpan(offset=1703, length=51)]), DocumentLine(content=General Dip - SW 55º., polygon=[Point(x=1.7487, y=4.8329), Point(x=3.5163, y=4.8187), Point(x=3.5163, y=5.0035), Point(x=1.7487, y=5.0129)], spans=[DocumentSpan(offset=1755, length=21)]), DocumentLine(content=Electric Log:, polygon=[Point(x=1.7392, y=5.1598), Point(x=2.9334, y=5.174), Point(x=2.9287, y=5.3446), Point(x=1.7392, y=5.3257)], spans=[DocumentSpan(offset=1777, length=13)]), DocumentLine(content=Shale line thruout., polygon=[Point(x=2.9381, y=5.1646), Point(x=4.5968, y=5.1551), Point(x=4.5968, y=5.3209), Point(x=2.9381, y=5.3304)], spans=[DocumentSpan(offset=1791, length=19)]), DocumentLine(content=3,500 - Fresh water., polygon=[Point(x=2.995, y=5.4962), Point(x=4.6868, y=5.4962), Point(x=4.6868, y=5.6573), Point(x=2.995, y=5.6668)], spans=[DocumentSpan(offset=1811, length=20)]), DocumentLine(content=3,880 - 3,920 - Fresh water., polygon=[Point(x=2.995, y=5.6668), Point(x=5.3503, y=5.6526), Point(x=5.355, y=5.8137), Point(x=2.9997, y=5.8279)], spans=[DocumentSpan(offset=1832, length=28)]), DocumentLine(content=4,270 - 4,310), polygon=[Point(x=2.9997, y=5.8279), Point(x=4.1797, y=5.8184), Point(x=4.1797, y=5.989), Point(x=3.0045, y=5.9985)], spans=[DocumentSpan(offset=1861, length=14)]), DocumentLine(content=4,380, polygon=[Point(x=3.0045, y=6.008), Point(x=3.4547, y=5.9937), Point(x=3.4547, y=6.1501), Point(x=3.0092, y=6.1691)], spans=[DocumentSpan(offset=1876, length=5)]), DocumentLine(content=6,640 - 6,660), polygon=[Point(x=3.0045, y=6.1548), Point(x=4.1797, y=6.1454), Point(x=4.1797, y=6.3302), Point(x=3.0045, y=6.3349)], spans=[DocumentSpan(offset=1882, length=14)]), DocumentLine(content=6,750 - 6,860), polygon=[Point(x=3.0045, y=6.3254), Point(x=4.1892, y=6.3207), Point(x=4.1892, y=6.5055), Point(x=3.0045, y=6.5102)], spans=[DocumentSpan(offset=1897, length=14)]), DocumentLine(content=Probably salt water., polygon=[Point(x=4.2319, y=5.989), Point(x=5.9284, y=5.9795), Point(x=5.9284, y=6.1501), Point(x=4.2319, y=6.1596)], spans=[DocumentSpan(offset=1912, length=20)]), DocumentLine(content=Log indicates poor prospects for oil production, polygon=[Point(x=2.995, y=6.6571), Point(x=6.9615, y=6.6239), Point(x=6.9615, y=6.8087), Point(x=2.995, y=6.8371)], spans=[DocumentSpan(offset=1933, length=47)]), DocumentLine(content=because of shaly nature., polygon=[Point(x=3.0045, y=6.8371), Point(x=5.0233, y=6.8324), Point(x=5.0233, y=6.9888), Point(x=3.0092, y=6.9935)], spans=[DocumentSpan(offset=1981, length=24)]), DocumentLine(content=Note: Attempted to run E log to TD of 10,128' but cable would not go, polygon=[Point(x=1.7439, y=7.1641), Point(x=7.5396, y=7.1404), Point(x=7.5396, y=7.3109), Point(x=1.7439, y=7.3394)], spans=[DocumentSpan(offset=2006, length=68)]), DocumentLine(content=below 8,050' ., polygon=[Point(x=2.3505, y=7.3346), Point(x=3.4499, y=7.3346), Point(x=3.4499, y=7.5052), Point(x=2.3505, y=7.5005)], spans=[DocumentSpan(offset=2075, length=14)]), DocumentLine(content=List of material received to date:, polygon=[Point(x=1.7534, y=7.6616), Point(x=4.6157, y=7.6568), Point(x=4.6157, y=7.8274), Point(x=1.7534, y=7.8321)], spans=[DocumentSpan(offset=2090, length=34)]), DocumentLine(content=Electric lors, polygon=[Point(x=2.0093, y=8.0075), Point(x=3.1372, y=8.0075), Point(x=3.1372, y=8.1638), Point(x=2.0093, y=8.1638)], spans=[DocumentSpan(offset=2125, length=13)]), DocumentLine(content=Run 1, polygon=[Point(x=2.2463, y=8.1733), Point(x=2.7107, y=8.178), Point(x=2.7059, y=8.3249), Point(x=2.2463, y=8.3202)], spans=[DocumentSpan(offset=2139, length=5)]), DocumentLine(content=0 - 1,130', polygon=[Point(x=3.0993, y=8.1591), Point(x=3.9238, y=8.1449), Point(x=3.9286, y=8.306), Point(x=3.0993, y=8.3249)], spans=[DocumentSpan(offset=2145, length=10)]), DocumentLine(content=Run 3, polygon=[Point(x=2.2557, y=8.3344), Point(x=2.7296, y=8.3344), Point(x=2.7296, y=8.505), Point(x=2.2557, y=8.505)], spans=[DocumentSpan(offset=2156, length=5)]), DocumentLine(content=2,1001 - 3,051', polygon=[Point(x=3.0945, y=8.3296), Point(x=4.3361, y=8.3249), Point(x=4.3409, y=8.486), Point(x=3.0945, y=8.5002)], spans=[DocumentSpan(offset=2162, length=15)]), DocumentLine(content=Run 4, polygon=[Point(x=2.2415, y=8.5144), Point(x=2.7296, y=8.5239), Point(x=2.7249, y=8.6661), Point(x=2.2415, y=8.6471)], spans=[DocumentSpan(offset=2178, length=5)]), DocumentLine(content=2,9501 - 4,368', polygon=[Point(x=3.0945, y=8.5002), Point(x=4.3456, y=8.4765), Point(x=4.3503, y=8.6518), Point(x=3.0945, y=8.6708)], spans=[DocumentSpan(offset=2184, length=15)]), DocumentLine(content=Composite Log Runs 1 thru 8 0 - 9,124', polygon=[Point(x=2.2605, y=8.6566), Point(x=5.6014, y=8.6281), Point(x=5.6014, y=8.8224), Point(x=2.2605, y=8.8319)], spans=[DocumentSpan(offset=2200, length=38)]), DocumentLine(content=Extra Curves, polygon=[Point(x=2.2605, y=8.8414), Point(x=3.2888, y=8.8414), Point(x=3.2888, y=8.9882), Point(x=2.2605, y=8.9882)], spans=[DocumentSpan(offset=2239, length=12)]), DocumentLine(content=ES-3 2,090 - 3,050, polygon=[Point(x=2.5116, y=8.993), Point(x=4.4356, y=8.974), Point(x=4.4356, y=9.1588), Point(x=2.5116, y=9.173)], spans=[DocumentSpan(offset=2252, length=18)]), DocumentLine(content=ES-3 50 ohms 2,1001 - 3,060', polygon=[Point(x=2.4974, y=9.1588), Point(x=4.938, y=9.1351), Point(x=4.938, y=9.3152), Point(x=2.4974, y=9.3294)], spans=[DocumentSpan(offset=2271, length=28)]), DocumentLine(content=ES-7, polygon=[Point(x=2.5211, y=9.3199), Point(x=2.9903, y=9.3341), Point(x=2.9855, y=9.4858), Point(x=2.5116, y=9.4621)], spans=[DocumentSpan(offset=2300, length=4)]), DocumentLine(content=6,210' - 7,500', polygon=[Point(x=3.1798, y=9.3104), Point(x=4.4356, y=9.3152), Point(x=4.4309, y=9.4905), Point(x=3.1751, y=9.481)], spans=[DocumentSpan(offset=2305, length=15)]), DocumentLine(content=ES-5, polygon=[Point(x=2.5069, y=9.4905), Point(x=2.8955, y=9.4905), Point(x=2.8955, y=9.6658), Point(x=2.5022, y=9.6563)], spans=[DocumentSpan(offset=2321, length=4)]), DocumentLine(content=4,100' - 5,290', polygon=[Point(x=3.1988, y=9.4952), Point(x=4.4309, y=9.481), Point(x=4.4356, y=9.6611), Point(x=3.1988, y=9.68)], spans=[DocumentSpan(offset=2326, length=15)])], words=[DocumentWord(content=Costa, polygon=[Point(x=6.298, y=0.1185), Point(x=6.8478, y=0.09), Point(x=6.8478, y=0.3411), Point(x=6.2933, y=0.3411)], span=DocumentSpan(offset=1326, length=5), confidence=0.567), DocumentWord(content=Rica, polygon=[Point(x=6.9804, y=0.0853), Point(x=7.3975, y=0.0663), Point(x=7.4022, y=0.3269), Point(x=6.9804, y=0.3364)], span=DocumentSpan(offset=1332, length=4), confidence=0.108), DocumentWord(content=Pire, polygon=[Point(x=7.4686, y=0.0663), Point(x=7.8192, y=0.0521), Point(x=7.824, y=0.3032), Point(x=7.4686, y=0.3222)], span=DocumentSpan(offset=1337, length=4), confidence=0.23), DocumentWord(content=Union, polygon=[Point(x=3.1372, y=1.1561), Point(x=3.5732, y=1.1514), Point(x=3.5826, y=1.3219), Point(x=3.1419, y=1.3219)], span=DocumentSpan(offset=1342, length=5), confidence=0.78), DocumentWord(content=011, polygon=[Point(x=3.6205, y=1.1466), Point(x=3.9049, y=1.1419), Point(x=3.9096, y=1.3172), Point(x=3.63, y=1.3172)], span=DocumentSpan(offset=1348, length=3), confidence=0.604), DocumentWord(content=Company, polygon=[Point(x=3.9523, y=1.1419), Point(x=4.592, y=1.1372), Point(x=4.592, y=1.3125), Point(x=3.9617, y=1.3172)], span=DocumentSpan(offset=1352, length=7), confidence=0.955), DocumentWord(content=of, polygon=[Point(x=4.6394, y=1.1372), Point(x=4.8432, y=1.1372), Point(x=4.8432, y=1.3125), Point(x=4.6442, y=1.3125)], span=DocumentSpan(offset=1360, length=2), confidence=0.992), DocumentWord(content=California, polygon=[Point(x=4.8764, y=1.1372), Point(x=5.7436, y=1.1372), Point(x=5.7436, y=1.3125), Point(x=4.8811, y=1.3125)], span=DocumentSpan(offset=1363, length=10), confidence=0.673), DocumentWord(content=CR.1.03, polygon=[Point(x=6.5587, y=0.9192), Point(x=7.5112, y=0.9618), Point(x=7.5159, y=1.1751), Point(x=6.5587, y=1.1135)], span=DocumentSpan(offset=1374, length=7), confidence=0.892), DocumentWord(content=Pati, polygon=[Point(x=1.4027, y=1.6726), Point(x=1.7155, y=1.6773), Point(x=1.706, y=1.8479), Point(x=1.3932, y=1.8431)], span=DocumentSpan(offset=1382, length=4), confidence=0.434), DocumentWord(content=fo, polygon=[Point(x=1.7487, y=1.6773), Point(x=1.9382, y=1.6773), Point(x=1.9287, y=1.8479), Point(x=1.7392, y=1.8479)], span=DocumentSpan(offset=1387, length=2), confidence=0.595), DocumentWord(content=No., polygon=[Point(x=1.9714, y=1.6773), Point(x=2.2747, y=1.6773), Point(x=2.2699, y=1.8526), Point(x=1.9667, y=1.8479)], span=DocumentSpan(offset=1390, length=3), confidence=0.94), DocumentWord(content=2, polygon=[Point(x=2.3221, y=1.682), Point(x=2.4169, y=1.682), Point(x=2.4169, y=1.8526), Point(x=2.3173, y=1.8526)], span=DocumentSpan(offset=1394, length=1), confidence=0.996), DocumentWord(content=Location:, polygon=[Point(x=1.7344, y=2.009), Point(x=2.5116, y=2.0042), Point(x=2.5116, y=2.1606), Point(x=1.7344, y=2.1606)], span=DocumentSpan(offset=1396, length=9), confidence=0.991), DocumentWord(content=5, polygon=[Point(x=2.6538, y=1.9995), Point(x=2.7486, y=1.9995), Point(x=2.7486, y=2.1606), Point(x=2.6538, y=2.1606)], span=DocumentSpan(offset=1406, length=1), confidence=0.994), DocumentWord(content=Kms., polygon=[Point(x=2.8054, y=1.9995), Point(x=3.1798, y=1.9948), Point(x=3.1798, y=2.1559), Point(x=2.8054, y=2.1559)], span=DocumentSpan(offset=1408, length=4), confidence=0.783), DocumentWord(content=southwest, polygon=[Point(x=3.2367, y=1.9948), Point(x=4.0044, y=1.9853), Point(x=4.0091, y=2.1511), Point(x=3.2367, y=2.1559)], span=DocumentSpan(offset=1413, length=9), confidence=0.993), DocumentWord(content=of, polygon=[Point(x=4.0613, y=1.9853), Point(x=4.2508, y=1.9805), Point(x=4.2556, y=2.1464), Point(x=4.066, y=2.1511)], span=DocumentSpan(offset=1423, length=2), confidence=0.997), DocumentWord(content=Puerto, polygon=[Point(x=4.2982, y=1.9805), Point(x=4.8337, y=1.9758), Point(x=4.8337, y=2.1416), Point(x=4.2982, y=2.1464)], span=DocumentSpan(offset=1426, length=6), confidence=0.996), DocumentWord(content=Viejo, polygon=[Point(x=4.8858, y=1.9758), Point(x=5.3266, y=1.9711), Point(x=5.3313, y=2.1369), Point(x=4.8906, y=2.1416)], span=DocumentSpan(offset=1433, length=5), confidence=0.997), DocumentWord(content=in, polygon=[Point(x=5.3929, y=1.9711), Point(x=5.573, y=1.9663), Point(x=5.5777, y=2.1369), Point(x=5.3976, y=2.1369)], span=DocumentSpan(offset=1439, length=2), confidence=0.997), DocumentWord(content=SE, polygon=[Point(x=5.6298, y=1.9663), Point(x=5.8194, y=1.9663), Point(x=5.8241, y=2.1322), Point(x=5.6346, y=2.1369)], span=DocumentSpan(offset=1442, length=2), confidence=0.993), DocumentWord(content=Limon, polygon=[Point(x=5.8763, y=1.9663), Point(x=6.3217, y=1.9616), Point(x=6.3312, y=2.1274), Point(x=5.881, y=2.1322)], span=DocumentSpan(offset=1445, length=5), confidence=0.993), DocumentWord(content=Province, polygon=[Point(x=6.3786, y=1.9569), Point(x=7.0752, y=1.9521), Point(x=7.0847, y=2.1179), Point(x=6.3881, y=2.1274)], span=DocumentSpan(offset=1451, length=8), confidence=0.993), DocumentWord(content=(Caribbean, polygon=[Point(x=2.668, y=2.1653), Point(x=3.4973, y=2.1606), Point(x=3.4973, y=2.3312), Point(x=2.6633, y=2.3312)], span=DocumentSpan(offset=1460, length=10), confidence=0.993), DocumentWord(content=side),, polygon=[Point(x=3.5589, y=2.1606), Point(x=4.1039, y=2.1606), Point(x=4.1039, y=2.3312), Point(x=3.5589, y=2.3312)], span=DocumentSpan(offset=1471, length=6), confidence=0.991), DocumentWord(content=Costa, polygon=[Point(x=4.1371, y=2.1559), Point(x=4.5825, y=2.1559), Point(x=4.5873, y=2.3264), Point(x=4.1418, y=2.3312)], span=DocumentSpan(offset=1478, length=5), confidence=0.928), DocumentWord(content=Rica., polygon=[Point(x=4.6299, y=2.1511), Point(x=5.0659, y=2.1464), Point(x=5.0754, y=2.3169), Point(x=4.6347, y=2.3264)], span=DocumentSpan(offset=1484, length=5), confidence=0.989), DocumentWord(content=Coordinates:, polygon=[Point(x=2.6633, y=2.3454), Point(x=3.6679, y=2.3359), Point(x=3.6727, y=2.497), Point(x=2.668, y=2.4923)], span=DocumentSpan(offset=1490, length=12), confidence=0.991), DocumentWord(content=Lat., polygon=[Point(x=3.8054, y=2.3312), Point(x=4.175, y=2.3264), Point(x=4.175, y=2.4923), Point(x=3.8054, y=2.497)], span=DocumentSpan(offset=1503, length=4), confidence=0.959), DocumentWord(content=9º, polygon=[Point(x=4.2319, y=2.3264), Point(x=4.4262, y=2.3217), Point(x=4.4309, y=2.4923), Point(x=4.2366, y=2.4923)], span=DocumentSpan(offset=1508, length=2), confidence=0.458), DocumentWord(content=39', polygon=[Point(x=4.4735, y=2.3217), Point(x=4.7579, y=2.3217), Point(x=4.7579, y=2.4923), Point(x=4.4783, y=2.4923)], span=DocumentSpan(offset=1511, length=3), confidence=0.616), DocumentWord(content=14\", polygon=[Point(x=4.8053, y=2.3169), Point(x=5.0754, y=2.3169), Point(x=5.0754, y=2.4875), Point(x=4.8053, y=2.4923)], span=DocumentSpan(offset=1515, length=3), confidence=0.808), DocumentWord(content=-, polygon=[Point(x=5.1323, y=2.3122), Point(x=5.227, y=2.3122), Point(x=5.2318, y=2.4875), Point(x=5.137, y=2.4875)], span=DocumentSpan(offset=1519, length=1), confidence=0.969), DocumentWord(content=Long., polygon=[Point(x=5.2981, y=2.3122), Point(x=5.7673, y=2.3027), Point(x=5.7673, y=2.4828), Point(x=5.2981, y=2.4875)], span=DocumentSpan(offset=1521, length=5), confidence=0.991), DocumentWord(content=82', polygon=[Point(x=5.8004, y=2.3027), Point(x=6.0848, y=2.298), Point(x=6.0895, y=2.478), Point(x=5.8052, y=2.4828)], span=DocumentSpan(offset=1527, length=3), confidence=0.684), DocumentWord(content=48', polygon=[Point(x=6.1322, y=2.298), Point(x=6.426, y=2.2933), Point(x=6.426, y=2.4733), Point(x=6.1322, y=2.478)], span=DocumentSpan(offset=1531, length=3), confidence=0.846), DocumentWord(content=10\", polygon=[Point(x=6.4734, y=2.2933), Point(x=6.7435, y=2.2885), Point(x=6.7482, y=2.4638), Point(x=6.4734, y=2.4686)], span=DocumentSpan(offset=1535, length=3), confidence=0.315), DocumentWord(content=Dates:, polygon=[Point(x=1.725, y=2.6865), Point(x=2.2652, y=2.6723), Point(x=2.2652, y=2.8476), Point(x=1.725, y=2.8571)], span=DocumentSpan(offset=1539, length=6), confidence=0.992), DocumentWord(content=Commenced:, polygon=[Point(x=2.3932, y=2.6723), Point(x=3.2746, y=2.6534), Point(x=3.2793, y=2.8239), Point(x=2.3932, y=2.8476)], span=DocumentSpan(offset=1546, length=10), confidence=0.801), DocumentWord(content=2/23/55, polygon=[Point(x=3.4026, y=2.6581), Point(x=4.0186, y=2.6534), Point(x=4.0186, y=2.8334), Point(x=3.4026, y=2.8239)], span=DocumentSpan(offset=1557, length=7), confidence=0.931), DocumentWord(content=Completed:, polygon=[Point(x=2.4074, y=2.8524), Point(x=3.2651, y=2.8381), Point(x=3.2699, y=3.0135), Point(x=2.4074, y=3.0182)], span=DocumentSpan(offset=1565, length=10), confidence=0.955), DocumentWord(content=4/19/55, polygon=[Point(x=3.3978, y=2.8334), Point(x=4.0139, y=2.8334), Point(x=4.0091, y=3.0087), Point(x=3.3978, y=3.004)], span=DocumentSpan(offset=1576, length=7), confidence=0.995), DocumentWord(content=Status:, polygon=[Point(x=1.7439, y=3.1746), Point(x=2.3458, y=3.1698), Point(x=2.3505, y=3.3356), Point(x=1.7487, y=3.3356)], span=DocumentSpan(offset=1584, length=7), confidence=0.993), DocumentWord(content=D, polygon=[Point(x=2.4785, y=3.1698), Point(x=2.5732, y=3.1698), Point(x=2.5732, y=3.3309), Point(x=2.4785, y=3.3309)], span=DocumentSpan(offset=1592, length=1), confidence=0.995), DocumentWord(content=&, polygon=[Point(x=2.6491, y=3.1651), Point(x=2.7438, y=3.1651), Point(x=2.7438, y=3.3262), Point(x=2.6491, y=3.3309)], span=DocumentSpan(offset=1594, length=1), confidence=0.995), DocumentWord(content=A, polygon=[Point(x=2.8102, y=3.1651), Point(x=2.905, y=3.1603), Point(x=2.905, y=3.3262), Point(x=2.8102, y=3.3262)], span=DocumentSpan(offset=1596, length=1), confidence=0.993), DocumentWord(content=Total, polygon=[Point(x=1.7392, y=3.5062), Point(x=2.1894, y=3.5015), Point(x=2.1894, y=3.6863), Point(x=1.7392, y=3.6863)], span=DocumentSpan(offset=1598, length=5), confidence=0.996), DocumentWord(content=Depth:, polygon=[Point(x=2.2273, y=3.5015), Point(x=2.7723, y=3.5015), Point(x=2.7723, y=3.6815), Point(x=2.2273, y=3.6863)], span=DocumentSpan(offset=1604, length=6), confidence=0.996), DocumentWord(content=10,128', polygon=[Point(x=2.8955, y=3.5015), Point(x=3.521, y=3.4967), Point(x=3.5258, y=3.6721), Point(x=2.8955, y=3.6768)], span=DocumentSpan(offset=1611, length=7), confidence=0.934), DocumentWord(content=formation, polygon=[Point(x=3.5732, y=3.4967), Point(x=4.3456, y=3.492), Point(x=4.3503, y=3.6673), Point(x=3.5779, y=3.6721)], span=DocumentSpan(offset=1619, length=9), confidence=0.993), DocumentWord(content=unknown, polygon=[Point(x=4.393, y=3.492), Point(x=5.0138, y=3.4873), Point(x=5.0185, y=3.6626), Point(x=4.3977, y=3.6673)], span=DocumentSpan(offset=1629, length=7), confidence=0.991), DocumentWord(content=as, polygon=[Point(x=5.0612, y=3.4873), Point(x=5.2602, y=3.4825), Point(x=5.265, y=3.6626), Point(x=5.0659, y=3.6626)], span=DocumentSpan(offset=1637, length=2), confidence=0.996), DocumentWord(content=yet., polygon=[Point(x=5.3123, y=3.4825), Point(x=5.6915, y=3.4778), Point(x=5.6962, y=3.6626), Point(x=5.3171, y=3.6626)], span=DocumentSpan(offset=1640, length=4), confidence=0.932), DocumentWord(content=Probably, polygon=[Point(x=5.8004, y=3.4778), Point(x=6.5018, y=3.4683), Point(x=6.5065, y=3.6578), Point(x=5.8052, y=3.6626)], span=DocumentSpan(offset=1645, length=8), confidence=0.67), DocumentWord(content=Eocene., polygon=[Point(x=6.5397, y=3.4683), Point(x=7.151, y=3.4636), Point(x=7.1558, y=3.6578), Point(x=6.5445, y=3.6578)], span=DocumentSpan(offset=1654, length=7), confidence=0.67), DocumentWord(content=Shows:, polygon=[Point(x=1.7439, y=3.8379), Point(x=2.2699, y=3.8379), Point(x=2.2652, y=3.999), Point(x=1.7392, y=3.999)], span=DocumentSpan(offset=1662, length=6), confidence=0.972), DocumentWord(content=No, polygon=[Point(x=2.3884, y=3.8379), Point(x=2.5922, y=3.8379), Point(x=2.5922, y=4.0037), Point(x=2.3884, y=4.0037)], span=DocumentSpan(offset=1669, length=2), confidence=0.996), DocumentWord(content=oil, polygon=[Point(x=2.6491, y=3.8379), Point(x=2.9287, y=3.8379), Point(x=2.9287, y=4.0037), Point(x=2.6491, y=4.0037)], span=DocumentSpan(offset=1672, length=3), confidence=0.884), DocumentWord(content=or, polygon=[Point(x=2.9903, y=3.8379), Point(x=3.1798, y=3.8379), Point(x=3.1798, y=4.0037), Point(x=2.9855, y=4.0037)], span=DocumentSpan(offset=1676, length=2), confidence=0.997), DocumentWord(content=gas, polygon=[Point(x=3.2509, y=3.8379), Point(x=3.5163, y=3.8379), Point(x=3.5163, y=4.0037), Point(x=3.2462, y=4.0037)], span=DocumentSpan(offset=1679, length=3), confidence=0.994), DocumentWord(content=shows., polygon=[Point(x=3.5732, y=3.8379), Point(x=4.0992, y=3.8379), Point(x=4.0992, y=4.0037), Point(x=3.5732, y=4.0037)], span=DocumentSpan(offset=1683, length=6), confidence=0.995), DocumentWord(content=DST's:, polygon=[Point(x=1.7439, y=4.1648), Point(x=2.2699, y=4.1696), Point(x=2.2699, y=4.3259), Point(x=1.7439, y=4.3259)], span=DocumentSpan(offset=1690, length=6), confidence=0.966), DocumentWord(content=None., polygon=[Point(x=2.4026, y=4.1743), Point(x=2.8434, y=4.1933), Point(x=2.8434, y=4.3259), Point(x=2.4026, y=4.3259)], span=DocumentSpan(offset=1697, length=5), confidence=0.955), DocumentWord(content=Location, polygon=[Point(x=1.7439, y=4.5107), Point(x=2.4263, y=4.506), Point(x=2.4263, y=4.6718), Point(x=1.7439, y=4.6718)], span=DocumentSpan(offset=1703, length=8), confidence=0.994), DocumentWord(content=based, polygon=[Point(x=2.4832, y=4.506), Point(x=2.9287, y=4.506), Point(x=2.9334, y=4.6671), Point(x=2.4879, y=4.6718)], span=DocumentSpan(offset=1712, length=5), confidence=0.997), DocumentWord(content=on:, polygon=[Point(x=2.9997, y=4.506), Point(x=3.2699, y=4.5012), Point(x=3.2699, y=4.6671), Point(x=2.9997, y=4.6671)], span=DocumentSpan(offset=1718, length=3), confidence=0.996), DocumentWord(content=Surface:, polygon=[Point(x=3.3931, y=4.5012), Point(x=4.0992, y=4.4965), Point(x=4.1039, y=4.6623), Point(x=3.3931, y=4.6671)], span=DocumentSpan(offset=1722, length=8), confidence=0.991), DocumentWord(content=Puerto, polygon=[Point(x=4.2319, y=4.4965), Point(x=4.7674, y=4.487), Point(x=4.7674, y=4.6576), Point(x=4.2366, y=4.6623)], span=DocumentSpan(offset=1731, length=6), confidence=0.733), DocumentWord(content=Viejo, polygon=[Point(x=4.8242, y=4.487), Point(x=5.2697, y=4.4823), Point(x=5.2744, y=4.6529), Point(x=4.829, y=4.6576)], span=DocumentSpan(offset=1738, length=5), confidence=0.934), DocumentWord(content=Anticline., polygon=[Point(x=5.3029, y=4.4823), Point(x=6.1843, y=4.4728), Point(x=6.1843, y=4.6481), Point(x=5.3076, y=4.6529)], span=DocumentSpan(offset=1744, length=10), confidence=0.991), DocumentWord(content=General, polygon=[Point(x=1.7487, y=4.8376), Point(x=2.3552, y=4.8376), Point(x=2.36, y=5.0129), Point(x=1.7534, y=5.0082)], span=DocumentSpan(offset=1755, length=7), confidence=0.522), DocumentWord(content=Dip, polygon=[Point(x=2.4074, y=4.8376), Point(x=2.6822, y=4.8376), Point(x=2.687, y=5.0129), Point(x=2.4121, y=5.0129)], span=DocumentSpan(offset=1763, length=3), confidence=0.997), DocumentWord(content=-, polygon=[Point(x=2.7391, y=4.8376), Point(x=2.8434, y=4.8329), Point(x=2.8481, y=5.0129), Point(x=2.7438, y=5.0129)], span=DocumentSpan(offset=1767, length=1), confidence=0.98), DocumentWord(content=SW, polygon=[Point(x=2.905, y=4.8329), Point(x=3.0945, y=4.8329), Point(x=3.104, y=5.0082), Point(x=2.9097, y=5.0129)], span=DocumentSpan(offset=1769, length=2), confidence=0.97), DocumentWord(content=55º., polygon=[Point(x=3.1703, y=4.8282), Point(x=3.5068, y=4.8234), Point(x=3.5115, y=4.9987), Point(x=3.1751, y=5.0082)], span=DocumentSpan(offset=1772, length=4), confidence=0.711), DocumentWord(content=Electric, polygon=[Point(x=1.7392, y=5.1646), Point(x=2.4358, y=5.1788), Point(x=2.4358, y=5.3399), Point(x=1.7439, y=5.3304)], span=DocumentSpan(offset=1777, length=8), confidence=0.851), DocumentWord(content=Log:, polygon=[Point(x=2.4879, y=5.1835), Point(x=2.8623, y=5.1788), Point(x=2.8671, y=5.3494), Point(x=2.4927, y=5.3446)], span=DocumentSpan(offset=1786, length=4), confidence=0.939), DocumentWord(content=Shale, polygon=[Point(x=2.9855, y=5.1693), Point(x=3.431, y=5.1646), Point(x=3.4262, y=5.3304), Point(x=2.9808, y=5.3351)], span=DocumentSpan(offset=1791, length=5), confidence=0.997), DocumentWord(content=line, polygon=[Point(x=3.4879, y=5.1646), Point(x=3.8575, y=5.1598), Point(x=3.8527, y=5.3304), Point(x=3.4879, y=5.3304)], span=DocumentSpan(offset=1797, length=4), confidence=0.955), DocumentWord(content=thruout., polygon=[Point(x=3.9144, y=5.1598), Point(x=4.592, y=5.1551), Point(x=4.592, y=5.3257), Point(x=3.9144, y=5.3257)], span=DocumentSpan(offset=1802, length=8), confidence=0.994), DocumentWord(content=3,500, polygon=[Point(x=3.0045, y=5.501), Point(x=3.4168, y=5.4962), Point(x=3.4215, y=5.6621), Point(x=3.0045, y=5.6715)], span=DocumentSpan(offset=1811, length=5), confidence=0.991), DocumentWord(content=-, polygon=[Point(x=3.5021, y=5.4962), Point(x=3.5921, y=5.4962), Point(x=3.5921, y=5.6573), Point(x=3.5021, y=5.6573)], span=DocumentSpan(offset=1817, length=1), confidence=0.998), DocumentWord(content=Fresh, polygon=[Point(x=3.6537, y=5.4962), Point(x=4.0897, y=5.501), Point(x=4.0944, y=5.6526), Point(x=3.6585, y=5.6573)], span=DocumentSpan(offset=1819, length=5), confidence=0.98), DocumentWord(content=water., polygon=[Point(x=4.156, y=5.501), Point(x=4.6868, y=5.5057), Point(x=4.6915, y=5.6479), Point(x=4.1608, y=5.6526)], span=DocumentSpan(offset=1825, length=6), confidence=0.995), DocumentWord(content=3,880, polygon=[Point(x=3.0092, y=5.6668), Point(x=3.431, y=5.6668), Point(x=3.431, y=5.8279), Point(x=3.0092, y=5.8326)], span=DocumentSpan(offset=1832, length=5), confidence=0.955), DocumentWord(content=-, polygon=[Point(x=3.4973, y=5.6668), Point(x=3.5921, y=5.6668), Point(x=3.5921, y=5.8279), Point(x=3.5021, y=5.8279)], span=DocumentSpan(offset=1838, length=1), confidence=0.998), DocumentWord(content=3,920, polygon=[Point(x=3.6585, y=5.6621), Point(x=4.0944, y=5.6621), Point(x=4.0944, y=5.8232), Point(x=3.6585, y=5.8279)], span=DocumentSpan(offset=1840, length=5), confidence=0.926), DocumentWord(content=-, polygon=[Point(x=4.1608, y=5.6621), Point(x=4.2556, y=5.6621), Point(x=4.2508, y=5.8232), Point(x=4.1608, y=5.8232)], span=DocumentSpan(offset=1846, length=1), confidence=0.998), DocumentWord(content=Fresh, polygon=[Point(x=4.3219, y=5.6621), Point(x=4.7674, y=5.6573), Point(x=4.7626, y=5.8184), Point(x=4.3219, y=5.8232)], span=DocumentSpan(offset=1848, length=5), confidence=0.996), DocumentWord(content=water., polygon=[Point(x=4.8195, y=5.6573), Point(x=5.3455, y=5.6573), Point(x=5.3455, y=5.8184), Point(x=4.8195, y=5.8184)], span=DocumentSpan(offset=1854, length=6), confidence=0.996), DocumentWord(content=4,270, polygon=[Point(x=3.0045, y=5.8326), Point(x=3.431, y=5.8374), Point(x=3.4357, y=5.9985), Point(x=3.0045, y=6.0032)], span=DocumentSpan(offset=1861, length=5), confidence=0.995), DocumentWord(content=-, polygon=[Point(x=3.5021, y=5.8374), Point(x=3.5968, y=5.8374), Point(x=3.5968, y=5.9985), Point(x=3.5021, y=5.9985)], span=DocumentSpan(offset=1867, length=1), confidence=0.996), DocumentWord(content=4,310), polygon=[Point(x=3.6632, y=5.8374), Point(x=4.175, y=5.8184), Point(x=4.1797, y=5.989), Point(x=3.6679, y=5.9985)], span=DocumentSpan(offset=1869, length=6), confidence=0.995), DocumentWord(content=4,380, polygon=[Point(x=3.0045, y=6.008), Point(x=3.4262, y=5.9937), Point(x=3.431, y=6.1548), Point(x=3.0092, y=6.1691)], span=DocumentSpan(offset=1876, length=5), confidence=0.995), DocumentWord(content=6,640, polygon=[Point(x=3.014, y=6.1596), Point(x=3.4405, y=6.1643), Point(x=3.4357, y=6.3302), Point(x=3.0092, y=6.3349)], span=DocumentSpan(offset=1882, length=5), confidence=0.994), DocumentWord(content=-, polygon=[Point(x=3.5021, y=6.1643), Point(x=3.6016, y=6.1596), Point(x=3.5968, y=6.3302), Point(x=3.4973, y=6.3302)], span=DocumentSpan(offset=1888, length=1), confidence=0.89), DocumentWord(content=6,660), polygon=[Point(x=3.6727, y=6.1596), Point(x=4.1797, y=6.1501), Point(x=4.175, y=6.3349), Point(x=3.6679, y=6.3302)], span=DocumentSpan(offset=1890, length=6), confidence=0.993), DocumentWord(content=6,750, polygon=[Point(x=3.014, y=6.3254), Point(x=3.4452, y=6.3302), Point(x=3.4452, y=6.5055), Point(x=3.0092, y=6.5149)], span=DocumentSpan(offset=1897, length=5), confidence=0.993), DocumentWord(content=-, polygon=[Point(x=3.4973, y=6.3302), Point(x=3.6016, y=6.3302), Point(x=3.6016, y=6.5055), Point(x=3.4973, y=6.5055)], span=DocumentSpan(offset=1903, length=1), confidence=0.994), DocumentWord(content=6,860), polygon=[Point(x=3.6632, y=6.3302), Point(x=4.194, y=6.3207), Point(x=4.194, y=6.5102), Point(x=3.6632, y=6.5055)], span=DocumentSpan(offset=1905, length=6), confidence=0.991), DocumentWord(content=Probably, polygon=[Point(x=4.2366, y=5.9937), Point(x=4.938, y=5.989), Point(x=4.938, y=6.1596), Point(x=4.2366, y=6.1596)], span=DocumentSpan(offset=1912, length=8), confidence=0.996), DocumentWord(content=salt, polygon=[Point(x=4.9996, y=5.989), Point(x=5.355, y=5.9843), Point(x=5.355, y=6.1596), Point(x=4.9996, y=6.1596)], span=DocumentSpan(offset=1921, length=4), confidence=0.988), DocumentWord(content=water., polygon=[Point(x=5.4119, y=5.9843), Point(x=5.9284, y=5.9843), Point(x=5.9331, y=6.1501), Point(x=5.4119, y=6.1548)], span=DocumentSpan(offset=1926, length=6), confidence=0.996), DocumentWord(content=Log, polygon=[Point(x=2.9997, y=6.6618), Point(x=3.2746, y=6.6618), Point(x=3.2746, y=6.8324), Point(x=2.9997, y=6.8324)], span=DocumentSpan(offset=1933, length=3), confidence=0.992), DocumentWord(content=indicates, polygon=[Point(x=3.3315, y=6.6618), Point(x=4.1134, y=6.6618), Point(x=4.1134, y=6.8371), Point(x=3.3362, y=6.8324)], span=DocumentSpan(offset=1937, length=9), confidence=0.993), DocumentWord(content=poor, polygon=[Point(x=4.1608, y=6.6618), Point(x=4.5162, y=6.6618), Point(x=4.5209, y=6.8324), Point(x=4.1608, y=6.8371)], span=DocumentSpan(offset=1947, length=4), confidence=0.989), DocumentWord(content=prospects, polygon=[Point(x=4.5778, y=6.6618), Point(x=5.355, y=6.6571), Point(x=5.3597, y=6.8277), Point(x=4.5825, y=6.8324)], span=DocumentSpan(offset=1952, length=9), confidence=0.946), DocumentWord(content=for, polygon=[Point(x=5.4119, y=6.6523), Point(x=5.6962, y=6.6523), Point(x=5.7009, y=6.8229), Point(x=5.4166, y=6.8277)], span=DocumentSpan(offset=1962, length=3), confidence=0.995), DocumentWord(content=oil, polygon=[Point(x=5.7436, y=6.6523), Point(x=6.0232, y=6.6476), Point(x=6.0279, y=6.8182), Point(x=5.7483, y=6.8229)], span=DocumentSpan(offset=1966, length=3), confidence=0.616), DocumentWord(content=production, polygon=[Point(x=6.08, y=6.6429), Point(x=6.9378, y=6.6287), Point(x=6.9473, y=6.7992), Point(x=6.0895, y=6.8182)], span=DocumentSpan(offset=1970, length=10), confidence=0.991), DocumentWord(content=because, polygon=[Point(x=3.0092, y=6.8419), Point(x=3.5968, y=6.8371), Point(x=3.5968, y=6.9935), Point(x=3.014, y=6.9935)], span=DocumentSpan(offset=1981, length=7), confidence=0.994), DocumentWord(content=of, polygon=[Point(x=3.6679, y=6.8371), Point(x=3.848, y=6.8371), Point(x=3.8527, y=6.9935), Point(x=3.6727, y=6.9935)], span=DocumentSpan(offset=1989, length=2), confidence=0.997), DocumentWord(content=shaly, polygon=[Point(x=3.9238, y=6.8371), Point(x=4.3503, y=6.8371), Point(x=4.3551, y=6.9935), Point(x=3.9286, y=6.9935)], span=DocumentSpan(offset=1992, length=5), confidence=0.997), DocumentWord(content=nature., polygon=[Point(x=4.4119, y=6.8371), Point(x=5.0185, y=6.8371), Point(x=5.0233, y=6.9888), Point(x=4.4167, y=6.9935)], span=DocumentSpan(offset=1998, length=7), confidence=0.809), DocumentWord(content=Note:, polygon=[Point(x=1.7534, y=7.1878), Point(x=2.1989, y=7.1783), Point(x=2.1989, y=7.3394), Point(x=1.7534, y=7.3346)], span=DocumentSpan(offset=2006, length=5), confidence=0.673), DocumentWord(content=Attempted, polygon=[Point(x=2.3268, y=7.1783), Point(x=3.1087, y=7.1688), Point(x=3.1087, y=7.3394), Point(x=2.3268, y=7.3394)], span=DocumentSpan(offset=2012, length=9), confidence=0.899), DocumentWord(content=to, polygon=[Point(x=3.1798, y=7.1641), Point(x=3.3646, y=7.1641), Point(x=3.3646, y=7.3394), Point(x=3.1751, y=7.3394)], span=DocumentSpan(offset=2022, length=2), confidence=0.997), DocumentWord(content=run, polygon=[Point(x=3.4262, y=7.1641), Point(x=3.6916, y=7.1593), Point(x=3.6916, y=7.3346), Point(x=3.4215, y=7.3394)], span=DocumentSpan(offset=2025, length=3), confidence=0.997), DocumentWord(content=E, polygon=[Point(x=3.739, y=7.1593), Point(x=3.8338, y=7.1593), Point(x=3.8338, y=7.3346), Point(x=3.739, y=7.3346)], span=DocumentSpan(offset=2029, length=1), confidence=0.964), DocumentWord(content=log, polygon=[Point(x=3.9191, y=7.1593), Point(x=4.194, y=7.1546), Point(x=4.194, y=7.3346), Point(x=3.9144, y=7.3346)], span=DocumentSpan(offset=2031, length=3), confidence=0.991), DocumentWord(content=to, polygon=[Point(x=4.265, y=7.1546), Point(x=4.4404, y=7.1546), Point(x=4.4404, y=7.3346), Point(x=4.265, y=7.3346)], span=DocumentSpan(offset=2035, length=2), confidence=0.996), DocumentWord(content=TD, polygon=[Point(x=4.5115, y=7.1546), Point(x=4.6868, y=7.1498), Point(x=4.6868, y=7.3346), Point(x=4.5115, y=7.3346)], span=DocumentSpan(offset=2038, length=2), confidence=0.956), DocumentWord(content=of, polygon=[Point(x=4.7579, y=7.1498), Point(x=4.9427, y=7.1498), Point(x=4.9427, y=7.3299), Point(x=4.7579, y=7.3346)], span=DocumentSpan(offset=2041, length=2), confidence=0.997), DocumentWord(content=10,128', polygon=[Point(x=4.9948, y=7.1498), Point(x=5.6156, y=7.1451), Point(x=5.6156, y=7.3252), Point(x=4.9901, y=7.3299)], span=DocumentSpan(offset=2044, length=7), confidence=0.901), DocumentWord(content=but, polygon=[Point(x=5.663, y=7.1451), Point(x=5.9426, y=7.1451), Point(x=5.9426, y=7.3252), Point(x=5.663, y=7.3252)], span=DocumentSpan(offset=2052, length=3), confidence=0.997), DocumentWord(content=cable, polygon=[Point(x=5.9995, y=7.1451), Point(x=6.4449, y=7.1451), Point(x=6.4449, y=7.3204), Point(x=5.9995, y=7.3252)], span=DocumentSpan(offset=2056, length=5), confidence=0.997), DocumentWord(content=would, polygon=[Point(x=6.4923, y=7.1451), Point(x=6.9378, y=7.1451), Point(x=6.9378, y=7.3157), Point(x=6.4923, y=7.3204)], span=DocumentSpan(offset=2062, length=5), confidence=0.997), DocumentWord(content=not, polygon=[Point(x=6.9994, y=7.1451), Point(x=7.2743, y=7.1451), Point(x=7.2743, y=7.3109), Point(x=6.9994, y=7.3157)], span=DocumentSpan(offset=2068, length=3), confidence=0.997), DocumentWord(content=go, polygon=[Point(x=7.3311, y=7.1451), Point(x=7.5302, y=7.1451), Point(x=7.5302, y=7.3062), Point(x=7.3311, y=7.3109)], span=DocumentSpan(offset=2072, length=2), confidence=0.997), DocumentWord(content=below, polygon=[Point(x=2.3505, y=7.3441), Point(x=2.7675, y=7.3394), Point(x=2.7675, y=7.5005), Point(x=2.3505, y=7.4957)], span=DocumentSpan(offset=2075, length=5), confidence=0.965), DocumentWord(content=8,050', polygon=[Point(x=2.8339, y=7.3394), Point(x=3.3315, y=7.3346), Point(x=3.3315, y=7.5099), Point(x=2.8339, y=7.5005)], span=DocumentSpan(offset=2081, length=6), confidence=0.855), DocumentWord(content=., polygon=[Point(x=3.3646, y=7.3346), Point(x=3.4499, y=7.3346), Point(x=3.4499, y=7.5099), Point(x=3.3646, y=7.5099)], span=DocumentSpan(offset=2088, length=1), confidence=0.947), DocumentWord(content=List, polygon=[Point(x=1.7581, y=7.6853), Point(x=2.1325, y=7.6758), Point(x=2.1325, y=7.8274), Point(x=1.7581, y=7.8274)], span=DocumentSpan(offset=2090, length=4), confidence=0.985), DocumentWord(content=of, polygon=[Point(x=2.1752, y=7.6758), Point(x=2.3837, y=7.671), Point(x=2.3837, y=7.8274), Point(x=2.1799, y=7.8274)], span=DocumentSpan(offset=2095, length=2), confidence=0.987), DocumentWord(content=material, polygon=[Point(x=2.4263, y=7.671), Point(x=3.1372, y=7.6616), Point(x=3.1372, y=7.8274), Point(x=2.4311, y=7.8274)], span=DocumentSpan(offset=2098, length=8), confidence=0.888), DocumentWord(content=received, polygon=[Point(x=3.1798, y=7.6616), Point(x=3.867, y=7.6616), Point(x=3.867, y=7.8321), Point(x=3.1798, y=7.8274)], span=DocumentSpan(offset=2107, length=8), confidence=0.884), DocumentWord(content=to, polygon=[Point(x=3.9333, y=7.6616), Point(x=4.1418, y=7.6663), Point(x=4.1418, y=7.8321), Point(x=3.9333, y=7.8321)], span=DocumentSpan(offset=2116, length=2), confidence=0.994), DocumentWord(content=date:, polygon=[Point(x=4.1845, y=7.6663), Point(x=4.6015, y=7.671), Point(x=4.6015, y=7.8321), Point(x=4.1845, y=7.8321)], span=DocumentSpan(offset=2119, length=5), confidence=0.975), DocumentWord(content=Electric, polygon=[Point(x=2.014, y=8.0169), Point(x=2.687, y=8.0075), Point(x=2.687, y=8.1591), Point(x=2.014, y=8.1638)], span=DocumentSpan(offset=2125, length=8), confidence=0.922), DocumentWord(content=lors, polygon=[Point(x=2.7675, y=8.0122), Point(x=3.1182, y=8.0169), Point(x=3.1135, y=8.1685), Point(x=2.7675, y=8.1638)], span=DocumentSpan(offset=2134, length=4), confidence=0.521), DocumentWord(content=Run, polygon=[Point(x=2.2463, y=8.178), Point(x=2.5258, y=8.178), Point(x=2.5258, y=8.3249), Point(x=2.251, y=8.3202)], span=DocumentSpan(offset=2139, length=3), confidence=0.991), DocumentWord(content=1, polygon=[Point(x=2.5969, y=8.178), Point(x=2.6775, y=8.178), Point(x=2.6822, y=8.3296), Point(x=2.5969, y=8.3296)], span=DocumentSpan(offset=2143, length=1), confidence=0.544), DocumentWord(content=0, polygon=[Point(x=3.0993, y=8.1591), Point(x=3.194, y=8.1591), Point(x=3.194, y=8.3296), Point(x=3.104, y=8.3296)], span=DocumentSpan(offset=2145, length=1), confidence=0.994), DocumentWord(content=-, polygon=[Point(x=3.2604, y=8.1591), Point(x=3.3504, y=8.1591), Point(x=3.3552, y=8.3249), Point(x=3.2604, y=8.3296)], span=DocumentSpan(offset=2147, length=1), confidence=0.86), DocumentWord(content=1,130', polygon=[Point(x=3.4168, y=8.1591), Point(x=3.9238, y=8.1496), Point(x=3.9286, y=8.3012), Point(x=3.4215, y=8.3249)], span=DocumentSpan(offset=2149, length=6), confidence=0.787), DocumentWord(content=Run, polygon=[Point(x=2.2605, y=8.3439), Point(x=2.5353, y=8.3391), Point(x=2.5353, y=8.505), Point(x=2.2605, y=8.505)], span=DocumentSpan(offset=2156, length=3), confidence=0.997), DocumentWord(content=3, polygon=[Point(x=2.5922, y=8.3391), Point(x=2.6965, y=8.3391), Point(x=2.6965, y=8.5097), Point(x=2.5922, y=8.505)], span=DocumentSpan(offset=2160, length=1), confidence=0.995), DocumentWord(content=2,1001, polygon=[Point(x=3.104, y=8.3344), Point(x=3.6205, y=8.3296), Point(x=3.6158, y=8.4955), Point(x=3.104, y=8.505)], span=DocumentSpan(offset=2162, length=6), confidence=0.625), DocumentWord(content=-, polygon=[Point(x=3.6774, y=8.3296), Point(x=3.7722, y=8.3296), Point(x=3.7674, y=8.4955), Point(x=3.6727, y=8.4955)], span=DocumentSpan(offset=2169, length=1), confidence=0.993), DocumentWord(content=3,051', polygon=[Point(x=3.8527, y=8.3249), Point(x=4.3361, y=8.3249), Point(x=4.3314, y=8.4907), Point(x=3.848, y=8.4955)], span=DocumentSpan(offset=2171, length=6), confidence=0.637), DocumentWord(content=Run, polygon=[Point(x=2.251, y=8.5144), Point(x=2.5116, y=8.5192), Point(x=2.5164, y=8.6518), Point(x=2.2605, y=8.6518)], span=DocumentSpan(offset=2178, length=3), confidence=0.997), DocumentWord(content=4, polygon=[Point(x=2.6017, y=8.5239), Point(x=2.6822, y=8.5286), Point(x=2.6822, y=8.6613), Point(x=2.6064, y=8.6613)], span=DocumentSpan(offset=2182, length=1), confidence=0.996), DocumentWord(content=2,9501, polygon=[Point(x=3.1135, y=8.505), Point(x=3.6205, y=8.5002), Point(x=3.6158, y=8.6708), Point(x=3.104, y=8.6661)], span=DocumentSpan(offset=2184, length=6), confidence=0.623), DocumentWord(content=-, polygon=[Point(x=3.6821, y=8.5002), Point(x=3.7769, y=8.4955), Point(x=3.7722, y=8.6708), Point(x=3.6727, y=8.6708)], span=DocumentSpan(offset=2191, length=1), confidence=0.994), DocumentWord(content=4,368', polygon=[Point(x=3.8338, y=8.4955), Point(x=4.3409, y=8.4813), Point(x=4.3361, y=8.6518), Point(x=3.8291, y=8.6708)], span=DocumentSpan(offset=2193, length=6), confidence=0.661), DocumentWord(content=Composite, polygon=[Point(x=2.2699, y=8.6803), Point(x=3.0661, y=8.6755), Point(x=3.0613, y=8.8319), Point(x=2.2652, y=8.8319)], span=DocumentSpan(offset=2200, length=9), confidence=0.965), DocumentWord(content=Log, polygon=[Point(x=3.1087, y=8.6755), Point(x=3.3883, y=8.6708), Point(x=3.3836, y=8.8319), Point(x=3.1087, y=8.8319)], span=DocumentSpan(offset=2210, length=3), confidence=0.997), DocumentWord(content=Runs, polygon=[Point(x=3.4215, y=8.6708), Point(x=3.7959, y=8.6661), Point(x=3.7911, y=8.8271), Point(x=3.4168, y=8.8319)], span=DocumentSpan(offset=2214, length=4), confidence=0.988), DocumentWord(content=1, polygon=[Point(x=3.867, y=8.6661), Point(x=3.9712, y=8.6613), Point(x=3.9712, y=8.8271), Point(x=3.8622, y=8.8271)], span=DocumentSpan(offset=2219, length=1), confidence=0.969), DocumentWord(content=thru, polygon=[Point(x=4.0186, y=8.6613), Point(x=4.393, y=8.6566), Point(x=4.393, y=8.8271), Point(x=4.0186, y=8.8271)], span=DocumentSpan(offset=2221, length=4), confidence=0.991), DocumentWord(content=8, polygon=[Point(x=4.4404, y=8.6566), Point(x=4.5494, y=8.6518), Point(x=4.5494, y=8.8271), Point(x=4.4404, y=8.8271)], span=DocumentSpan(offset=2226, length=1), confidence=0.956), DocumentWord(content=0, polygon=[Point(x=4.7768, y=8.6471), Point(x=4.8953, y=8.6471), Point(x=4.8953, y=8.8271), Point(x=4.7721, y=8.8271)], span=DocumentSpan(offset=2228, length=1), confidence=0.986), DocumentWord(content=-, polygon=[Point(x=4.9285, y=8.6471), Point(x=5.0612, y=8.6424), Point(x=5.0612, y=8.8271), Point(x=4.9285, y=8.8271)], span=DocumentSpan(offset=2230, length=1), confidence=0.986), DocumentWord(content=9,124', polygon=[Point(x=5.1275, y=8.6424), Point(x=5.5919, y=8.6329), Point(x=5.5919, y=8.8319), Point(x=5.1275, y=8.8271)], span=DocumentSpan(offset=2232, length=6), confidence=0.941), DocumentWord(content=Extra, polygon=[Point(x=2.2652, y=8.8461), Point(x=2.687, y=8.8461), Point(x=2.687, y=8.993), Point(x=2.2652, y=8.993)], span=DocumentSpan(offset=2239, length=5), confidence=0.993), DocumentWord(content=Curves, polygon=[Point(x=2.7486, y=8.8461), Point(x=3.2699, y=8.8461), Point(x=3.2699, y=8.9835), Point(x=2.7486, y=8.993)], span=DocumentSpan(offset=2245, length=6), confidence=0.993), DocumentWord(content=ES-3, polygon=[Point(x=2.5211, y=9.0119), Point(x=2.886, y=9.0072), Point(x=2.8813, y=9.1636), Point(x=2.5164, y=9.1541)], span=DocumentSpan(offset=2252, length=4), confidence=0.954), DocumentWord(content=2,090, polygon=[Point(x=3.194, y=9.0025), Point(x=3.6253, y=8.9977), Point(x=3.6205, y=9.1683), Point(x=3.1893, y=9.1683)], span=DocumentSpan(offset=2257, length=5), confidence=0.745), DocumentWord(content=-, polygon=[Point(x=3.7769, y=8.993), Point(x=3.8812, y=8.993), Point(x=3.8764, y=9.1683), Point(x=3.7722, y=9.1683)], span=DocumentSpan(offset=2263, length=1), confidence=0.944), DocumentWord(content=3,050, polygon=[Point(x=3.9523, y=8.9882), Point(x=4.3835, y=8.9788), Point(x=4.3788, y=9.1493), Point(x=3.9475, y=9.1636)], span=DocumentSpan(offset=2265, length=5), confidence=0.733), DocumentWord(content=ES-3, polygon=[Point(x=2.5069, y=9.173), Point(x=2.8671, y=9.173), Point(x=2.8765, y=9.3294), Point(x=2.5164, y=9.3294)], span=DocumentSpan(offset=2271, length=4), confidence=0.962), DocumentWord(content=50, polygon=[Point(x=2.9381, y=9.1683), Point(x=3.123, y=9.1683), Point(x=3.1277, y=9.3294), Point(x=2.9429, y=9.3294)], span=DocumentSpan(offset=2276, length=2), confidence=0.991), DocumentWord(content=ohms, polygon=[Point(x=3.1656, y=9.1683), Point(x=3.54, y=9.1636), Point(x=3.5447, y=9.3294), Point(x=3.1751, y=9.3294)], span=DocumentSpan(offset=2279, length=4), confidence=0.658), DocumentWord(content=2,1001, polygon=[Point(x=3.6821, y=9.1636), Point(x=4.2082, y=9.1541), Point(x=4.2129, y=9.3247), Point(x=3.6869, y=9.3294)], span=DocumentSpan(offset=2284, length=6), confidence=0.756), DocumentWord(content=-, polygon=[Point(x=4.265, y=9.1541), Point(x=4.3646, y=9.1493), Point(x=4.3646, y=9.3247), Point(x=4.2698, y=9.3247)], span=DocumentSpan(offset=2291, length=1), confidence=0.993), DocumentWord(content=3,060', polygon=[Point(x=4.4309, y=9.1493), Point(x=4.938, y=9.1399), Point(x=4.9427, y=9.3199), Point(x=4.4356, y=9.3247)], span=DocumentSpan(offset=2293, length=6), confidence=0.66), DocumentWord(content=ES-7, polygon=[Point(x=2.5211, y=9.3199), Point(x=2.8671, y=9.3341), Point(x=2.8671, y=9.4858), Point(x=2.5164, y=9.4668)], span=DocumentSpan(offset=2300, length=4), confidence=0.94), DocumentWord(content=6,210', polygon=[Point(x=3.1893, y=9.3152), Point(x=3.7058, y=9.3247), Point(x=3.7058, y=9.4905), Point(x=3.1893, y=9.4858)], span=DocumentSpan(offset=2305, length=6), confidence=0.651), DocumentWord(content=-, polygon=[Point(x=3.7627, y=9.3247), Point(x=3.8575, y=9.3247), Point(x=3.8575, y=9.4905), Point(x=3.7627, y=9.4905)], span=DocumentSpan(offset=2312, length=1), confidence=0.825), DocumentWord(content=7,500', polygon=[Point(x=3.9428, y=9.3294), Point(x=4.4356, y=9.3247), Point(x=4.4356, y=9.4858), Point(x=3.9475, y=9.4905)], span=DocumentSpan(offset=2314, length=6), confidence=0.813), DocumentWord(content=ES-5, polygon=[Point(x=2.5069, y=9.4905), Point(x=2.8765, y=9.4905), Point(x=2.8718, y=9.6658), Point(x=2.5022, y=9.6611)], span=DocumentSpan(offset=2321, length=4), confidence=0.985), DocumentWord(content=4,100', polygon=[Point(x=3.1988, y=9.5), Point(x=3.6964, y=9.4952), Point(x=3.6964, y=9.6753), Point(x=3.1988, y=9.68)], span=DocumentSpan(offset=2326, length=6), confidence=0.943), DocumentWord(content=-, polygon=[Point(x=3.7438, y=9.4952), Point(x=3.8622, y=9.4952), Point(x=3.8622, y=9.6753), Point(x=3.7485, y=9.6753)], span=DocumentSpan(offset=2333, length=1), confidence=0.73), DocumentWord(content=5,290', polygon=[Point(x=3.957, y=9.4905), Point(x=4.4262, y=9.4858), Point(x=4.4309, y=9.6611), Point(x=3.9617, y=9.6753)], span=DocumentSpan(offset=2335, length=6), confidence=0.956)], selection_marks=[], spans=[DocumentSpan(offset=1326, length=1015)])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60375cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyzeResultapi_version</th>\n",
       "      <th>analyzeResult.model_id</th>\n",
       "      <th>analyzeResult.content</th>\n",
       "      <th>analyzeResult.pages</th>\n",
       "      <th>analyzeResult.styles</th>\n",
       "      <th>analyzeResult.paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>prebuilt-read</td>\n",
       "      <td>H012943623 KATALYST DATA MANAGEMENT\\n-\\nCR 1.0...</td>\n",
       "      <td>[DocumentPage(page_number=1, angle=-0.49579998...</td>\n",
       "      <td>[DocumentStyle(is_handwritten=True, spans=[Doc...</td>\n",
       "      <td>[DocumentParagraph(role=None, content=H0129436...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  analyzeResultapi_version analyzeResult.model_id   \n",
       "0               2022-08-31          prebuilt-read  \\\n",
       "\n",
       "                               analyzeResult.content   \n",
       "0  H012943623 KATALYST DATA MANAGEMENT\\n-\\nCR 1.0...  \\\n",
       "\n",
       "                                 analyzeResult.pages   \n",
       "0  [DocumentPage(page_number=1, angle=-0.49579998...  \\\n",
       "\n",
       "                                analyzeResult.styles   \n",
       "0  [DocumentStyle(is_handwritten=True, spans=[Doc...  \\\n",
       "\n",
       "                            analyzeResult.paragraphs  \n",
       "0  [DocumentParagraph(role=None, content=H0129436...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relevant data from the AnalyzeResult object\n",
    "data = {\n",
    "    \"analyzeResultapi_version\": [b.api_version],\n",
    "    \"analyzeResult.model_id\": [b.model_id],\n",
    "    \"analyzeResult.content\": [b.content],\n",
    "    \"analyzeResult.pages\": [b.pages],\n",
    "    \"analyzeResult.styles\": [b.styles],\n",
    "    \"analyzeResult.paragraphs\": [b.paragraphs]\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "analyze_result = pd.DataFrame(data)\n",
    "analyze_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50a63a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/David.Godinez/Desktop/BJSS/exxon3/exxonmobile/files/7b12da4f-7664-433c-9a34-4306c35f1aab_removed.pdf'\n",
    "an_doc = analyze_document(file_path)\n",
    "an_res = analyze_result(an_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bb779bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[DocumentStyle(is_handwritten=True, spans=[DocumentSpan(offset=38, length=7)], confidence=0.95), DocumentStyle(is_handwritten=True, spans=[DocumentSpan(offset=144, length=1)], confidence=0.5), DocumentStyle(is_handwritten=True, spans=[DocumentSpan(offset=438, length=6)], confidence=0.4), DocumentStyle(is_handwritten=True, spans=[DocumentSpan(offset=1295, length=1), DocumentSpan(offset=1326, length=15), DocumentSpan(offset=1374, length=7)], confidence=1.0)]'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an_res['analyzeResult.styles'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7bcae685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentStyle(is_handwritten=True, spans=[DocumentSpan(offset=38, length=7)], confidence=0.95),\n",
       " DocumentStyle(is_handwritten=True, spans=[DocumentSpan(offset=144, length=1)], confidence=0.5),\n",
       " DocumentStyle(is_handwritten=True, spans=[DocumentSpan(offset=438, length=6)], confidence=0.4),\n",
       " DocumentStyle(is_handwritten=True, spans=[DocumentSpan(offset=1295, length=1), DocumentSpan(offset=1326, length=15), DocumentSpan(offset=1374, length=7)], confidence=1.0)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1e721cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_style_dataframe(input_string):\n",
    "    is_handwritten_pattern = re.compile(r\"is_handwritten=([^,]+)\")\n",
    "    span_pattern = re.compile(r\"DocumentSpan\\(offset=(\\d+), length=(\\d+)\\)\")\n",
    "    confidence_pattern = re.compile(r\"confidence=([\\d.]+)\")\n",
    "\n",
    "    is_handwritten_list = is_handwritten_pattern.findall(input_string)\n",
    "    span_list = span_pattern.findall(input_string)\n",
    "    confidence_list = confidence_pattern.findall(input_string)\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(is_handwritten_list)):\n",
    "        data.append({\n",
    "            \"confidence\": confidence_list[i],\n",
    "            \"is_handwritten\": is_handwritten_list[i],\n",
    "            \"offset\": span_list[i][0],\n",
    "            \"length\": span_list[i][1]\n",
    "            \n",
    "        })\n",
    "\n",
    "    df_style_spans = pd.DataFrame(data)\n",
    "\n",
    "    return df_style_spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ec929ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>is_handwritten</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>438</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  confidence is_handwritten offset length\n",
       "0       0.95           True     38      7\n",
       "1        0.5           True    144      1\n",
       "2        0.4           True    438      6\n",
       "3        1.0           True   1295      1"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_style = create_style_dataframe(an_res['analyzeResult.styles'][0])\n",
    "df_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf3df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "        for span in row['spans']:\n",
    "            span['confidence'] = row['confidence']\n",
    "            span['isHandwritten'] = row['isHandwritten']\n",
    "            span['fontStyle'] = row['fontStyle']\n",
    "            span['fontWeight'] = row['fontWeight']\n",
    "            span['similarFontFamily'] = row['similarFontFamily']\n",
    "            span['color'] = row['color']\n",
    "            span['backgroundColor'] = row['backgroundColor']\n",
    "            style_spans.append(span)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c071d71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f768e857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea50387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b77507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ffa16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a798511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb76006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document contains content:  H012943623 KATALYST DATA MANAGEMENT\n",
      "-\n",
      "CR 1.03\n",
      "March 21, 1953\n",
      "Fler CR-30 .\n",
      "Subject: WELL DATA FROM THESE TESTS DRILLSD BY UMION CIL 02 CAL.\n",
      "MACA\n",
      "-\n",
      "Mr. K. A. Kright Producing Coordination 30 Rockefeller Plaza New York 20, N.Y.\n",
      "bear SEx:\n",
      "Tixier separate cover we are sending you well data as Listed in an attachment to this letter frea the following tests drilled by Urdon 011 of California in Costa Rica:\n",
      "Patiño No. 2\n",
      "30,1281\n",
      "Cocoles Bo. 2\n",
      "7,4071\n",
      "Brie No. L\n",
      "7,9691\n",
      "A guneral summary is attached for each wall.\n",
      "The material on there Union 011 of California welle in Central Acerica ves the result of an e reasont signed on January 16, 1958 botwoon Esso Standard 012, 5.A. and Union Oil of Califorde, Union agreed to furnish Esso with information on the wells listed above and Baso agreed to furnish Union with Information from its Balios No. 1 drilled in Cuba and roch other vello Laco drills in the Caribbean ares, that in their opinion the relenen of information is not detrimental to then, The cx- change includes senples and goneral well infomation such as logs, DSTS, etc. and is on a foot for foot tasis ..\n",
      "Wo have the sons set we are sorting you in our Havana office. The purpose of sending you a cot is for security and your use.\n",
      "Very truly yours, E250 STANDARD OIL, S.A .. ORIGINAL SIGNED -\n",
      "--\n",
      "J. Il. Sexpor\n",
      "ÅSter\n",
      "Atts.\n",
      "Costa Rica Pire\n",
      "Union 011 Company of California\n",
      "CR.1.03\n",
      "Pati fo No. 2\n",
      "Location: 5 Kms. southwest of Puerto Viejo in SE Limon Province (Caribbean side), Costa Rica. Coordinates: Lat. 9º 39' 14\" - Long. 82' 48' 10\"\n",
      "Dates: Commenced:\n",
      "2/23/55\n",
      "Completed:\n",
      "4/19/55\n",
      "Status: D & A\n",
      "Total Depth: 10,128' formation unknown as yet. Probably Eocene.\n",
      "Shows: No oil or gas shows.\n",
      "DST's: None.\n",
      "Location based on: Surface: Puerto Viejo Anticline.\n",
      "General Dip - SW 55º.\n",
      "Electric Log:\n",
      "Shale line thruout.\n",
      "3,500 - Fresh water.\n",
      "3,880 - 3,920 - Fresh water.\n",
      "4,270 - 4,310)\n",
      "4,380\n",
      "6,640 - 6,660)\n",
      "6,750 - 6,860)\n",
      "Probably salt water.\n",
      "Log indicates poor prospects for oil production because of shaly nature.\n",
      "Note: Attempted to run E log to TD of 10,128' but cable would not go below 8,050' .\n",
      "List of material received to date:\n",
      "Electric lors\n",
      "Run 1\n",
      "0 - 1,130'\n",
      "Run 3\n",
      "2,1001 - 3,051'\n",
      "Run 4\n",
      "2,9501 - 4,368'\n",
      "Composite Log Runs 1 thru 8 0 - 9,124'\n",
      "Extra Curves\n",
      "ES-3 2,090 - 3,050\n",
      "ES-3 50 ohms 2,1001 - 3,060'\n",
      "ES-7\n",
      "6,210' - 7,500'\n",
      "ES-5\n",
      "4,100' - 5,290'\n",
      "Document contains handwritten content\n",
      "Document contains handwritten content\n",
      "Document contains handwritten content\n",
      "Document contains handwritten content\n",
      "----Analyzing Read from page #1----\n",
      "Page has width: 8.5 and height: 11.0278, measured with unit: inch\n",
      "...Line # 0 has text content 'H012943623' within bounding box '[1.5794, 0.6653], [2.7663, 0.6462], [2.7711, 0.8376], [1.5794, 0.852]'\n",
      "...Line # 1 has text content 'KATALYST DATA MANAGEMENT' within bounding box '[1.5842, 0.8424], [2.7759, 0.8233], [2.7759, 0.9142], [1.5842, 0.9333]'\n",
      "...Line # 2 has text content '-' within bounding box '[6.0974, 0.7419], [6.0639, 0.8137], [6.0256, 0.7945], [6.0639, 0.7227]'\n",
      "...Line # 3 has text content 'CR 1.03' within bounding box '[6.7196, 1.3354], [7.7965, 1.3545], [7.7917, 1.5651], [6.7196, 1.5412]'\n",
      "...Line # 4 has text content 'March 21, 1953' within bounding box '[3.6565, 1.771], [4.8722, 1.747], [4.877, 1.9385], [3.6565, 1.9672]'\n",
      "...Line # 5 has text content 'Fler CR-30 .' within bounding box '[4.9966, 2.2496], [6.1213, 2.2496], [6.1261, 2.4267], [4.9966, 2.4267]'\n",
      "...Line # 6 has text content 'Subject: WELL DATA FROM THESE TESTS' within bounding box '[5.0158, 2.5942], [8.0693, 2.5607], [8.074, 2.7378], [5.0206, 2.7857]'\n",
      "...Line # 7 has text content 'DRILLSD BY UMION CIL 02 CAL.' within bounding box '[5.839, 2.7474], [8.2272, 2.7426], [8.2272, 2.9005], [5.839, 2.9053]'\n",
      "...Line # 8 has text content 'MACA' within bounding box '[7.1312, 2.9436], [7.4614, 2.9388], [7.4566, 3.0585], [7.1312, 3.0728]'\n",
      "...Line # 9 has text content '-' within bounding box '[7.9017, 3.0106], [8.2607, 3.0106], [8.2607, 3.1111], [7.9017, 3.1111]'\n",
      "...Line # 10 has text content 'Mr. K. A. Kright' within bounding box '[1.4693, 3.6424], [2.8716, 3.6376], [2.8764, 3.8147], [1.4693, 3.8291]'\n",
      "...Line # 11 has text content 'Producing Coordination' within bounding box '[1.4693, 3.7908], [3.3742, 3.7908], [3.3694, 3.9679], [1.4693, 3.9679]'\n",
      "...Line # 12 has text content '30 Rockefeller Plaza' within bounding box '[1.4885, 3.9823], [3.2162, 3.9775], [3.2162, 4.1306], [1.4885, 4.1402]'\n",
      "...Line # 13 has text content 'New York 20, N.Y.' within bounding box '[1.4645, 4.145], [2.9434, 4.1402], [2.9482, 4.3173], [1.4645, 4.3221]'\n",
      "...Line # 14 has text content 'bear SEx:' within bounding box '[1.5172, 4.4752], [2.2877, 4.4752], [2.2877, 4.6571], [1.5172, 4.6619]'\n",
      "...Line # 15 has text content 'Tixier separate cover we are sending you well data as Listed in' within bounding box '[2.1633, 4.8103], [7.4375, 4.7576], [7.4375, 4.9347], [2.1633, 4.9778]'\n",
      "...Line # 16 has text content 'an attachment to this letter frea the following tests drilled by Urdon' within bounding box '[1.498, 4.9922], [7.4279, 4.9347], [7.4327, 5.1023], [1.5028, 5.1501]'\n",
      "...Line # 17 has text content '011 of California in Costa Rica:' within bounding box '[1.4789, 5.1597], [4.2117, 5.1501], [4.2117, 5.3033], [1.4837, 5.3224]'\n",
      "...Line # 18 has text content 'Patiño No. 2' within bounding box '[2.5127, 5.6575], [3.5752, 5.6527], [3.5752, 5.8202], [2.5127, 5.8202]'\n",
      "...Line # 19 has text content '30,1281' within bounding box '[5.1833, 5.6431], [5.7863, 5.624], [5.7959, 5.7819], [5.1833, 5.8059]'\n",
      "...Line # 20 has text content 'Cocoles Bo. 2' within bounding box '[2.4983, 5.8346], [3.6757, 5.8346], [3.6757, 5.9877], [2.4983, 5.9877]'\n",
      "...Line # 21 has text content '7,4071' within bounding box '[5.2934, 5.8059], [5.8007, 5.7867], [5.8007, 5.9638], [5.2934, 5.983]'\n",
      "...Line # 22 has text content 'Brie No. L' within bounding box '[2.5127, 6.0021], [3.4172, 5.9925], [3.4172, 6.1696], [2.5127, 6.1792]'\n",
      "...Line # 23 has text content '7,9691' within bounding box '[5.3029, 5.9877], [5.8007, 5.959], [5.7959, 6.1361], [5.3077, 6.1553]'\n",
      "...Line # 24 has text content 'A guneral summary is attached for each wall.' within bounding box '[2.1776, 6.3515], [5.9251, 6.3084], [5.9299, 6.4712], [2.1776, 6.5238]'\n",
      "...Line # 25 has text content 'The material on there Union 011 of California welle in Central' within bounding box '[2.1824, 6.6818], [7.4375, 6.6291], [7.4423, 6.7871], [2.1824, 6.8445]'\n",
      "...Line # 26 has text content 'Acerica ves the result of an e reasont signed on January 16, 1958 botwoon' within bounding box '[1.5076, 6.8589], [7.7103, 6.7966], [7.7103, 6.9642], [1.5076, 7.0168]'\n",
      "...Line # 27 has text content 'Esso Standard 012, 5.A. and Union Oil of Califorde, Union agreed to' within bounding box '[1.5172, 7.0312], [7.3753, 6.9833], [7.3753, 7.1317], [1.5172, 7.1939]'\n",
      "...Line # 28 has text content 'furnish Esso with information on the wells listed above and Baso agreed' within bounding box '[1.5267, 7.2035], [7.5284, 7.1508], [7.5284, 7.304], [1.5267, 7.3614]'\n",
      "...Line # 29 has text content 'to furnish Union with Information from its Balios No. 1 drilled in Cuba' within bounding box '[1.522, 7.371], [7.4471, 7.3136], [7.4471, 7.4763], [1.522, 7.5337]'\n",
      "...Line # 30 has text content 'and roch other vello Laco drills in the Caribbean ares, that in their' within bounding box '[1.5267, 7.5529], [7.3801, 7.4907], [7.3801, 7.6486], [1.5267, 7.706]'\n",
      "...Line # 31 has text content 'opinion the relenen of information is not detrimental to then, The cx-' within bounding box '[1.5267, 7.7156], [7.5476, 7.663], [7.5476, 7.8113], [1.5267, 7.8784]'\n",
      "...Line # 32 has text content 'change includes senples and goneral well infomation such as logs, DSTS,' within bounding box '[1.5363, 7.8831], [7.6194, 7.8305], [7.6194, 7.998], [1.5363, 8.0507]'\n",
      "...Line # 33 has text content 'etc. and is on a foot for foot tasis ..' within bounding box '[1.5315, 8.0554], [4.719, 8.0315], [4.719, 8.1943], [1.5315, 8.223]'\n",
      "...Line # 34 has text content 'Wo have the sons set we are sorting you in our Havana office.' within bounding box '[2.1872, 8.3809], [7.3561, 8.3283], [7.3609, 8.5006], [2.1872, 8.5389]'\n",
      "...Line # 35 has text content 'The purpose of sending you a cot is for security and your use.' within bounding box '[1.5267, 8.5676], [6.7818, 8.5245], [6.7818, 8.6825], [1.5267, 8.7255]'\n",
      "...Line # 36 has text content 'Very truly yours,' within bounding box '[5.1163, 8.8452], [6.6813, 8.8452], [6.6813, 9.0271], [5.1163, 9.0223]'\n",
      "...Line # 37 has text content 'E250 STANDARD OIL, S.A ..' within bounding box '[4.9775, 9.0941], [6.9493, 9.0797], [6.9541, 9.276], [4.9775, 9.2855]'\n",
      "...Line # 38 has text content 'ORIGINAL' within bounding box '[4.9344, 9.3286], [5.5709, 9.3238], [5.5709, 9.477], [4.9392, 9.4818]'\n",
      "...Line # 39 has text content 'SIGNED' within bounding box '[4.9248, 9.477], [5.3891, 9.4674], [5.3939, 9.5919], [4.9248, 9.6014]'\n",
      "...Line # 40 has text content '-' within bounding box '[5.638, 9.4004], [5.6427, 9.5536], [5.5709, 9.5488], [5.5757, 9.3956]'\n",
      "...Line # 41 has text content '--' within bounding box '[6.4994, 9.6158], [6.8967, 9.6206], [6.8919, 9.7211], [6.4994, 9.7163]'\n",
      "...Line # 42 has text content 'J. Il. Sexpor' within bounding box '[5.3077, 9.6685], [6.3894, 9.678], [6.3846, 9.8743], [5.3077, 9.8695]'\n",
      "...Line # 43 has text content 'ÅSter' within bounding box '[1.5459, 9.9891], [2.0149, 9.9844], [2.0149, 10.1567], [1.5363, 10.1567]'\n",
      "...Line # 44 has text content 'Atts.' within bounding box '[1.5602, 10.3481], [2.0006, 10.3577], [2.0006, 10.5013], [1.5555, 10.4965]'\n",
      "...Word 'H012943623' has a confidence of 0.984\n",
      "...Word 'KATALYST' has a confidence of 0.993\n",
      "...Word 'DATA' has a confidence of 0.985\n",
      "...Word 'MANAGEMENT' has a confidence of 0.937\n",
      "...Word '-' has a confidence of 0.958\n",
      "...Word 'CR' has a confidence of 0.757\n",
      "...Word '1.03' has a confidence of 0.949\n",
      "...Word 'March' has a confidence of 0.622\n",
      "...Word '21,' has a confidence of 0.997\n",
      "...Word '1953' has a confidence of 0.916\n",
      "...Word 'Fler' has a confidence of 0.57\n",
      "...Word 'CR-30' has a confidence of 0.846\n",
      "...Word '.' has a confidence of 0.269\n",
      "...Word 'Subject:' has a confidence of 0.848\n",
      "...Word 'WELL' has a confidence of 0.971\n",
      "...Word 'DATA' has a confidence of 0.847\n",
      "...Word 'FROM' has a confidence of 0.489\n",
      "...Word 'THESE' has a confidence of 0.318\n",
      "...Word 'TESTS' has a confidence of 0.609\n",
      "...Word 'DRILLSD' has a confidence of 0.542\n",
      "...Word 'BY' has a confidence of 0.607\n",
      "...Word 'UMION' has a confidence of 0.628\n",
      "...Word 'CIL' has a confidence of 0.963\n",
      "...Word '02' has a confidence of 0.666\n",
      "...Word 'CAL.' has a confidence of 0.703\n",
      "...Word 'MACA' has a confidence of 0.155\n",
      "...Word '-' has a confidence of 0.34\n",
      "...Word 'Mr.' has a confidence of 0.632\n",
      "...Word 'K.' has a confidence of 0.14\n",
      "...Word 'A.' has a confidence of 0.957\n",
      "...Word 'Kright' has a confidence of 0.625\n",
      "...Word 'Producing' has a confidence of 0.725\n",
      "...Word 'Coordination' has a confidence of 0.243\n",
      "...Word '30' has a confidence of 0.78\n",
      "...Word 'Rockefeller' has a confidence of 0.286\n",
      "...Word 'Plaza' has a confidence of 0.076\n",
      "...Word 'New' has a confidence of 0.291\n",
      "...Word 'York' has a confidence of 0.144\n",
      "...Word '20,' has a confidence of 0.997\n",
      "...Word 'N.Y.' has a confidence of 0.855\n",
      "...Word 'bear' has a confidence of 0.78\n",
      "...Word 'SEx:' has a confidence of 0.065\n",
      "...Word 'Tixier' has a confidence of 0.179\n",
      "...Word 'separate' has a confidence of 0.306\n",
      "...Word 'cover' has a confidence of 0.975\n",
      "...Word 'we' has a confidence of 0.292\n",
      "...Word 'are' has a confidence of 0.612\n",
      "...Word 'sending' has a confidence of 0.637\n",
      "...Word 'you' has a confidence of 0.997\n",
      "...Word 'well' has a confidence of 0.827\n",
      "...Word 'data' has a confidence of 0.693\n",
      "...Word 'as' has a confidence of 0.617\n",
      "...Word 'Listed' has a confidence of 0.834\n",
      "...Word 'in' has a confidence of 0.969\n",
      "...Word 'an' has a confidence of 0.906\n",
      "...Word 'attachment' has a confidence of 0.276\n",
      "...Word 'to' has a confidence of 0.997\n",
      "...Word 'this' has a confidence of 0.631\n",
      "...Word 'letter' has a confidence of 0.603\n",
      "...Word 'frea' has a confidence of 0.647\n",
      "...Word 'the' has a confidence of 0.997\n",
      "...Word 'following' has a confidence of 0.244\n",
      "...Word 'tests' has a confidence of 0.657\n",
      "...Word 'drilled' has a confidence of 0.617\n",
      "...Word 'by' has a confidence of 0.997\n",
      "...Word 'Urdon' has a confidence of 0.804\n",
      "...Word '011' has a confidence of 0.37\n",
      "...Word 'of' has a confidence of 0.991\n",
      "...Word 'California' has a confidence of 0.606\n",
      "...Word 'in' has a confidence of 0.996\n",
      "...Word 'Costa' has a confidence of 0.654\n",
      "...Word 'Rica:' has a confidence of 0.226\n",
      "...Word 'Patiño' has a confidence of 0.603\n",
      "...Word 'No.' has a confidence of 0.931\n",
      "...Word '2' has a confidence of 0.995\n",
      "...Word '30,1281' has a confidence of 0.624\n",
      "...Word 'Cocoles' has a confidence of 0.594\n",
      "...Word 'Bo.' has a confidence of 0.702\n",
      "...Word '2' has a confidence of 0.995\n",
      "...Word '7,4071' has a confidence of 0.647\n",
      "...Word 'Brie' has a confidence of 0.647\n",
      "...Word 'No.' has a confidence of 0.297\n",
      "...Word 'L' has a confidence of 0.662\n",
      "...Word '7,9691' has a confidence of 0.618\n",
      "...Word 'A' has a confidence of 0.926\n",
      "...Word 'guneral' has a confidence of 0.886\n",
      "...Word 'summary' has a confidence of 0.297\n",
      "...Word 'is' has a confidence of 0.933\n",
      "...Word 'attached' has a confidence of 0.468\n",
      "...Word 'for' has a confidence of 0.893\n",
      "...Word 'each' has a confidence of 0.641\n",
      "...Word 'wall.' has a confidence of 0.669\n",
      "...Word 'The' has a confidence of 0.993\n",
      "...Word 'material' has a confidence of 0.729\n",
      "...Word 'on' has a confidence of 0.991\n",
      "...Word 'there' has a confidence of 0.603\n",
      "...Word 'Union' has a confidence of 0.881\n",
      "...Word '011' has a confidence of 0.123\n",
      "...Word 'of' has a confidence of 0.991\n",
      "...Word 'California' has a confidence of 0.63\n",
      "...Word 'welle' has a confidence of 0.657\n",
      "...Word 'in' has a confidence of 0.997\n",
      "...Word 'Central' has a confidence of 0.836\n",
      "...Word 'Acerica' has a confidence of 0.728\n",
      "...Word 'ves' has a confidence of 0.153\n",
      "...Word 'the' has a confidence of 0.853\n",
      "...Word 'result' has a confidence of 0.436\n",
      "...Word 'of' has a confidence of 0.251\n",
      "...Word 'an' has a confidence of 0.996\n",
      "...Word 'e' has a confidence of 0.67\n",
      "...Word 'reasont' has a confidence of 0.605\n",
      "...Word 'signed' has a confidence of 0.454\n",
      "...Word 'on' has a confidence of 0.994\n",
      "...Word 'January' has a confidence of 0.63\n",
      "...Word '16,' has a confidence of 0.964\n",
      "...Word '1958' has a confidence of 0.991\n",
      "...Word 'botwoon' has a confidence of 0.578\n",
      "...Word 'Esso' has a confidence of 0.642\n",
      "...Word 'Standard' has a confidence of 0.993\n",
      "...Word '012,' has a confidence of 0.307\n",
      "...Word '5.A.' has a confidence of 0.601\n",
      "...Word 'and' has a confidence of 0.95\n",
      "...Word 'Union' has a confidence of 0.94\n",
      "...Word 'Oil' has a confidence of 0.605\n",
      "...Word 'of' has a confidence of 0.955\n",
      "...Word 'Califorde,' has a confidence of 0.536\n",
      "...Word 'Union' has a confidence of 0.849\n",
      "...Word 'agreed' has a confidence of 0.303\n",
      "...Word 'to' has a confidence of 0.866\n",
      "...Word 'furnish' has a confidence of 0.62\n",
      "...Word 'Esso' has a confidence of 0.587\n",
      "...Word 'with' has a confidence of 0.944\n",
      "...Word 'information' has a confidence of 0.097\n",
      "...Word 'on' has a confidence of 0.907\n",
      "...Word 'the' has a confidence of 0.736\n",
      "...Word 'wells' has a confidence of 0.782\n",
      "...Word 'listed' has a confidence of 0.612\n",
      "...Word 'above' has a confidence of 0.601\n",
      "...Word 'and' has a confidence of 0.616\n",
      "...Word 'Baso' has a confidence of 0.369\n",
      "...Word 'agreed' has a confidence of 0.443\n",
      "...Word 'to' has a confidence of 0.884\n",
      "...Word 'furnish' has a confidence of 0.681\n",
      "...Word 'Union' has a confidence of 0.695\n",
      "...Word 'with' has a confidence of 0.98\n",
      "...Word 'Information' has a confidence of 0.267\n",
      "...Word 'from' has a confidence of 0.92\n",
      "...Word 'its' has a confidence of 0.974\n",
      "...Word 'Balios' has a confidence of 0.806\n",
      "...Word 'No.' has a confidence of 0.665\n",
      "...Word '1' has a confidence of 0.861\n",
      "...Word 'drilled' has a confidence of 0.681\n",
      "...Word 'in' has a confidence of 0.995\n",
      "...Word 'Cuba' has a confidence of 0.85\n",
      "...Word 'and' has a confidence of 0.655\n",
      "...Word 'roch' has a confidence of 0.701\n",
      "...Word 'other' has a confidence of 0.604\n",
      "...Word 'vello' has a confidence of 0.095\n",
      "...Word 'Laco' has a confidence of 0.265\n",
      "...Word 'drills' has a confidence of 0.651\n",
      "...Word 'in' has a confidence of 0.941\n",
      "...Word 'the' has a confidence of 0.602\n",
      "...Word 'Caribbean' has a confidence of 0.665\n",
      "...Word 'ares,' has a confidence of 0.763\n",
      "...Word 'that' has a confidence of 0.8\n",
      "...Word 'in' has a confidence of 0.924\n",
      "...Word 'their' has a confidence of 0.728\n",
      "...Word 'opinion' has a confidence of 0.778\n",
      "...Word 'the' has a confidence of 0.945\n",
      "...Word 'relenen' has a confidence of 0.646\n",
      "...Word 'of' has a confidence of 0.883\n",
      "...Word 'information' has a confidence of 0.073\n",
      "...Word 'is' has a confidence of 0.94\n",
      "...Word 'not' has a confidence of 0.957\n",
      "...Word 'detrimental' has a confidence of 0.545\n",
      "...Word 'to' has a confidence of 0.997\n",
      "...Word 'then,' has a confidence of 0.618\n",
      "...Word 'The' has a confidence of 0.618\n",
      "...Word 'cx-' has a confidence of 0.628\n",
      "...Word 'change' has a confidence of 0.954\n",
      "...Word 'includes' has a confidence of 0.601\n",
      "...Word 'senples' has a confidence of 0.683\n",
      "...Word 'and' has a confidence of 0.349\n",
      "...Word 'goneral' has a confidence of 0.456\n",
      "...Word 'well' has a confidence of 0.534\n",
      "...Word 'infomation' has a confidence of 0.455\n",
      "...Word 'such' has a confidence of 0.585\n",
      "...Word 'as' has a confidence of 0.601\n",
      "...Word 'logs,' has a confidence of 0.844\n",
      "...Word 'DSTS,' has a confidence of 0.379\n",
      "...Word 'etc.' has a confidence of 0.67\n",
      "...Word 'and' has a confidence of 0.928\n",
      "...Word 'is' has a confidence of 0.795\n",
      "...Word 'on' has a confidence of 0.996\n",
      "...Word 'a' has a confidence of 0.995\n",
      "...Word 'foot' has a confidence of 0.85\n",
      "...Word 'for' has a confidence of 0.682\n",
      "...Word 'foot' has a confidence of 0.96\n",
      "...Word 'tasis' has a confidence of 0.615\n",
      "...Word '..' has a confidence of 0.68\n",
      "...Word 'Wo' has a confidence of 0.929\n",
      "...Word 'have' has a confidence of 0.169\n",
      "...Word 'the' has a confidence of 0.929\n",
      "...Word 'sons' has a confidence of 0.011\n",
      "...Word 'set' has a confidence of 0.771\n",
      "...Word 'we' has a confidence of 0.001\n",
      "...Word 'are' has a confidence of 0.61\n",
      "...Word 'sorting' has a confidence of 0.556\n",
      "...Word 'you' has a confidence of 0.993\n",
      "...Word 'in' has a confidence of 0.933\n",
      "...Word 'our' has a confidence of 0.721\n",
      "...Word 'Havana' has a confidence of 0.324\n",
      "...Word 'office.' has a confidence of 0.636\n",
      "...Word 'The' has a confidence of 0.955\n",
      "...Word 'purpose' has a confidence of 0.62\n",
      "...Word 'of' has a confidence of 0.997\n",
      "...Word 'sending' has a confidence of 0.631\n",
      "...Word 'you' has a confidence of 0.955\n",
      "...Word 'a' has a confidence of 0.991\n",
      "...Word 'cot' has a confidence of 0.901\n",
      "...Word 'is' has a confidence of 0.635\n",
      "...Word 'for' has a confidence of 0.997\n",
      "...Word 'security' has a confidence of 0.617\n",
      "...Word 'and' has a confidence of 0.991\n",
      "...Word 'your' has a confidence of 0.998\n",
      "...Word 'use.' has a confidence of 0.728\n",
      "...Word 'Very' has a confidence of 0.619\n",
      "...Word 'truly' has a confidence of 0.955\n",
      "...Word 'yours,' has a confidence of 0.93\n",
      "...Word 'E250' has a confidence of 0.089\n",
      "...Word 'STANDARD' has a confidence of 0.366\n",
      "...Word 'OIL,' has a confidence of 0.32\n",
      "...Word 'S.A' has a confidence of 0.626\n",
      "...Word '..' has a confidence of 0.439\n",
      "...Word 'ORIGINAL' has a confidence of 0.943\n",
      "...Word 'SIGNED' has a confidence of 0.627\n",
      "...Word '-' has a confidence of 0.712\n",
      "...Word '--' has a confidence of 0.805\n",
      "...Word 'J.' has a confidence of 0.739\n",
      "...Word 'Il.' has a confidence of 0.151\n",
      "...Word 'Sexpor' has a confidence of 0.174\n",
      "...Word 'ÅSter' has a confidence of 0.41\n",
      "...Word 'Atts.' has a confidence of 0.846\n",
      "----Analyzing Read from page #2----\n",
      "Page has width: 8.4306 and height: 10.9167, measured with unit: inch\n",
      "...Line # 0 has text content 'Costa Rica Pire' within bounding box '[6.2554, 0.1042], [7.8619, 0.0521], [7.8714, 0.3032], [6.2554, 0.3411]'\n",
      "...Line # 1 has text content 'Union 011 Company of California' within bounding box '[3.1324, 1.1419], [5.772, 1.1324], [5.772, 1.3077], [3.1324, 1.3219]'\n",
      "...Line # 2 has text content 'CR.1.03' within bounding box '[6.5255, 0.9145], [7.5207, 0.9618], [7.5159, 1.1703], [6.5255, 1.1087]'\n",
      "...Line # 3 has text content 'Pati fo No. 2' within bounding box '[1.3885, 1.6726], [2.4548, 1.6773], [2.4548, 1.8479], [1.3885, 1.8431]'\n",
      "...Line # 4 has text content 'Location: 5 Kms. southwest of Puerto Viejo in SE Limon Province' within bounding box '[1.7297, 1.9995], [7.0894, 1.9474], [7.0942, 2.1179], [1.7297, 2.1606]'\n",
      "...Line # 5 has text content '(Caribbean side), Costa Rica.' within bounding box '[2.6633, 2.1606], [5.0707, 2.1464], [5.0754, 2.3169], [2.6633, 2.3312]'\n",
      "...Line # 6 has text content 'Coordinates: Lat. 9º 39' 14\" - Long. 82' 48' 10\"' within bounding box '[2.6633, 2.3264], [6.7861, 2.2838], [6.7861, 2.4686], [2.6633, 2.497]'\n",
      "...Line # 7 has text content 'Dates: Commenced:' within bounding box '[1.725, 2.6818], [3.3267, 2.6534], [3.3315, 2.8192], [1.725, 2.8524]'\n",
      "...Line # 8 has text content '2/23/55' within bounding box '[3.3694, 2.6486], [4.0281, 2.6486], [4.0281, 2.8287], [3.3694, 2.8287]'\n",
      "...Line # 9 has text content 'Completed:' within bounding box '[2.4074, 2.8381], [3.322, 2.8334], [3.3267, 3.0087], [2.4074, 3.0182]'\n",
      "...Line # 10 has text content '4/19/55' within bounding box '[3.3931, 2.8287], [4.0186, 2.8287], [4.0186, 3.004], [3.3931, 3.004]'\n",
      "...Line # 11 has text content 'Status: D & A' within bounding box '[1.7392, 3.1698], [2.9381, 3.1603], [2.9429, 3.3214], [1.7439, 3.3356]'\n",
      "...Line # 12 has text content 'Total Depth: 10,128' formation unknown as yet. Probably Eocene.' within bounding box '[1.7155, 3.4967], [7.1605, 3.4588], [7.1605, 3.6484], [1.7155, 3.6863]'\n",
      "...Line # 13 has text content 'Shows: No oil or gas shows.' within bounding box '[1.7392, 3.8332], [4.0992, 3.8332], [4.0992, 3.999], [1.7392, 3.999]'\n",
      "...Line # 14 has text content 'DST's: None.' within bounding box '[1.7439, 4.1601], [2.8481, 4.1743], [2.8481, 4.3259], [1.7439, 4.3212]'\n",
      "...Line # 15 has text content 'Location based on: Surface: Puerto Viejo Anticline.' within bounding box '[1.7392, 4.5012], [6.1796, 4.4681], [6.1843, 4.6434], [1.7439, 4.6718]'\n",
      "...Line # 16 has text content 'General Dip - SW 55º.' within bounding box '[1.7487, 4.8329], [3.5163, 4.8187], [3.5163, 5.0035], [1.7487, 5.0129]'\n",
      "...Line # 17 has text content 'Electric Log:' within bounding box '[1.7392, 5.1598], [2.9334, 5.174], [2.9287, 5.3446], [1.7392, 5.3257]'\n",
      "...Line # 18 has text content 'Shale line thruout.' within bounding box '[2.9381, 5.1646], [4.5968, 5.1551], [4.5968, 5.3209], [2.9381, 5.3304]'\n",
      "...Line # 19 has text content '3,500 - Fresh water.' within bounding box '[2.995, 5.4962], [4.6868, 5.4962], [4.6868, 5.6573], [2.995, 5.6668]'\n",
      "...Line # 20 has text content '3,880 - 3,920 - Fresh water.' within bounding box '[2.995, 5.6668], [5.3503, 5.6526], [5.355, 5.8137], [2.9997, 5.8279]'\n",
      "...Line # 21 has text content '4,270 - 4,310)' within bounding box '[2.9997, 5.8279], [4.1797, 5.8184], [4.1797, 5.989], [3.0045, 5.9985]'\n",
      "...Line # 22 has text content '4,380' within bounding box '[3.0045, 6.008], [3.4547, 5.9937], [3.4547, 6.1501], [3.0092, 6.1691]'\n",
      "...Line # 23 has text content '6,640 - 6,660)' within bounding box '[3.0045, 6.1548], [4.1797, 6.1454], [4.1797, 6.3302], [3.0045, 6.3349]'\n",
      "...Line # 24 has text content '6,750 - 6,860)' within bounding box '[3.0045, 6.3254], [4.1892, 6.3207], [4.1892, 6.5055], [3.0045, 6.5102]'\n",
      "...Line # 25 has text content 'Probably salt water.' within bounding box '[4.2319, 5.989], [5.9284, 5.9795], [5.9284, 6.1501], [4.2319, 6.1596]'\n",
      "...Line # 26 has text content 'Log indicates poor prospects for oil production' within bounding box '[2.995, 6.6571], [6.9615, 6.6239], [6.9615, 6.8087], [2.995, 6.8371]'\n",
      "...Line # 27 has text content 'because of shaly nature.' within bounding box '[3.0045, 6.8371], [5.0233, 6.8324], [5.0233, 6.9888], [3.0092, 6.9935]'\n",
      "...Line # 28 has text content 'Note: Attempted to run E log to TD of 10,128' but cable would not go' within bounding box '[1.7439, 7.1641], [7.5396, 7.1404], [7.5396, 7.3109], [1.7439, 7.3394]'\n",
      "...Line # 29 has text content 'below 8,050' .' within bounding box '[2.3505, 7.3346], [3.4499, 7.3346], [3.4499, 7.5052], [2.3505, 7.5005]'\n",
      "...Line # 30 has text content 'List of material received to date:' within bounding box '[1.7534, 7.6616], [4.6157, 7.6568], [4.6157, 7.8274], [1.7534, 7.8321]'\n",
      "...Line # 31 has text content 'Electric lors' within bounding box '[2.0093, 8.0075], [3.1372, 8.0075], [3.1372, 8.1638], [2.0093, 8.1638]'\n",
      "...Line # 32 has text content 'Run 1' within bounding box '[2.2463, 8.1733], [2.7107, 8.178], [2.7059, 8.3249], [2.2463, 8.3202]'\n",
      "...Line # 33 has text content '0 - 1,130'' within bounding box '[3.0993, 8.1591], [3.9238, 8.1449], [3.9286, 8.306], [3.0993, 8.3249]'\n",
      "...Line # 34 has text content 'Run 3' within bounding box '[2.2557, 8.3344], [2.7296, 8.3344], [2.7296, 8.505], [2.2557, 8.505]'\n",
      "...Line # 35 has text content '2,1001 - 3,051'' within bounding box '[3.0945, 8.3296], [4.3361, 8.3249], [4.3409, 8.486], [3.0945, 8.5002]'\n",
      "...Line # 36 has text content 'Run 4' within bounding box '[2.2415, 8.5144], [2.7296, 8.5239], [2.7249, 8.6661], [2.2415, 8.6471]'\n",
      "...Line # 37 has text content '2,9501 - 4,368'' within bounding box '[3.0945, 8.5002], [4.3456, 8.4765], [4.3503, 8.6518], [3.0945, 8.6708]'\n",
      "...Line # 38 has text content 'Composite Log Runs 1 thru 8 0 - 9,124'' within bounding box '[2.2605, 8.6566], [5.6014, 8.6281], [5.6014, 8.8224], [2.2605, 8.8319]'\n",
      "...Line # 39 has text content 'Extra Curves' within bounding box '[2.2605, 8.8414], [3.2888, 8.8414], [3.2888, 8.9882], [2.2605, 8.9882]'\n",
      "...Line # 40 has text content 'ES-3 2,090 - 3,050' within bounding box '[2.5116, 8.993], [4.4356, 8.974], [4.4356, 9.1588], [2.5116, 9.173]'\n",
      "...Line # 41 has text content 'ES-3 50 ohms 2,1001 - 3,060'' within bounding box '[2.4974, 9.1588], [4.938, 9.1351], [4.938, 9.3152], [2.4974, 9.3294]'\n",
      "...Line # 42 has text content 'ES-7' within bounding box '[2.5211, 9.3199], [2.9903, 9.3341], [2.9855, 9.4858], [2.5116, 9.4621]'\n",
      "...Line # 43 has text content '6,210' - 7,500'' within bounding box '[3.1798, 9.3104], [4.4356, 9.3152], [4.4309, 9.4905], [3.1751, 9.481]'\n",
      "...Line # 44 has text content 'ES-5' within bounding box '[2.5069, 9.4905], [2.8955, 9.4905], [2.8955, 9.6658], [2.5022, 9.6563]'\n",
      "...Line # 45 has text content '4,100' - 5,290'' within bounding box '[3.1988, 9.4952], [4.4309, 9.481], [4.4356, 9.6611], [3.1988, 9.68]'\n",
      "...Word 'Costa' has a confidence of 0.567\n",
      "...Word 'Rica' has a confidence of 0.108\n",
      "...Word 'Pire' has a confidence of 0.23\n",
      "...Word 'Union' has a confidence of 0.78\n",
      "...Word '011' has a confidence of 0.604\n",
      "...Word 'Company' has a confidence of 0.955\n",
      "...Word 'of' has a confidence of 0.992\n",
      "...Word 'California' has a confidence of 0.673\n",
      "...Word 'CR.1.03' has a confidence of 0.892\n",
      "...Word 'Pati' has a confidence of 0.434\n",
      "...Word 'fo' has a confidence of 0.595\n",
      "...Word 'No.' has a confidence of 0.94\n",
      "...Word '2' has a confidence of 0.996\n",
      "...Word 'Location:' has a confidence of 0.991\n",
      "...Word '5' has a confidence of 0.994\n",
      "...Word 'Kms.' has a confidence of 0.783\n",
      "...Word 'southwest' has a confidence of 0.993\n",
      "...Word 'of' has a confidence of 0.997\n",
      "...Word 'Puerto' has a confidence of 0.996\n",
      "...Word 'Viejo' has a confidence of 0.997\n",
      "...Word 'in' has a confidence of 0.997\n",
      "...Word 'SE' has a confidence of 0.993\n",
      "...Word 'Limon' has a confidence of 0.993\n",
      "...Word 'Province' has a confidence of 0.993\n",
      "...Word '(Caribbean' has a confidence of 0.993\n",
      "...Word 'side),' has a confidence of 0.991\n",
      "...Word 'Costa' has a confidence of 0.928\n",
      "...Word 'Rica.' has a confidence of 0.989\n",
      "...Word 'Coordinates:' has a confidence of 0.991\n",
      "...Word 'Lat.' has a confidence of 0.959\n",
      "...Word '9º' has a confidence of 0.458\n",
      "...Word '39'' has a confidence of 0.616\n",
      "...Word '14\"' has a confidence of 0.808\n",
      "...Word '-' has a confidence of 0.969\n",
      "...Word 'Long.' has a confidence of 0.991\n",
      "...Word '82'' has a confidence of 0.684\n",
      "...Word '48'' has a confidence of 0.846\n",
      "...Word '10\"' has a confidence of 0.315\n",
      "...Word 'Dates:' has a confidence of 0.992\n",
      "...Word 'Commenced:' has a confidence of 0.801\n",
      "...Word '2/23/55' has a confidence of 0.931\n",
      "...Word 'Completed:' has a confidence of 0.955\n",
      "...Word '4/19/55' has a confidence of 0.995\n",
      "...Word 'Status:' has a confidence of 0.993\n",
      "...Word 'D' has a confidence of 0.995\n",
      "...Word '&' has a confidence of 0.995\n",
      "...Word 'A' has a confidence of 0.993\n",
      "...Word 'Total' has a confidence of 0.996\n",
      "...Word 'Depth:' has a confidence of 0.996\n",
      "...Word '10,128'' has a confidence of 0.934\n",
      "...Word 'formation' has a confidence of 0.993\n",
      "...Word 'unknown' has a confidence of 0.991\n",
      "...Word 'as' has a confidence of 0.996\n",
      "...Word 'yet.' has a confidence of 0.932\n",
      "...Word 'Probably' has a confidence of 0.67\n",
      "...Word 'Eocene.' has a confidence of 0.67\n",
      "...Word 'Shows:' has a confidence of 0.972\n",
      "...Word 'No' has a confidence of 0.996\n",
      "...Word 'oil' has a confidence of 0.884\n",
      "...Word 'or' has a confidence of 0.997\n",
      "...Word 'gas' has a confidence of 0.994\n",
      "...Word 'shows.' has a confidence of 0.995\n",
      "...Word 'DST's:' has a confidence of 0.966\n",
      "...Word 'None.' has a confidence of 0.955\n",
      "...Word 'Location' has a confidence of 0.994\n",
      "...Word 'based' has a confidence of 0.997\n",
      "...Word 'on:' has a confidence of 0.996\n",
      "...Word 'Surface:' has a confidence of 0.991\n",
      "...Word 'Puerto' has a confidence of 0.733\n",
      "...Word 'Viejo' has a confidence of 0.934\n",
      "...Word 'Anticline.' has a confidence of 0.991\n",
      "...Word 'General' has a confidence of 0.522\n",
      "...Word 'Dip' has a confidence of 0.997\n",
      "...Word '-' has a confidence of 0.98\n",
      "...Word 'SW' has a confidence of 0.97\n",
      "...Word '55º.' has a confidence of 0.711\n",
      "...Word 'Electric' has a confidence of 0.851\n",
      "...Word 'Log:' has a confidence of 0.939\n",
      "...Word 'Shale' has a confidence of 0.997\n",
      "...Word 'line' has a confidence of 0.955\n",
      "...Word 'thruout.' has a confidence of 0.994\n",
      "...Word '3,500' has a confidence of 0.991\n",
      "...Word '-' has a confidence of 0.998\n",
      "...Word 'Fresh' has a confidence of 0.98\n",
      "...Word 'water.' has a confidence of 0.995\n",
      "...Word '3,880' has a confidence of 0.955\n",
      "...Word '-' has a confidence of 0.998\n",
      "...Word '3,920' has a confidence of 0.926\n",
      "...Word '-' has a confidence of 0.998\n",
      "...Word 'Fresh' has a confidence of 0.996\n",
      "...Word 'water.' has a confidence of 0.996\n",
      "...Word '4,270' has a confidence of 0.995\n",
      "...Word '-' has a confidence of 0.996\n",
      "...Word '4,310)' has a confidence of 0.995\n",
      "...Word '4,380' has a confidence of 0.995\n",
      "...Word '6,640' has a confidence of 0.994\n",
      "...Word '-' has a confidence of 0.89\n",
      "...Word '6,660)' has a confidence of 0.993\n",
      "...Word '6,750' has a confidence of 0.993\n",
      "...Word '-' has a confidence of 0.994\n",
      "...Word '6,860)' has a confidence of 0.991\n",
      "...Word 'Probably' has a confidence of 0.996\n",
      "...Word 'salt' has a confidence of 0.988\n",
      "...Word 'water.' has a confidence of 0.996\n",
      "...Word 'Log' has a confidence of 0.992\n",
      "...Word 'indicates' has a confidence of 0.993\n",
      "...Word 'poor' has a confidence of 0.989\n",
      "...Word 'prospects' has a confidence of 0.946\n",
      "...Word 'for' has a confidence of 0.995\n",
      "...Word 'oil' has a confidence of 0.616\n",
      "...Word 'production' has a confidence of 0.991\n",
      "...Word 'because' has a confidence of 0.994\n",
      "...Word 'of' has a confidence of 0.997\n",
      "...Word 'shaly' has a confidence of 0.997\n",
      "...Word 'nature.' has a confidence of 0.809\n",
      "...Word 'Note:' has a confidence of 0.673\n",
      "...Word 'Attempted' has a confidence of 0.899\n",
      "...Word 'to' has a confidence of 0.997\n",
      "...Word 'run' has a confidence of 0.997\n",
      "...Word 'E' has a confidence of 0.964\n",
      "...Word 'log' has a confidence of 0.991\n",
      "...Word 'to' has a confidence of 0.996\n",
      "...Word 'TD' has a confidence of 0.956\n",
      "...Word 'of' has a confidence of 0.997\n",
      "...Word '10,128'' has a confidence of 0.901\n",
      "...Word 'but' has a confidence of 0.997\n",
      "...Word 'cable' has a confidence of 0.997\n",
      "...Word 'would' has a confidence of 0.997\n",
      "...Word 'not' has a confidence of 0.997\n",
      "...Word 'go' has a confidence of 0.997\n",
      "...Word 'below' has a confidence of 0.965\n",
      "...Word '8,050'' has a confidence of 0.855\n",
      "...Word '.' has a confidence of 0.947\n",
      "...Word 'List' has a confidence of 0.985\n",
      "...Word 'of' has a confidence of 0.987\n",
      "...Word 'material' has a confidence of 0.888\n",
      "...Word 'received' has a confidence of 0.884\n",
      "...Word 'to' has a confidence of 0.994\n",
      "...Word 'date:' has a confidence of 0.975\n",
      "...Word 'Electric' has a confidence of 0.922\n",
      "...Word 'lors' has a confidence of 0.521\n",
      "...Word 'Run' has a confidence of 0.991\n",
      "...Word '1' has a confidence of 0.544\n",
      "...Word '0' has a confidence of 0.994\n",
      "...Word '-' has a confidence of 0.86\n",
      "...Word '1,130'' has a confidence of 0.787\n",
      "...Word 'Run' has a confidence of 0.997\n",
      "...Word '3' has a confidence of 0.995\n",
      "...Word '2,1001' has a confidence of 0.625\n",
      "...Word '-' has a confidence of 0.993\n",
      "...Word '3,051'' has a confidence of 0.637\n",
      "...Word 'Run' has a confidence of 0.997\n",
      "...Word '4' has a confidence of 0.996\n",
      "...Word '2,9501' has a confidence of 0.623\n",
      "...Word '-' has a confidence of 0.994\n",
      "...Word '4,368'' has a confidence of 0.661\n",
      "...Word 'Composite' has a confidence of 0.965\n",
      "...Word 'Log' has a confidence of 0.997\n",
      "...Word 'Runs' has a confidence of 0.988\n",
      "...Word '1' has a confidence of 0.969\n",
      "...Word 'thru' has a confidence of 0.991\n",
      "...Word '8' has a confidence of 0.956\n",
      "...Word '0' has a confidence of 0.986\n",
      "...Word '-' has a confidence of 0.986\n",
      "...Word '9,124'' has a confidence of 0.941\n",
      "...Word 'Extra' has a confidence of 0.993\n",
      "...Word 'Curves' has a confidence of 0.993\n",
      "...Word 'ES-3' has a confidence of 0.954\n",
      "...Word '2,090' has a confidence of 0.745\n",
      "...Word '-' has a confidence of 0.944\n",
      "...Word '3,050' has a confidence of 0.733\n",
      "...Word 'ES-3' has a confidence of 0.962\n",
      "...Word '50' has a confidence of 0.991\n",
      "...Word 'ohms' has a confidence of 0.658\n",
      "...Word '2,1001' has a confidence of 0.756\n",
      "...Word '-' has a confidence of 0.993\n",
      "...Word '3,060'' has a confidence of 0.66\n",
      "...Word 'ES-7' has a confidence of 0.94\n",
      "...Word '6,210'' has a confidence of 0.651\n",
      "...Word '-' has a confidence of 0.825\n",
      "...Word '7,500'' has a confidence of 0.813\n",
      "...Word 'ES-5' has a confidence of 0.985\n",
      "...Word '4,100'' has a confidence of 0.943\n",
      "...Word '-' has a confidence of 0.73\n",
      "...Word '5,290'' has a confidence of 0.956\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code sample shows Prebuilt Read operations with the Azure Form Recognizer client library. \n",
    "The async versions of the samples require Python 3.6 or later.\n",
    "\n",
    "To learn more, please visit the documentation - Quickstart: Form Recognizer Python client library SDKs\n",
    "https://docs.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/quickstarts/try-v3-python-sdk\n",
    "\"\"\"\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "\n",
    "\"\"\"\n",
    "Remember to remove the key from your code when you're done, and never post it publicly. For production, use\n",
    "secure methods to store and access your credentials. For more information, see \n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-security?tabs=command-line%2Ccsharp#environment-variables-and-application-configuration\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def format_bounding_box(bounding_box):\n",
    "    if not bounding_box:\n",
    "        return \"N/A\"\n",
    "    return \", \".join([\"[{}, {}]\".format(p.x, p.y) for p in bounding_box])\n",
    "\n",
    "def analyze_read():\n",
    "    # sample document\n",
    "    document = \"/Users/David.Godinez/Downloads/24769174__AMERICAS__Costa-Rica_truncated_1-5.pdf\"\n",
    "    \n",
    "    credentials_path = os.path.abspath('credentials3.json')\n",
    "    with open(credentials_path, 'r') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    subscription_key = credentials['API_key']\n",
    "    endpoint = credentials['endpoint']\n",
    "    document_analysis_client = DocumentAnalysisClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "    )\n",
    "    \n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "        \n",
    "    poller = document_analysis_client.begin_analyze_document(\n",
    "            \"prebuilt-read\", file_content)\n",
    "    \n",
    "    result = poller.result()\n",
    "\n",
    "    print (\"Document contains content: \", result.content)\n",
    "    \n",
    "    for idx, style in enumerate(result.styles):\n",
    "        print(\n",
    "            \"Document contains {} content\".format(\n",
    "                \"handwritten\" if style.is_handwritten else \"no handwritten\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for page in result.pages:\n",
    "        print(\"----Analyzing Read from page #{}----\".format(page.page_number))\n",
    "        print(\n",
    "            \"Page has width: {} and height: {}, measured with unit: {}\".format(\n",
    "                page.width, page.height, page.unit\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for line_idx, line in enumerate(page.lines):\n",
    "            print(\n",
    "                \"...Line # {} has text content '{}' within bounding box '{}'\".format(\n",
    "                    line_idx,\n",
    "                    line.content,\n",
    "                    format_bounding_box(line.polygon),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for word in page.words:\n",
    "            print(\n",
    "                \"...Word '{}' has a confidence of {}\".format(\n",
    "                    word.content, word.confidence\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ba446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74fc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f518d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0469a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5114861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fd8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0621f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303dc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded5ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a740d1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2131a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing code used in current pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02f40433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document contains handwritten content: \n",
      "CR\n",
      "1.03\n",
      ".\n",
      ".\n",
      "Document contains handwritten content: \n",
      "Document contains handwritten content: \n",
      "7,4071\n",
      "Document contains handwritten content: \n",
      "Pire\n",
      "CR.1.03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'CR',\n",
       "  'confidence': 0.757,\n",
       "  'polygon': [Point(x=6.8345, y=1.3402),\n",
       "   Point(x=7.1264, y=1.345),\n",
       "   Point(x=7.1312, y=1.546),\n",
       "   Point(x=6.844, y=1.5412)]},\n",
       " {'text': '1.03',\n",
       "  'confidence': 0.949,\n",
       "  'polygon': [Point(x=7.2078, y=1.3498),\n",
       "   Point(x=7.7917, y=1.3545),\n",
       "   Point(x=7.7869, y=1.5699),\n",
       "   Point(x=7.2126, y=1.546)]},\n",
       " {'text': '.',\n",
       "  'confidence': 0.269,\n",
       "  'polygon': [Point(x=6.0591, y=2.2544),\n",
       "   Point(x=6.1213, y=2.2496),\n",
       "   Point(x=6.1309, y=2.4219),\n",
       "   Point(x=6.0687, y=2.4219)]},\n",
       " {'text': '.',\n",
       "  'confidence': 0.947,\n",
       "  'polygon': [Point(x=3.3646, y=7.3346),\n",
       "   Point(x=3.4499, y=7.3346),\n",
       "   Point(x=3.4499, y=7.5099),\n",
       "   Point(x=3.3646, y=7.5099)]},\n",
       " {'text': '7,4071',\n",
       "  'confidence': 0.647,\n",
       "  'polygon': [Point(x=5.2934, y=5.8059),\n",
       "   Point(x=5.7911, y=5.7867),\n",
       "   Point(x=5.7959, y=5.959),\n",
       "   Point(x=5.2981, y=5.9782)]},\n",
       " {'text': 'Pire',\n",
       "  'confidence': 0.23,\n",
       "  'polygon': [Point(x=7.4686, y=0.0663),\n",
       "   Point(x=7.8192, y=0.0521),\n",
       "   Point(x=7.824, y=0.3032),\n",
       "   Point(x=7.4686, y=0.3222)]},\n",
       " {'text': 'CR.1.03',\n",
       "  'confidence': 0.892,\n",
       "  'polygon': [Point(x=6.5587, y=0.9192),\n",
       "   Point(x=7.5112, y=0.9618),\n",
       "   Point(x=7.5159, y=1.1751),\n",
       "   Point(x=6.5587, y=1.1135)]}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handwritten_words = []\n",
    "\n",
    "for style in b.styles:\n",
    "    if style.is_handwritten:\n",
    "        print(\"Document contains handwritten content: \")\n",
    "        for span in style.spans:\n",
    "            start_idx = span.offset\n",
    "            end_idx = start_idx + span.length\n",
    "\n",
    "            for page in b.pages:\n",
    "                for word in page.words:\n",
    "                    word_idx = b.content.index(word.content)\n",
    "                    if word_idx >= start_idx and word_idx < end_idx:\n",
    "                        print(word.content)\n",
    "                        handwritten_words.append({\n",
    "                            \"text\": word.content,\n",
    "                            \"confidence\": word.confidence,\n",
    "                            \"polygon\": [point for point in word.polygon]\n",
    "                        })\n",
    "                        \n",
    "handwritten_words                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631555b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf70e242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f432e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80efd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6fa6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a49a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using document_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89c824b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re \n",
    "import os\n",
    "import pandas as pd\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient, AnalyzeResult\n",
    "\n",
    "def analyze_document(file_path):\n",
    "    # Load the credentials from a JSON file and other necessary steps\n",
    "    credentials_path = os.path.abspath('credentials2.json')\n",
    "    with open(credentials_path, 'r') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    subscription_key = credentials['API_key']\n",
    "    endpoint = credentials['endpoint']\n",
    "    \n",
    "    document_analysis_client = DocumentAnalysisClient(endpoint=endpoint, credential=AzureKeyCredential(subscription_key))\n",
    "\n",
    "    poller = document_analysis_client.begin_analyze_document_from_url(\"prebuilt-read\", file_path)\n",
    "    result = poller.result()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def analyze_result(result): \n",
    "    # Extract relevant data from the AnalyzeResult object\n",
    "    data = {\n",
    "        \"analyzeResultapi_version\": [result.api_version],\n",
    "        \"analyzeResult.model_id\": [result.model_id],\n",
    "        \"analyzeResult.content\": [str(result.content)],\n",
    "        \"analyzeResult.pages\": [str(result.pages)],\n",
    "        \"analyzeResult.styles\": [str(result.styles)],\n",
    "        \"analyzeResult.paragraphs\": [str(result.paragraphs)]\n",
    "    }\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    analyze_result = pd.DataFrame(data)\n",
    "    return analyze_result\n",
    "    \n",
    "\n",
    "\n",
    "def create_paragraph_dataframe(input_string):\n",
    "    # input_string = anlyze_result['analyzeResult.paragraphs'][0]\n",
    "    content_pattern = re.compile(r\"content=([^,]+)\")\n",
    "    page_number_pattern = re.compile(r\"page_number=(\\d+)\")\n",
    "    polygon_pattern = re.compile(r\"Point\\(x=([\\d.]+), y=([\\d.]+)\\)\")\n",
    "    span_pattern = re.compile(r\"DocumentSpan\\(offset=(\\d+), length=(\\d+)\\)\")\n",
    "\n",
    "    content_list = content_pattern.findall(input_string)\n",
    "    page_number_list = page_number_pattern.findall(input_string)\n",
    "    polygon_list = [list(zip(x[0::2], x[1::2])) for x in polygon_pattern.findall(input_string)]\n",
    "    span_list = span_pattern.findall(input_string)\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(content_list)):\n",
    "        data.append({\n",
    "            \"offset\": span_list[i][0],\n",
    "            \"length\": span_list[i][1],\n",
    "            \"content\": content_list[i],\n",
    "            \"page_number\": page_number_list[i],\n",
    "            \"polygon\": polygon_list[i]\n",
    "            \n",
    "        })\n",
    "        \n",
    "    df_paragraph_spans = pd.DataFrame(data)\n",
    "\n",
    "    return df_paragraph_spans\n",
    "\n",
    "\n",
    "\n",
    "def create_style_dataframe(input_string):\n",
    "    is_handwritten_pattern = re.compile(r\"is_handwritten=([^,]+)\")\n",
    "    span_pattern = re.compile(r\"DocumentSpan\\(offset=(\\d+), length=(\\d+)\\)\")\n",
    "    confidence_pattern = re.compile(r\"confidence=([\\d.]+)\")\n",
    "\n",
    "    is_handwritten_list = is_handwritten_pattern.findall(input_string)\n",
    "    span_list = span_pattern.findall(input_string)\n",
    "    confidence_list = confidence_pattern.findall(input_string)\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(is_handwritten_list)):\n",
    "        data.append({\n",
    "            \"confidence\": confidence_list[i],\n",
    "            \"is_handwritten\": is_handwritten_list[i],\n",
    "            \"offset\": span_list[i][0],\n",
    "            \"length\": span_list[i][1]\n",
    "        })\n",
    "\n",
    "    df_style_spans = pd.DataFrame(data)\n",
    "\n",
    "    return df_style_spans\n",
    "\n",
    "def merge_dataframes(df_paragraph_spans, df_style_spans):\n",
    "    df_merged = pd.merge(df_paragraph_spans, df_style_spans, on=['offset', 'length'], how='inner')\n",
    "    return df_merged.reindex()\n",
    "\n",
    "def process_analyze_result(filepath: str):\n",
    "    result = analyze_document(filepath)\n",
    "    analyzed_result = analyze_result(result)\n",
    "    df_paragraph_spans = create_paragraph_dataframe(analyzed_result['analyzeResult.paragraphs'][0])\n",
    "    df_style_spans = create_style_dataframe(analyzed_result['analyzeResult.styles'][0])\n",
    "    df_handwritten_spans_merged = merge_dataframes(df_paragraph_spans, df_style_spans)\n",
    "\n",
    "    return df_handwritten_spans_merged[df_handwritten_spans_merged['isHandwritten'] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83549550",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "(InvalidRequest) Invalid request.\nCode: InvalidRequest\nMessage: Invalid request.\nInner error: {\n    \"code\": \"InvalidContent\",\n    \"message\": \"The file is corrupted or format is unsupported. Refer to documentation for the list of supported formats.\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://drive.google.com/file/d/13uuqgI4tgRYxGwmsSwj0Egq8QxghiYZc/view?usp=sharing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43manalyze_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 19\u001b[0m, in \u001b[0;36manalyze_document\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m credentials[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mendpoint\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m document_analysis_client \u001b[38;5;241m=\u001b[39m DocumentAnalysisClient(endpoint\u001b[38;5;241m=\u001b[39mendpoint, credential\u001b[38;5;241m=\u001b[39mAzureKeyCredential(subscription_key))\n\u001b[0;32m---> 19\u001b[0m poller \u001b[38;5;241m=\u001b[39m \u001b[43mdocument_analysis_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_analyze_document_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprebuilt-read\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m result \u001b[38;5;241m=\u001b[39m poller\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/ai/formrecognizer/_document_analysis_client.py:192\u001b[0m, in \u001b[0;36mDocumentAnalysisClient.begin_analyze_document_from_url\u001b[0;34m(self, model_id, document_url, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(document_url, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument_url\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m needs to be of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see `begin_analyze_document()` to pass a byte stream.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     )\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_analyze_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43manalyze_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murlSource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_url\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_index_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43municodeCodePoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/ai/formrecognizer/_generated/_operations_mixin.py:170\u001b[0m, in \u001b[0;36mFormRecognizerClientOperationsMixin.begin_analyze_document\u001b[0;34m(self, model_id, pages, locale, string_index_type, analyze_request, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m mixin_instance\u001b[38;5;241m.\u001b[39m_serialize\u001b[38;5;241m.\u001b[39mclient_side_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    169\u001b[0m mixin_instance\u001b[38;5;241m.\u001b[39m_deserialize \u001b[38;5;241m=\u001b[39m Deserializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models_dict(api_version))\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmixin_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_analyze_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring_index_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manalyze_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/ai/formrecognizer/_generated/v2022_08_31/operations/_form_recognizer_client_operations.py:576\u001b[0m, in \u001b[0;36mFormRecognizerClientOperationsMixin.begin_analyze_document\u001b[0;34m(self, model_id, pages, locale, string_index_type, analyze_request, content_type, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m cont_token \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinuation_token\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# type: Optional[str]\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cont_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 576\u001b[0m     raw_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_analyze_document_initial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstring_index_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_index_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43manalyze_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manalyze_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mz\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_map\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_long_running_output\u001b[39m(pipeline_response):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/ai/formrecognizer/_generated/v2022_08_31/operations/_form_recognizer_client_operations.py:508\u001b[0m, in \u001b[0;36mFormRecognizerClientOperationsMixin._analyze_document_initial\u001b[0;34m(self, model_id, pages, locale, string_index_type, analyze_request, content_type, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m202\u001b[39m]:\n\u001b[1;32m    507\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m    510\u001b[0m response_headers \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    511\u001b[0m response_headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperation-Location\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperation-Location\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: (InvalidRequest) Invalid request.\nCode: InvalidRequest\nMessage: Invalid request.\nInner error: {\n    \"code\": \"InvalidContent\",\n    \"message\": \"The file is corrupted or format is unsupported. Refer to documentation for the list of supported formats.\"\n}"
     ]
    }
   ],
   "source": [
    "file_path = \"https://drive.google.com/file/d/13uuqgI4tgRYxGwmsSwj0Egq8QxghiYZc/view?usp=sharing\"\n",
    "analyze_document(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa65916a",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "(InvalidRequest) Invalid request.\nCode: InvalidRequest\nMessage: Invalid request.\nInner error: {\n    \"code\": \"InvalidContent\",\n    \"message\": \"The file is corrupted or format is unsupported. Refer to documentation for the list of supported formats.\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 83\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[43manalyze_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 42\u001b[0m, in \u001b[0;36manalyze_read\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m formUrl \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://exxonpdfstorage1.blob.core.windows.net/pdfcontainer1/Certifications\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20-\u001b[39m\u001b[38;5;132;01m%20d\u001b[39;00m\u001b[38;5;124mavidgodinez-0799\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20Microsoft\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20Docs.pdf?sp=r&st=2023-05-05T19:07:34Z&se=2023-05-06T03:07:34Z&sip=98.44.56.177&sv=2022-11-02&sr=b&sig=VHJJxnyXM8NZgvlU8x28R4pafzaic2pjKRO3BA38tEU\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m3D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m document_analysis_client \u001b[38;5;241m=\u001b[39m DocumentAnalysisClient(\n\u001b[1;32m     39\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mendpoint, credential\u001b[38;5;241m=\u001b[39mAzureKeyCredential(subscription_key)\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 42\u001b[0m poller \u001b[38;5;241m=\u001b[39m \u001b[43mdocument_analysis_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_analyze_document_from_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprebuilt-read\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformUrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m result \u001b[38;5;241m=\u001b[39m poller\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument contains content: \u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/ai/formrecognizer/_document_analysis_client.py:192\u001b[0m, in \u001b[0;36mDocumentAnalysisClient.begin_analyze_document_from_url\u001b[0;34m(self, model_id, document_url, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(document_url, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument_url\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m needs to be of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see `begin_analyze_document()` to pass a byte stream.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     )\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_analyze_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43manalyze_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murlSource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_url\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_index_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43municodeCodePoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/ai/formrecognizer/_generated/_operations_mixin.py:170\u001b[0m, in \u001b[0;36mFormRecognizerClientOperationsMixin.begin_analyze_document\u001b[0;34m(self, model_id, pages, locale, string_index_type, analyze_request, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m mixin_instance\u001b[38;5;241m.\u001b[39m_serialize\u001b[38;5;241m.\u001b[39mclient_side_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    169\u001b[0m mixin_instance\u001b[38;5;241m.\u001b[39m_deserialize \u001b[38;5;241m=\u001b[39m Deserializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_models_dict(api_version))\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmixin_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_analyze_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring_index_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manalyze_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/ai/formrecognizer/_generated/v2022_08_31/operations/_form_recognizer_client_operations.py:576\u001b[0m, in \u001b[0;36mFormRecognizerClientOperationsMixin.begin_analyze_document\u001b[0;34m(self, model_id, pages, locale, string_index_type, analyze_request, content_type, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m cont_token \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinuation_token\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# type: Optional[str]\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cont_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 576\u001b[0m     raw_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_analyze_document_initial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstring_index_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_index_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43manalyze_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manalyze_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mz\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_map\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_long_running_output\u001b[39m(pipeline_response):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/exxonmobile-lfDCNjq4-py3.9/lib/python3.9/site-packages/azure/ai/formrecognizer/_generated/v2022_08_31/operations/_form_recognizer_client_operations.py:508\u001b[0m, in \u001b[0;36mFormRecognizerClientOperationsMixin._analyze_document_initial\u001b[0;34m(self, model_id, pages, locale, string_index_type, analyze_request, content_type, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m202\u001b[39m]:\n\u001b[1;32m    507\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m    510\u001b[0m response_headers \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    511\u001b[0m response_headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperation-Location\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperation-Location\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: (InvalidRequest) Invalid request.\nCode: InvalidRequest\nMessage: Invalid request.\nInner error: {\n    \"code\": \"InvalidContent\",\n    \"message\": \"The file is corrupted or format is unsupported. Refer to documentation for the list of supported formats.\"\n}"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code sample shows Prebuilt Read operations with the Azure Form Recognizer client library. \n",
    "The async versions of the samples require Python 3.6 or later.\n",
    "\n",
    "To learn more, please visit the documentation - Quickstart: Form Recognizer Python client library SDKs\n",
    "https://docs.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/quickstarts/try-v3-python-sdk\n",
    "\"\"\"\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import json\n",
    "import re \n",
    "import os\n",
    "import pandas as pd\n",
    "\"\"\"\n",
    "Remember to remove the key from your code when you're done, and never post it publicly. For production, use\n",
    "secure methods to store and access your credentials. For more information, see \n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-security?tabs=command-line%2Ccsharp#environment-variables-and-application-configuration\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "def format_bounding_box(bounding_box):\n",
    "    if not bounding_box:\n",
    "        return \"N/A\"\n",
    "    return \", \".join([\"[{}, {}]\".format(p.x, p.y) for p in bounding_box])\n",
    "\n",
    "def analyze_read():\n",
    "    \n",
    "    credentials_path = os.path.abspath('credentials3.json')\n",
    "    with open(credentials_path, 'r') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    subscription_key = credentials['API_key']\n",
    "    endpoint = credentials['endpoint']\n",
    "    # sample document\n",
    "    formUrl = \"https://exxonpdfstorage1.blob.core.windows.net/pdfcontainer1/Certifications%20-%20davidgodinez-0799%20_%20Microsoft%20Docs.pdf?sp=r&st=2023-05-05T19:07:34Z&se=2023-05-06T03:07:34Z&sip=98.44.56.177&sv=2022-11-02&sr=b&sig=VHJJxnyXM8NZgvlU8x28R4pafzaic2pjKRO3BA38tEU%3D\"\n",
    "    document_analysis_client = DocumentAnalysisClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(subscription_key)\n",
    "    )\n",
    "    \n",
    "    poller = document_analysis_client.begin_analyze_document_from_url(\n",
    "            \"prebuilt-read\", formUrl)\n",
    "    result = poller.result()\n",
    "\n",
    "    print (\"Document contains content: \", result.content)\n",
    "    \n",
    "    for idx, style in enumerate(result.styles):\n",
    "        print(\n",
    "            \"Document contains {} content\".format(\n",
    "                \"handwritten\" if style.is_handwritten else \"no handwritten\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for page in result.pages:\n",
    "        print(\"----Analyzing Read from page #{}----\".format(page.page_number))\n",
    "        print(\n",
    "            \"Page has width: {} and height: {}, measured with unit: {}\".format(\n",
    "                page.width, page.height, page.unit\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for line_idx, line in enumerate(page.lines):\n",
    "            print(\n",
    "                \"...Line # {} has text content '{}' within bounding box '{}'\".format(\n",
    "                    line_idx,\n",
    "                    line.content,\n",
    "                    format_bounding_box(line.polygon),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for word in page.words:\n",
    "            print(\n",
    "                \"...Word '{}' has a confidence of {}\".format(\n",
    "                    word.content, word.confidence\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03151fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae94c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://raw.githubusercontent.com/davidgodinez/exxonmobile/{path-to-file}/{file-name}.pdf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "007637dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {\"error\":{\"code\":\"404\",\"message\": \"Resource not found\"}}\n",
      "Error processing the document. Exiting.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def format_bounding_box(bounding_box):\n",
    "    if not bounding_box:\n",
    "        return \"N/A\"\n",
    "    return \", \".join([\"[{}, {}]\".format(p[\"x\"], p[\"y\"]) for p in bounding_box])\n",
    "\n",
    "def analyze_document(subscription_key, endpoint, model, document_url, apiVersion):\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"source\": document_url\n",
    "    }\n",
    "    \n",
    "    analyze_url = f\"{endpoint}/formrecognizer/{apiVersion}/prebuilt/{model}/analyze\"\n",
    "    \n",
    "    response = requests.post(analyze_url, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code != 202:\n",
    "        print(\"Error:\", response.text)\n",
    "        return None\n",
    "\n",
    "    operation_location = response.headers[\"Operation-Location\"]\n",
    "\n",
    "    for _ in range(20):\n",
    "        time.sleep(10)\n",
    "        result_response = requests.get(operation_location, headers=headers)\n",
    "        result = result_response.json()\n",
    "        \n",
    "        if result[\"status\"] not in [\"notStarted\", \"running\"]:\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"Status: {result['status']}, waiting for results...\")\n",
    "    \n",
    "    print(\"Timed out waiting for results.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def analyze_read():\n",
    "    credentials_path = os.path.abspath('credentials3.json')\n",
    "    with open(credentials_path, 'r') as f:\n",
    "        credentials = json.load(f)\n",
    "\n",
    "    subscription_key = credentials['API_key']\n",
    "    endpoint = credentials['endpoint']\n",
    "    formUrl = \"https://exxonpdfstorage1.blob.core.windows.net/pdfcontainer1/Certifications%20-%20davidgodinez-0799%20_%20Microsoft%20Docs.pdf?sp=r&st=2023-05-05T19:41:23Z&se=2023-05-06T03:41:23Z&sip=98.44.56.177&sv=2022-11-02&sr=b&sig=J1ohy%2BXjS0K3xGz9ChKermtl%2BTYwj7JrV%2FLOtpp6Z%2Bw%3D\"\n",
    "    \n",
    "    # Call the REST API\n",
    "    result = analyze_document(subscription_key, endpoint, \"prebuilt-read\", formUrl, \"2023-02-28-preview\")\n",
    "\n",
    "\n",
    "    # Check if the result is None and exit if there was an error\n",
    "    if result is None:\n",
    "        print(\"Error processing the document. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Process the result\n",
    "    if result[\"status\"] == \"succeeded\":\n",
    "        read_results = result[\"analyzeResult\"][\"readResults\"]\n",
    "        print(\"Document contains content: \", read_results)\n",
    "\n",
    "        for page in read_results:\n",
    "            print(\"----Analyzing Read from page #{}----\".format(page[\"pageNumber\"]))\n",
    "            print(\n",
    "                \"Page has width: {} and height: {}, measured with unit: {}\".format(\n",
    "                    page[\"width\"], page[\"height\"], page[\"unit\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            for line_idx, line in enumerate(page[\"lines\"]):\n",
    "                print(\n",
    "                    \"...Line # {} has text content '{}' within bounding box '{}'\".format(\n",
    "                        line_idx,\n",
    "                        line[\"text\"],\n",
    "                        format_bounding_box(line[\"boundingBox\"]),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            for word in page[\"words\"]:\n",
    "                print(\n",
    "                    \"...Word '{}' has a confidence of {}\".format(\n",
    "                        word[\"text\"], word[\"confidence\"]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    else:\n",
    "        print(\"Error:\", result[\"error\"])\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8b00a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                       Version\r\n",
      "--------------------------------------------- -----------\r\n",
      "anyio                                         3.6.2\r\n",
      "appdirs                                       1.4.4\r\n",
      "appnope                                       0.1.3\r\n",
      "argon2-cffi                                   21.3.0\r\n",
      "argon2-cffi-bindings                          21.2.0\r\n",
      "arrow                                         1.2.3\r\n",
      "asttokens                                     2.2.1\r\n",
      "attrs                                         23.1.0\r\n",
      "azure-ai-formrecognizer                       3.2.0\r\n",
      "azure-cognitiveservices-vision-computervision 0.9.0\r\n",
      "azure-common                                  1.1.28\r\n",
      "azure-core                                    1.26.4\r\n",
      "backcall                                      0.2.0\r\n",
      "beautifulsoup4                                4.12.2\r\n",
      "bleach                                        6.0.0\r\n",
      "boto3                                         1.26.115\r\n",
      "botocore                                      1.29.115\r\n",
      "certifi                                       2022.12.7\r\n",
      "cffi                                          1.15.1\r\n",
      "charset-normalizer                            3.1.0\r\n",
      "click                                         8.1.3\r\n",
      "comm                                          0.1.3\r\n",
      "contourpy                                     1.0.7\r\n",
      "cryptography                                  40.0.2\r\n",
      "cycler                                        0.11.0\r\n",
      "datajoint                                     0.14.0\r\n",
      "debugpy                                       1.6.7\r\n",
      "decorator                                     5.1.1\r\n",
      "defusedxml                                    0.7.1\r\n",
      "easyocr                                       1.6.2\r\n",
      "exceptiongroup                                1.1.1\r\n",
      "executing                                     1.2.0\r\n",
      "fastjsonschema                                2.16.3\r\n",
      "filelock                                      3.12.0\r\n",
      "Flask                                         2.2.3\r\n",
      "fonttools                                     4.39.3\r\n",
      "fqdn                                          1.5.1\r\n",
      "idna                                          3.4\r\n",
      "imageio                                       2.27.0\r\n",
      "importlib-metadata                            6.5.0\r\n",
      "importlib-resources                           5.12.0\r\n",
      "iniconfig                                     2.0.0\r\n",
      "ipykernel                                     6.22.0\r\n",
      "ipython                                       8.12.0\r\n",
      "ipython-genutils                              0.2.0\r\n",
      "ipywidgets                                    8.0.6\r\n",
      "isodate                                       0.6.1\r\n",
      "isoduration                                   20.11.0\r\n",
      "itsdangerous                                  2.1.2\r\n",
      "jedi                                          0.18.2\r\n",
      "Jinja2                                        3.1.2\r\n",
      "jmespath                                      1.0.1\r\n",
      "jsonpointer                                   2.3\r\n",
      "jsonschema                                    4.17.3\r\n",
      "jupyter                                       1.0.0\r\n",
      "jupyter_client                                8.2.0\r\n",
      "jupyter-console                               6.6.3\r\n",
      "jupyter_core                                  5.3.0\r\n",
      "jupyter-events                                0.6.3\r\n",
      "jupyter_server                                2.5.0\r\n",
      "jupyter_server_terminals                      0.4.4\r\n",
      "jupyterlab-pygments                           0.2.2\r\n",
      "jupyterlab-widgets                            3.0.7\r\n",
      "kiwisolver                                    1.4.4\r\n",
      "MarkupSafe                                    2.1.2\r\n",
      "matplotlib                                    3.7.1\r\n",
      "matplotlib-inline                             0.1.6\r\n",
      "minio                                         7.1.14\r\n",
      "mistune                                       2.0.5\r\n",
      "mpmath                                        1.3.0\r\n",
      "msrest                                        0.7.1\r\n",
      "nbclassic                                     0.5.5\r\n",
      "nbclient                                      0.7.3\r\n",
      "nbconvert                                     7.3.1\r\n",
      "nbformat                                      5.8.0\r\n",
      "nest-asyncio                                  1.5.6\r\n",
      "networkx                                      2.6.3\r\n",
      "ninja                                         1.11.1\r\n",
      "notebook                                      6.5.4\r\n",
      "notebook_shim                                 0.2.2\r\n",
      "numpy                                         1.24.2\r\n",
      "oauthlib                                      3.2.2\r\n",
      "opencv-python                                 4.5.4.60\r\n",
      "opencv-python-headless                        4.5.4.60\r\n",
      "otumat                                        0.3.1\r\n",
      "packaging                                     23.1\r\n",
      "pandas                                        2.0.0\r\n",
      "pandocfilters                                 1.5.0\r\n",
      "parso                                         0.8.3\r\n",
      "pexpect                                       4.8.0\r\n",
      "pickleshare                                   0.7.5\r\n",
      "Pillow                                        9.5.0\r\n",
      "pip                                           23.0.1\r\n",
      "platformdirs                                  3.2.0\r\n",
      "pluggy                                        1.0.0\r\n",
      "prometheus-client                             0.16.0\r\n",
      "prompt-toolkit                                3.0.38\r\n",
      "psutil                                        5.9.5\r\n",
      "ptyprocess                                    0.7.0\r\n",
      "pure-eval                                     0.2.2\r\n",
      "pyclipper                                     1.3.0.post4\r\n",
      "pycparser                                     2.21\r\n",
      "pydot                                         1.4.2\r\n",
      "Pygments                                      2.15.1\r\n",
      "PyMuPDF                                       1.22.1\r\n",
      "PyMySQL                                       1.0.3\r\n",
      "pyparsing                                     3.0.9\r\n",
      "PyPDF4                                        1.27.0\r\n",
      "pyrsistent                                    0.19.3\r\n",
      "pytesseract                                   0.3.10\r\n",
      "pytest                                        7.3.1\r\n",
      "python-bidi                                   0.4.2\r\n",
      "python-dateutil                               2.8.2\r\n",
      "python-json-logger                            2.0.7\r\n",
      "pytz                                          2023.3\r\n",
      "PyWavelets                                    1.4.1\r\n",
      "PyYAML                                        6.0\r\n",
      "pyzmq                                         25.0.2\r\n",
      "qtconsole                                     5.4.2\r\n",
      "QtPy                                          2.3.1\r\n",
      "requests                                      2.28.2\r\n",
      "requests-oauthlib                             1.3.1\r\n",
      "rfc3339-validator                             0.1.4\r\n",
      "rfc3986-validator                             0.1.1\r\n",
      "s3transfer                                    0.6.0\r\n",
      "scikit-image                                  0.19.3\r\n",
      "scipy                                         1.9.3\r\n",
      "Send2Trash                                    1.8.0\r\n",
      "setuptools                                    67.4.0\r\n",
      "shapely                                       2.0.1\r\n",
      "six                                           1.16.0\r\n",
      "sniffio                                       1.3.0\r\n",
      "soupsieve                                     2.4.1\r\n",
      "stack-data                                    0.6.2\r\n",
      "sympy                                         1.11.1\r\n",
      "terminado                                     0.17.1\r\n",
      "tifffile                                      2023.4.12\r\n",
      "tinycss2                                      1.2.1\r\n",
      "tomli                                         2.0.1\r\n",
      "torch                                         2.0.0\r\n",
      "torchvision                                   0.15.1\r\n",
      "tornado                                       6.3\r\n",
      "tqdm                                          4.65.0\r\n",
      "traitlets                                     5.9.0\r\n",
      "typing_extensions                             4.5.0\r\n",
      "tzdata                                        2023.3\r\n",
      "uri-template                                  1.2.0\r\n",
      "urllib3                                       1.26.15\r\n",
      "watchdog                                      3.0.0\r\n",
      "wcwidth                                       0.2.6\r\n",
      "webcolors                                     1.13\r\n",
      "webencodings                                  0.5.1\r\n",
      "websocket-client                              1.5.1\r\n",
      "Werkzeug                                      2.2.3\r\n",
      "wheel                                         0.38.4\r\n",
      "widgetsnbextension                            4.0.7\r\n",
      "zipp                                          3.15.0\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d02ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
